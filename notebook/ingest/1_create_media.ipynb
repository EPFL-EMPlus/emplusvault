{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/arattinger/Projects/rts\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rts.db.dao import DataAccessObject\n",
    "from rts.db_settings import DATABASE_URL\n",
    "from rts.db.queries import get_library_id_from_name, read_media_by_source_file_id\n",
    "from rts.io.media import upload_media_files\n",
    "from rts.api.models import Media\n",
    "import os\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "DataAccessObject().connect(DATABASE_URL)\n",
    "\n",
    "ARCHIVE_BASE_PATH = os.getenv(\"BASE_PATH\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- Decouple the upload functions from discovering the files. We need to give them a list of file paths and metadata (minimum one). One of the dangers at the moment is that we might ingest something by accident.\n",
    "- Make sure that all the data for the atlases are returned with the requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup before we can create media objects\n",
    "archive_name =  \"rts\"\n",
    "bucket_name =  archive_name\n",
    "library_id =  get_library_id_from_name(archive_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "# Upload clips\n",
    "\n",
    "clips = []\n",
    "data_dir = os.path.join(ARCHIVE_BASE_PATH, \"data\")\n",
    "for dirname in os.listdir(data_dir):\n",
    "    try:\n",
    "        clip_dir = os.path.join(data_dir, dirname, 'clips', 'videos')\n",
    "\n",
    "        for clip in os.listdir(clip_dir):\n",
    "            clip_path = os.path.join(clip_dir, clip)\n",
    "\n",
    "            clips.append(Media(**{\n",
    "                    'original_path': clip_path,\n",
    "                    'original_id': dirname,\n",
    "                    'media_path': f\"{bucket_name}/videos/{dirname}/{clip}\", \n",
    "                    'media_type': \"video\",\n",
    "                    'file_id': clip.split('.')[0],\n",
    "                    'sub_type': \"clip\", \n",
    "                    'size': os.path.getsize(clip_path), \n",
    "                    'metadata': {},\n",
    "                    'library_id': library_id, \n",
    "                    'hash': hashlib.md5(f\"{bucket_name}/videos/{dirname}/{clip}\".encode()).hexdigest(), \n",
    "                    'parent_id': -1,\n",
    "                    'start_ts': 0, 'end_ts': 10, \n",
    "                    'start_frame': 0, 'end_frame': 10, 'frame_rate': 30, \n",
    "            }))\n",
    "\n",
    "    except NotADirectoryError:\n",
    "        pass\n",
    "print(len(clips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_clips = upload_media_files(clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_media_by_source_file_id('ZB006020-L001').media_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "# Upload thumbnails\n",
    "thumbnails = []\n",
    "square_res = 256\n",
    "\n",
    "data_dir = os.path.join(ARCHIVE_BASE_PATH, \"data\")\n",
    "for dirname in os.listdir(data_dir):\n",
    "    try:\n",
    "        clip_dir = os.path.join(data_dir, dirname, 'clips', 'images', '256px')\n",
    "\n",
    "        for clip in os.listdir(clip_dir):\n",
    "            clip_path = os.path.join(clip_dir, clip)\n",
    "\n",
    "            # Find the parent. There can be multiple ways this can be achieved but\n",
    "            # most of the time this will not be solely based with the database\n",
    "            source_file_id = clip.split('.')[0][:-3]\n",
    "            parent_id = read_media_by_source_file_id(source_file_id).media_id\n",
    "\n",
    "            thumbnails.append(Media(**{\n",
    "                    'original_path': clip_path,\n",
    "                    'original_id': dirname,\n",
    "                    'media_path': f\"{bucket_name}/images/{dirname}/{square_res}px/{clip}\", \n",
    "                    'media_type': \"image\", \n",
    "                    'file_id': clip.split('.')[0],\n",
    "                    'sub_type': \"thumbnail\", \n",
    "                    'size': os.path.getsize(clip_path),\n",
    "                    'metadata': {},\n",
    "                    'library_id': library_id, \n",
    "                    'hash': hashlib.md5(f\"{bucket_name}/videos/{dirname}/{clip}\".encode()).hexdigest(), \n",
    "                    'parent_id': parent_id,  # Fill in the info here from the media objects\n",
    "                    'start_ts': 0, 'end_ts': 10, \n",
    "                    'start_frame': 0, 'end_frame': 10, 'frame_rate': 30, \n",
    "            }))\n",
    "\n",
    "    except NotADirectoryError:\n",
    "        pass\n",
    "print(len(thumbnails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_clips = upload_media_files(thumbnails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
