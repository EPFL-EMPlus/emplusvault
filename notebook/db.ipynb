{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Examples \n",
    "\n",
    "Examples for the new database schema and how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /home/andre/rts/.venv/lib/python3.10/site-packages (2.9.6)\n",
      "Requirement already satisfied: python-dotenv in /home/andre/rts/.venv/lib/python3.10/site-packages (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install psycopg2-binary python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andre\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# jupyter notebook auto reload\n",
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Utility functions for setting up the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "from rts.db.utils import execute_read_query, execute_write_query\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables\n",
    "\n",
    "Creating the necessary database tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_write_query(\"DROP TABLE IF EXISTS map_projection_feature;\")\n",
    "execute_write_query(\"DROP TABLE IF EXISTS projection;\")\n",
    "execute_write_query(\"DROP TABLE IF EXISTS features;\")\n",
    "execute_write_query(\"DROP TABLE IF EXISTS media;\")\n",
    "execute_write_query(\"DROP TABLE IF EXISTS library;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1,)]\n"
     ]
    }
   ],
   "source": [
    "# postgres table definitions\n",
    "\n",
    "_table_library = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS library (\n",
    "        library_id SERIAL PRIMARY KEY,\n",
    "        library_name VARCHAR(50) NOT NULL,\n",
    "        version VARCHAR(20) NOT NULL,\n",
    "        created_at TIMESTAMP DEFAULT NOW(),\n",
    "        data JSONB NOT NULL\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "_create_library = \"\"\"\n",
    "    INSERT INTO library (library_name, version, data)\n",
    "    VALUES ('rts', '0.1', '{}')\n",
    "    RETURNING library_id;\n",
    "\"\"\"\n",
    "\n",
    "_table_projection = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS projection (\n",
    "        projection_id SERIAL PRIMARY KEY,\n",
    "        version VARCHAR(20) NOT NULL,\n",
    "        library_id INTEGER NOT NULL,\n",
    "        created_at TIMESTAMP DEFAULT NOW(),\n",
    "        model_name VARCHAR(200) NOT NULL,\n",
    "        model_params JSONB NOT NULL,\n",
    "        data JSONB NOT NULL,\n",
    "        dimension INTEGER NOT NULL,\n",
    "        atlas_folder_path VARCHAR(500) NOT NULL,\n",
    "        atlas_width INTEGER NOT NULL,\n",
    "        tile_size INTEGER NOT NULL,\n",
    "        atlas_count INTEGER NOT NULL,\n",
    "        total_tiles INTEGER NOT NULL,\n",
    "        tiles_per_atlas INTEGER NOT NULL,\n",
    "\n",
    "        CONSTRAINT FK_projection_library_id FOREIGN KEY (library_id)\n",
    "            REFERENCES library (library_id)\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "_table_media = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS media (\n",
    "        media_id SERIAL PRIMARY KEY,\n",
    "        media_path VARCHAR(500) UNIQUE,\n",
    "        original_path VARCHAR(500) NOT NULL,\n",
    "        created_at TIMESTAMP DEFAULT NOW(),\n",
    "        media_type VARCHAR(50) NOT NULL,\n",
    "        sub_type VARCHAR(50) NOT NULL,\n",
    "        size INTEGER NOT NULL,\n",
    "        metadata JSONB NOT NULL,\n",
    "        library_id INTEGER NOT NULL,\n",
    "        hash VARCHAR(50) NOT NULL,\n",
    "        parent_id INTEGER,\n",
    "        start_ts FLOAT,\n",
    "        end_ts FLOAT,\n",
    "        start_frame INTEGER,\n",
    "        end_frame INTEGER,\n",
    "        frame_rate INTEGER,\n",
    "\n",
    "        CONSTRAINT FK_media_library_id FOREIGN KEY (library_id)\n",
    "            REFERENCES library (library_id)\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "_table_features = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS features (\n",
    "        feature_id SERIAL PRIMARY KEY,\n",
    "        feature_type VARCHAR(50) NOT NULL,\n",
    "        version VARCHAR(20) NOT NULL,\n",
    "        created_at TIMESTAMP DEFAULT NOW(),\n",
    "        model_name VARCHAR(200) NOT NULL,\n",
    "        model_params JSONB NOT NULL,\n",
    "        data JSONB NOT NULL,\n",
    "\n",
    "        embedding_size INTEGER,\n",
    "        embedding_1024 vector (1024),\n",
    "        embedding_1536 vector (1536),\n",
    "        embedding_2048 vector (2048),\n",
    "\n",
    "        media_id INTEGER,\n",
    "\n",
    "        CONSTRAINT FK_features_media_id FOREIGN KEY (media_id) \n",
    "            REFERENCES media (media_id)\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "_table_map_projection_feature = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS map_projection_feature (\n",
    "        map_projection_feature_id SERIAL PRIMARY KEY,\n",
    "        projection_id INTEGER NOT NULL,\n",
    "        feature_id INTEGER NOT NULL,\n",
    "        atlas_order INTEGER NOT NULL,\n",
    "\n",
    "        CONSTRAINT FK_map_projection_feature_projection_id FOREIGN KEY (projection_id)\n",
    "            REFERENCES projection (projection_id),\n",
    "        CONSTRAINT FK_map_projection_feature_feature_id FOREIGN KEY (feature_id)\n",
    "            REFERENCES features (feature_id)\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "execute_write_query(_table_library)\n",
    "execute_write_query(_table_projection)\n",
    "execute_write_query(_table_media)\n",
    "execute_write_query(_table_features)\n",
    "execute_write_query(_table_map_projection_feature)\n",
    "\n",
    "print(execute_read_query(_create_library))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill tables with sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sample data for the tables, each media element can have multiple features\n",
    "\n",
    "swiss_cities = [\"Zurich\", \"Geneva\", \"Basel\", \"Lausanne\", \"Bern\", \"Winterthur\", \"Lucerne\", \"St. Gallen\", \"Lugano\", \"Biel/Bienne\"]\n",
    "years = [2015, 2016, 2017, 2018, 2019, 2020]\n",
    "\n",
    "for i in range(1, 21):\n",
    "    _table_media_sample = f\"\"\"\n",
    "        INSERT INTO media (media_path, original_path, media_type, sub_type, size, archive_name, archive_id, metadata)\n",
    "        VALUES \n",
    "            ('/path/to/media{i}', '/path/to/original{i}', 'image', 'jpg', 500, 'archive{i}', 'archive_id{i}', '{{\"key{i}\": \"value{i}\", \"city\": \"{swiss_cities[(i-1) % len(swiss_cities)]}\", \"year\": {years[(i-1) % len(years)]}}}')\n",
    "        RETURNING media_id;\n",
    "    \"\"\"\n",
    "    execute_write_query(_table_media_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  '/path/to/media1',\n",
       "  '/path/to/original1',\n",
       "  datetime.datetime(2023, 5, 2, 10, 35, 53, 70041),\n",
       "  'image',\n",
       "  'jpg',\n",
       "  500,\n",
       "  'archive1',\n",
       "  'archive_id1',\n",
       "  {'city': 'Zurich', 'key1': 'value1', 'year': 2015}),\n",
       " (2,\n",
       "  '/path/to/media2',\n",
       "  '/path/to/original2',\n",
       "  datetime.datetime(2023, 5, 2, 10, 35, 53, 107340),\n",
       "  'image',\n",
       "  'jpg',\n",
       "  500,\n",
       "  'archive2',\n",
       "  'archive_id2',\n",
       "  {'city': 'Geneva', 'key2': 'value2', 'year': 2016})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_query = \"\"\"SELECT * FROM media LIMIT 2;\"\"\"\n",
    "execute_read_query(_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert some samples with vectors\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "feature_types = [\"pose\", \"face\", \"object\", \"ner\"]\n",
    "color_meta = [\"red\", \"green\", \"blue\", \"yellow\", \"black\", \"white\", \"grey\", \"orange\", \"purple\", \"pink\"]\n",
    "\n",
    "for i in range(1, 11):\n",
    "    vector_1024 = np.random.rand(1024).tolist()\n",
    "    vector_2048 = np.random.rand(2048).tolist()\n",
    "    ner_tags = json.dumps([(\"person\", \"Ueli Steck\", 1, 9), (\"city\", \"geneva\", 10, 16), (\"city\", \"zurich\", 17, 23), (\"city\", \"bern\", 24, 28), (\"city\", \"basel\", 29, 34), (\"city\", \"winterthur\", 35, 46), (\"city\", \"lucerne\", 47, 54), (\"city\", \"st. gallen\", 55, 65), (\"city\", \"lugano\", 66, 72), (\"city\", \"biel/bienne\", 73, 85)])\n",
    "\n",
    "    _table_features_sample_vectors = f\"\"\"\n",
    "        INSERT INTO features (feature_type, version, model_name, model_params, data, media_id, embedding_size, embedding_1024)\n",
    "        VALUES\n",
    "            ('{feature_types[i % len(feature_types)]}', 'v1', 'resnet50', '{{\"param1\": \"{i}\"}}', '{{\"color\": \"{color_meta[i % len(color_meta)] }\", \"data1\": \"{i}\", \"ner\": {ner_tags} }}', {i}, 1024, ARRAY[{','.join([str(x) for x in vector_1024])}])\n",
    "        RETURNING feature_id;\n",
    "    \"\"\"\n",
    "    # print(_table_features_sample_vectors)\n",
    "    execute_write_query(_table_features_sample_vectors)\n",
    "\n",
    "    # At the moment we are only creating size 1024 vectors, for the sake of the next example queries to work, there can be only a single vector set per feature\n",
    "    # _table_features_sample_vectors = f\"\"\"\n",
    "    #     INSERT INTO features (feature_type, version, model_name, model_params, data, media_id, embedding_size, embedding_2048)\n",
    "    #     VALUES\n",
    "    #         ('image', 'v1', 'resnet50', '{{\"param1\": \"{i}\"}}', '{{\"data1\": \"{i}\"}}', {i}, 2048, ARRAY[{','.join([str(x) for x in vector_2048])}])\n",
    "    #     RETURNING feature_id;\n",
    "    # \"\"\"\n",
    "\n",
    "    # execute_write_query(_table_features_sample_vectors)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries\n",
    "\n",
    "### Scenario 1\n",
    "\n",
    "We have a media object and we want to find the 5 most similar media objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 12.6620561267192),\n",
       " (1, 12.9727147189136),\n",
       " (7, 12.9900472952322),\n",
       " (8, 13.0338304337032),\n",
       " (2, 13.0584285629705)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_query = \"\"\"\n",
    "    WITH target_embedding AS (\n",
    "    SELECT\n",
    "        media_id,\n",
    "        CASE\n",
    "            WHEN embedding_size = 1024 THEN embedding_1024\n",
    "            WHEN embedding_size = 2048 THEN embedding_2048\n",
    "            ELSE NULL\n",
    "        END AS embedding_vector\n",
    "    FROM \n",
    "        features\n",
    "    WHERE \n",
    "        media_id = 5\n",
    "    )\n",
    "\n",
    "    SELECT\n",
    "    f.media_id,\n",
    "    (target.embedding_vector <-> \n",
    "        CASE\n",
    "        WHEN f.embedding_size = 1024 THEN f.embedding_1024\n",
    "        WHEN f.embedding_size = 2048 THEN f.embedding_2048\n",
    "        ELSE NULL\n",
    "        END\n",
    "    ) AS distance\n",
    "    FROM\n",
    "    features f,\n",
    "    target_embedding target\n",
    "    WHERE\n",
    "    f.media_id != target.media_id\n",
    "    ORDER BY\n",
    "    distance ASC\n",
    "    LIMIT 5;\n",
    "\"\"\"\n",
    "\n",
    "execute_read_query(_query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2\n",
    "\n",
    "Find all media objects for Zurich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  '/path/to/media1',\n",
       "  '/path/to/original1',\n",
       "  datetime.datetime(2023, 5, 2, 10, 35, 53, 70041),\n",
       "  'image',\n",
       "  'jpg',\n",
       "  500,\n",
       "  'archive1',\n",
       "  'archive_id1',\n",
       "  {'city': 'Zurich', 'key1': 'value1', 'year': 2015}),\n",
       " (11,\n",
       "  '/path/to/media11',\n",
       "  '/path/to/original11',\n",
       "  datetime.datetime(2023, 5, 2, 10, 35, 53, 446582),\n",
       "  'image',\n",
       "  'jpg',\n",
       "  500,\n",
       "  'archive11',\n",
       "  'archive_id11',\n",
       "  {'city': 'Zurich', 'year': 2019, 'key11': 'value11'})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all media objects that have city: \"Zurich\" (queried from the jsonb metadata field)\n",
    "_query = \"\"\"\n",
    "    SELECT * FROM media WHERE metadata->>'city' = 'Zurich';\n",
    "\"\"\"\n",
    "execute_read_query(_query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 3\n",
    "\n",
    "Get all images from Geneva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2,\n",
       "  '/path/to/media2',\n",
       "  '/path/to/original2',\n",
       "  datetime.datetime(2023, 5, 2, 10, 35, 53, 107340),\n",
       "  'image',\n",
       "  'jpg',\n",
       "  500,\n",
       "  'archive2',\n",
       "  'archive_id2',\n",
       "  {'city': 'Geneva', 'key2': 'value2', 'year': 2016}),\n",
       " (12,\n",
       "  '/path/to/media12',\n",
       "  '/path/to/original12',\n",
       "  datetime.datetime(2023, 5, 2, 10, 35, 53, 479945),\n",
       "  'image',\n",
       "  'jpg',\n",
       "  500,\n",
       "  'archive12',\n",
       "  'archive_id12',\n",
       "  {'city': 'Geneva', 'year': 2020, 'key12': 'value12'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_query = \"\"\"\n",
    "    SELECT * FROM media WHERE metadata->>'city' = 'Geneva' AND media_type = 'image';\n",
    "\"\"\"\n",
    "execute_read_query(_query)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 4\n",
    "\n",
    "Fulltext string matching on jsonb fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Basel', 'Bern', 'Biel/Bienne', 'Basel', 'Bern', 'Biel/Bienne']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['St. Gallen', 'St. Gallen']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query for cities that start with b\n",
    "_query = \"\"\"\n",
    "    SELECT * FROM media WHERE metadata->>'city' LIKE 'B%';\n",
    "\"\"\"\n",
    "print([x[9]['city'] for x in execute_read_query(_query)])\n",
    "\n",
    "_query = \"\"\"\n",
    "    SELECT * FROM media WHERE metadata->>'city' LIKE '%Gall%';\n",
    "\"\"\"\n",
    "[x[9]['city'] for x in execute_read_query(_query)]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 5\n",
    "\n",
    "Similarity to a computed vector. Example: we have a video camera installed and a user poses like a tennis player and we find tennis matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 12.9973420438942), (4, 13.3367706705129)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_1024 = \",\".join([str(x) for x in np.random.rand(1024).tolist()])  # feature that would be creating by the pose detection algorithm\n",
    "\n",
    "# query the feature table for similar vectors\n",
    "_query = f\"\"\"\n",
    "    SELECT\n",
    "    f.media_id,\n",
    "    ('[{vector_1024}]' <-> \n",
    "        CASE\n",
    "        WHEN f.embedding_size = 1024 THEN f.embedding_1024\n",
    "        WHEN f.embedding_size = 2048 THEN f.embedding_2048\n",
    "        ELSE NULL\n",
    "        END\n",
    "    ) AS distance\n",
    "    FROM\n",
    "    features f\n",
    "    WHERE\n",
    "    f.feature_type = 'pose'\n",
    "    ORDER BY\n",
    "    distance ASC\n",
    "    LIMIT 5;\n",
    "\"\"\"\n",
    "\n",
    "execute_read_query(_query)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 6\n",
    "\n",
    "Find people or locations with ner tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'green',\n",
       "   'data1': '1'}),\n",
       " (2,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'blue',\n",
       "   'data1': '2'}),\n",
       " (3,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'yellow',\n",
       "   'data1': '3'}),\n",
       " (4,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'black',\n",
       "   'data1': '4'}),\n",
       " (5,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'white',\n",
       "   'data1': '5'}),\n",
       " (6,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'grey',\n",
       "   'data1': '6'}),\n",
       " (7,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'orange',\n",
       "   'data1': '7'}),\n",
       " (8,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'purple',\n",
       "   'data1': '8'}),\n",
       " (9,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'pink',\n",
       "   'data1': '9'}),\n",
       " (10,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'red',\n",
       "   'data1': '10'})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person = \"Ueli Steck\"\n",
    "\n",
    "_query = f\"\"\"\n",
    "    SELECT media_id, data FROM features WHERE data->>'ner' LIKE '%{person}%';\n",
    "\"\"\"\n",
    "\n",
    "execute_read_query(_query)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 7\n",
    "\n",
    "Find aribitrary features by metadata (here we use the simple field color as an example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'red',\n",
       "   'data1': '10'})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color = \"red\"\n",
    "\n",
    "_query = f\"\"\"\n",
    "    SELECT media_id, data FROM features WHERE data->>'color' = '{color}';\n",
    "\"\"\"\n",
    "\n",
    "execute_read_query(_query)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest the clips to the media table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOTE_RTS_DATA = \"/media/sinergia/RTS/\"\n",
    "REMOTE_VIDEOS = '/mnt/rts/'\n",
    "\n",
    "LOCAL_RTS_DATA = \"/media/data/rts/\"\n",
    "METADATA = LOCAL_RTS_DATA + 'metadata'\n",
    "LOCAL_VIDEOS = LOCAL_RTS_DATA + 'archive'\n",
    "\n",
    "AIBOX = LOCAL_RTS_DATA + 'aibox-vectors'\n",
    "\n",
    "OUTDIR = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import orjson\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "import io\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import hashlib\n",
    "from supabase import create_client, Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL imports\n",
    "import rts\n",
    "import rts.pipeline\n",
    "import rts.utils\n",
    "import rts.io.media\n",
    "import rts.features.audio\n",
    "import rts.features.text\n",
    "\n",
    "LOG = rts.utils.get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "supabase: Client = create_client(\n",
    "    os.getenv(\"SUPABASE_HOST\"), \n",
    "    os.getenv(\"SUPABASE_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "StorageException",
     "evalue": "{'statusCode': 400, 'error': 'Invalid JWT', 'message': 'new row violates row-level security policy for table \"buckets\"'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/rts/.venv/lib/python3.10/site-packages/storage3/_sync/bucket.py:28\u001b[0m, in \u001b[0;36mSyncStorageBucketAPI._request\u001b[0;34m(self, method, url, json)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 28\u001b[0m     response\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m     29\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError:\n",
      "File \u001b[0;32m~/rts/.venv/lib/python3.10/site-packages/httpx/_models.py:749\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    748\u001b[0m message \u001b[39m=\u001b[39m message\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m, error_type\u001b[39m=\u001b[39merror_type)\n\u001b[0;32m--> 749\u001b[0m \u001b[39mraise\u001b[39;00m HTTPStatusError(message, request\u001b[39m=\u001b[39mrequest, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '400 Bad Request' for url 'http://localhost:8000/storage/v1/bucket'\nFor more information check: https://httpstatuses.com/400",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mStorageException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m bucket_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrts\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m res \u001b[39m=\u001b[39m supabase\u001b[39m.\u001b[39;49mstorage\u001b[39m.\u001b[39;49mcreate_bucket(bucket_name)\n",
      "File \u001b[0;32m~/rts/.venv/lib/python3.10/site-packages/storage3/_sync/bucket.py:68\u001b[0m, in \u001b[0;36mSyncStorageBucketAPI.create_bucket\u001b[0;34m(self, id, name, public)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_bucket\u001b[39m(\n\u001b[1;32m     55\u001b[0m     \u001b[39mself\u001b[39m, \u001b[39mid\u001b[39m: \u001b[39mstr\u001b[39m, name: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, public: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     56\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m     57\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Creates a new storage bucket.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m        Whether the bucket you are creating should be publicly accessible. Defaults to False.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m     69\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     70\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/bucket\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     71\u001b[0m         json\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mid\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m\"\u001b[39;49m: name \u001b[39mor\u001b[39;49;00m \u001b[39mid\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mpublic\u001b[39;49m\u001b[39m\"\u001b[39;49m: public},\n\u001b[1;32m     72\u001b[0m     )\n\u001b[1;32m     73\u001b[0m     \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/rts/.venv/lib/python3.10/site-packages/storage3/_sync/bucket.py:30\u001b[0m, in \u001b[0;36mSyncStorageBucketAPI._request\u001b[0;34m(self, method, url, json)\u001b[0m\n\u001b[1;32m     28\u001b[0m     response\u001b[39m.\u001b[39mraise_for_status()\n\u001b[1;32m     29\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError:\n\u001b[0;32m---> 30\u001b[0m     \u001b[39mraise\u001b[39;00m StorageException(\n\u001b[1;32m     31\u001b[0m         {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresponse\u001b[39m.\u001b[39mjson(), \u001b[39m\"\u001b[39m\u001b[39mstatusCode\u001b[39m\u001b[39m\"\u001b[39m: response\u001b[39m.\u001b[39mstatus_code}\n\u001b[1;32m     32\u001b[0m     )\n\u001b[1;32m     34\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "\u001b[0;31mStorageException\u001b[0m: {'statusCode': 400, 'error': 'Invalid JWT', 'message': 'new row violates row-level security policy for table \"buckets\"'}"
     ]
    }
   ],
   "source": [
    "bucket_name = \"rts\"\n",
    "res = supabase.storage.create_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3177, 22)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = rts.utils.dataframe_from_hdf5(LOCAL_RTS_DATA + '/metadata', 'rts_aivectors')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/1/0/ZE004015/clips/videos/ZE004015-L006.mp4\n"
     ]
    }
   ],
   "source": [
    "print(f\"{row.mediaFolderPath.replace(REMOTE_VIDEOS, '')}/clips/videos/{files[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/data/rts/archive/5/1/0/ZE004015/clips/videos'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "StorageException",
     "evalue": "{'statusCode': 400, 'error': 'Duplicate', 'message': 'The resource already exists'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/rts/.venv/lib/python3.10/site-packages/storage3/_sync/file_api.py:46\u001b[0m, in \u001b[0;36mSyncBucketActionsMixin._request\u001b[0;34m(self, method, url, headers, json, files)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     response\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m     47\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError:\n",
      "File \u001b[0;32m~/rts/.venv/lib/python3.10/site-packages/httpx/_models.py:749\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    748\u001b[0m message \u001b[39m=\u001b[39m message\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m, error_type\u001b[39m=\u001b[39merror_type)\n\u001b[0;32m--> 749\u001b[0m \u001b[39mraise\u001b[39;00m HTTPStatusError(message, request\u001b[39m=\u001b[39mrequest, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '400 Bad Request' for url 'http://localhost:8000/storage/v1/object/rts/0/1/rts/test_supabase_upload.mp4-8'\nFor more information check: https://httpstatuses.com/400",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mStorageException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# with open(os.path.join(path, files[0]), 'rb+') as f:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, files[\u001b[39m0\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m res \u001b[39m=\u001b[39m supabase\u001b[39m.\u001b[39;49mstorage\u001b[39m.\u001b[39;49mfrom_(\u001b[39m'\u001b[39;49m\u001b[39mrts\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mupload(\u001b[39m\"\u001b[39;49m\u001b[39m0/1/rts/test_supabase_upload.mp4-8\u001b[39;49m\u001b[39m\"\u001b[39;49m, os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mabspath(filename))\n",
      "File \u001b[0;32m~/rts/.venv/lib/python3.10/site-packages/storage3/_sync/file_api.py:232\u001b[0m, in \u001b[0;36mSyncBucketActionsMixin.upload\u001b[0;34m(self, path, file, file_options)\u001b[0m\n\u001b[1;32m    228\u001b[0m     files \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m\"\u001b[39m: (filename, \u001b[39mopen\u001b[39m(file, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m), headers\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mcontent-type\u001b[39m\u001b[39m\"\u001b[39m))}\n\u001b[1;32m    230\u001b[0m _path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_final_path(path)\n\u001b[0;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    233\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    234\u001b[0m     \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/object/\u001b[39;49m\u001b[39m{\u001b[39;49;00m_path\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    235\u001b[0m     files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    236\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    237\u001b[0m )\n",
      "File \u001b[0;32m~/rts/.venv/lib/python3.10/site-packages/storage3/_sync/file_api.py:48\u001b[0m, in \u001b[0;36mSyncBucketActionsMixin._request\u001b[0;34m(self, method, url, headers, json, files)\u001b[0m\n\u001b[1;32m     46\u001b[0m     response\u001b[39m.\u001b[39mraise_for_status()\n\u001b[1;32m     47\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError:\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mraise\u001b[39;00m StorageException(\n\u001b[1;32m     49\u001b[0m         {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresponse\u001b[39m.\u001b[39mjson(), \u001b[39m\"\u001b[39m\u001b[39mstatusCode\u001b[39m\u001b[39m\"\u001b[39m: response\u001b[39m.\u001b[39mstatus_code}\n\u001b[1;32m     50\u001b[0m     )\n\u001b[1;32m     52\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "\u001b[0;31mStorageException\u001b[0m: {'statusCode': 400, 'error': 'Duplicate', 'message': 'The resource already exists'}"
     ]
    }
   ],
   "source": [
    "\n",
    "# with open(os.path.join(path, files[0]), 'rb+') as f:\n",
    "filename = os.path.join(path, files[0])\n",
    "res = supabase.storage.from_('rts').upload(\"0/1/rts/test_supabase_upload.mp4-8\", os.path.abspath(filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guid': 'AA1104002390',\n",
       " 'mediaFolderPath': '/mnt/rts/5/1/0/ZE004015',\n",
       " 'mediaDuration': 4437,\n",
       " 'ratio': '16:9',\n",
       " 'formatResolution': 'SD',\n",
       " 'publishedDate': '2011-04-09T00:00:00Z',\n",
       " 'categoryName': 'Programme',\n",
       " 'assetType': 'Programme',\n",
       " 'contentType': 'Pop et rock, clips',\n",
       " 'backgoundType': None,\n",
       " 'collection': 'MusicOmax',\n",
       " 'publishedBy': 'TSR 2',\n",
       " 'rights': 'Restriction/Condition',\n",
       " 'title': 'WALDER / PAMPLEMOUSSE / NICOLAS FRAISSINET - 11.04.09',\n",
       " 'resume': \"* Lausanne : 20110409, magazine de la scène musicale romande et régionale animé par DESTRAZ Pierrick et REPOND Judith depuis le MAD de Lausanne avec leurs invités et des concerts d'artistes suisses et internationaux.\",\n",
       " 'geoTheme': ['LAUSANNE'],\n",
       " 'resumeSequence': ['00:01.22\\nLausanne, MAD, diverses séquences : diverses présentations DESTRAZ, Pierrick et REPOND, Judith avec leurs invités WALDER, auteur-illustrateur (son métier, ses 1ers dessins, ses débuts, ses BD, références, chansons, musique, dessin  d\\'une pochette d\\'album, quiz musical, les mangas, différentes écoles de BD,  collaboration entre dessinateurs, Internet, influences, questionnaire rapide, voyages), MONNARD, Frédéric et DONNET, Christian, membres Pamplemousse (membres du groupe, leur style, composition des chansons), ainsi que FRAISSINET, Nicolas, chanteur (son album \"Les métamorphoses\") / Pamplemousse, groupe de  musique de variétés, chantant \"Lou\". bande dessinée',\n",
       "  '00:05.22, 00:12.12\\r\\nLausanne, int studios Couleur3, diverses séquences : Mmmh!, groupe de rock jazz, chantant \"Dragon\" / itw Mmmh! (meilleurs morceaux, rituel avant la  scène, objets sur un île déserte) / Mmmh! chantant \"Echo baby\". concert de  variétés ',\n",
       "  '00:27.27\\r\\nLieu indéterminé : diaporama de dessins extraits de bandes dessinées de  WALDER, auteur-illustrateur. bande dessinée ',\n",
       "  \"00:31.13\\r\\nLausanne, int studios Couleur3 : itw RED, Axelle, chanteuse (écriture de  l'album, style americana, concerts). interview \",\n",
       "  '00:50.14\\nLieu indéterminé : extrait vidéoclip de FRAISSINET, Nicolas, chanteur, chantant \"La métamorphose du papillon\"',\n",
       "  '00:55:50\\r\\nLausanne, int studios Couleur3, diverses séquences : Morphologue, groupe de musique électro trip hop, chantant \"A closed eyes\" et \"Sweeties\". concert de variétés, pop.'],\n",
       " 'created': 1670505072,\n",
       " 'published': 1302307200,\n",
       " 'sequences': {'901697': {'guid': 'AA1104002390',\n",
       "   'mediaId': 'ZE004015',\n",
       "   'seqid': '901697',\n",
       "   'geo': ['lausanne'],\n",
       "   'mat': ['bande dessinée'],\n",
       "   'pp': ['fraissinet, nicolas']},\n",
       "  '901698': {'guid': 'AA1104002390',\n",
       "   'mediaId': 'ZE004015',\n",
       "   'seqid': '901698',\n",
       "   'geo': ['lausanne'],\n",
       "   'mat': ['concert de variétés', 'jazz', 'rock'],\n",
       "   'pp': []},\n",
       "  '901699': {'guid': 'AA1104002390',\n",
       "   'mediaId': 'ZE004015',\n",
       "   'seqid': '901699',\n",
       "   'geo': ['lieu indéterminé'],\n",
       "   'mat': ['bande dessinée'],\n",
       "   'pp': []},\n",
       "  '901700': {'guid': 'AA1104002390',\n",
       "   'mediaId': 'ZE004015',\n",
       "   'seqid': '901700',\n",
       "   'geo': ['lausanne'],\n",
       "   'mat': ['interview'],\n",
       "   'pp': []},\n",
       "  '901701': {'guid': 'AA1104002390',\n",
       "   'mediaId': 'ZE004015',\n",
       "   'seqid': '901701',\n",
       "   'geo': ['lieu indéterminé'],\n",
       "   'mat': ['vidéoclip'],\n",
       "   'pp': ['fraissinet, nicolas']},\n",
       "  '901702': {'guid': 'AA1104002390',\n",
       "   'mediaId': 'ZE004015',\n",
       "   'seqid': '901702',\n",
       "   'geo': ['lausanne'],\n",
       "   'mat': ['pop', 'concert de variétés'],\n",
       "   'pp': []}},\n",
       " 'aivector_id': '0b3241369e6e4a20942adc020470326f',\n",
       " 'aivector_path': 'f/6/2/0b3241369e6e4a20942adc020470326f'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No clips found for 0 rows\n",
      "Total number of clips: 7\n",
      "Total number of vidoes with clips: 3177\n"
     ]
    }
   ],
   "source": [
    "# get all the clips from the archive and put them into supabase s3. At the same time create the database entries on the media table\n",
    "\n",
    "bucket_name = \"test\"\n",
    "\n",
    "error_count = 0\n",
    "no_clips = 0\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "\n",
    "    path = os.path.join(row.mediaFolderPath.replace(REMOTE_VIDEOS, LOCAL_VIDEOS + '/'), 'clips', 'videos')\n",
    "\n",
    "    # get all files in the folder\n",
    "    try:\n",
    "        files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "        no_clips += len(files)\n",
    "\n",
    "        # TODO: Create parent media file for the source video for clips\n",
    "        pass\n",
    "\n",
    "        # upload all files to supabase and create the database entries\n",
    "        for f in files:\n",
    "            supabase_key = f\"{bucket_name}/{row.mediaFolderPath.replace(REMOTE_VIDEOS, '')}/clips/videos/{f}\"\n",
    "            filename = os.path.join(path, files[0])\n",
    "            file_size = os.path.getsize(filename)\n",
    "            library_id = \"1\"  # rts\n",
    "            hash = hashlib.md5(open(filename, 'rb').read()).hexdigest()\n",
    "            parent_id = 1  # TODO: get the parent id from the database\n",
    "            start_ts, end_ts, start_frame, end_frame, frame_rate = 0, 0, 0, 0, 30  # TODO: get the values from the database\n",
    "            \n",
    "            # create the database entry\n",
    "            _query = f\"\"\"\n",
    "                INSERT INTO media (\n",
    "                    media_path, original_path, media_type, sub_type, \n",
    "                    size, library_id, metadata, hash, \n",
    "                    parent_id, start_ts, end_ts, start_frame, \n",
    "                    end_frame, frame_rate)\n",
    "                VALUES ('{supabase_key}', '{row.mediaFolderPath}', 'video', 'clip', \n",
    "                    {file_size}, {library_id}, '{json.dumps(row.to_dict())}', '{hash}', \n",
    "                    {parent_id}, {start_ts}, {end_ts}, {start_frame}, \n",
    "                    {end_frame}, {frame_rate})\n",
    "                ON CONFLICT (media_id) DO NOTHING;\n",
    "            \"\"\"\n",
    "            execute_write_query(_query)\n",
    "            \n",
    "            # upload to supabase s3\n",
    "            supabase.storage.from_('rts').upload(supabase_key, os.path.abspath(filename))\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        error_count += 1\n",
    "        continue\n",
    "\n",
    "print(f\"No clips folund for {error_count} rows\")\n",
    "print(f\"Total number of clips: {no_clips}\")\n",
    "print(f\"Total number of vidoes with clips: {len(df) - error_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/rts/5/1/0/ZE004015'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.mediaFolderPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/media/data/rts/archive/1/2/0/ZB187021/clips/videos',\n",
       " '/mnt/rts/1/2/0/ZB187021',\n",
       " ['ZB023013-L010.mp4',\n",
       "  'ZB023013-L009.mp4',\n",
       "  'ZB023013-L000.mp4',\n",
       "  'ZB023013-L023.mp4',\n",
       "  'ZB023013-L017.mp4',\n",
       "  'ZB023013-L024.mp4',\n",
       "  'ZB023013-L012.mp4',\n",
       "  'ZB023013-L018.mp4',\n",
       "  'ZB023013-L014.mp4',\n",
       "  'ZB023013-L015.mp4',\n",
       "  'ZB023013-L032.mp4',\n",
       "  'ZB023013-L004.mp4',\n",
       "  'ZB023013-L033.mp4',\n",
       "  'ZB023013-L001.mp4',\n",
       "  'ZB023013-L011.mp4',\n",
       "  'ZB023013-L028.mp4',\n",
       "  'ZB023013-L025.mp4',\n",
       "  'ZB023013-L031.mp4',\n",
       "  'ZB023013-L022.mp4',\n",
       "  'ZB023013-L013.mp4',\n",
       "  'ZB023013-L021.mp4',\n",
       "  'ZB023013-L016.mp4',\n",
       "  'ZB023013-L034.mp4',\n",
       "  'ZB023013-L019.mp4',\n",
       "  'ZB023013-L005.mp4',\n",
       "  'ZB023013-L002.mp4',\n",
       "  'ZB023013-L020.mp4',\n",
       "  'ZB023013-L027.mp4',\n",
       "  'ZB023013-L029.mp4',\n",
       "  'ZB023013-L030.mp4',\n",
       "  'ZB023013-L006.mp4',\n",
       "  'ZB023013-L008.mp4',\n",
       "  'ZB023013-L007.mp4',\n",
       "  'ZB023013-L003.mp4',\n",
       "  'ZB023013-L026.mp4'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path, row['mediaFolderPath'], files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
