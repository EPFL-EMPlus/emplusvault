{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Examples \n",
    "\n",
    "Examples for the new database schema and how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /home/andre/rts/.venv/lib/python3.10/site-packages (2.9.6)\n",
      "Requirement already satisfied: python-dotenv in /home/andre/rts/.venv/lib/python3.10/site-packages (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install psycopg2-binary python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andre/rts\n"
     ]
    }
   ],
   "source": [
    "# jupyter notebook auto reload\n",
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Utility functions for setting up the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "from rts.db.utils import execute_read_query, execute_write_query\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables\n",
    "\n",
    "Creating the necessary database tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_write_query(\"DROP TABLE IF EXISTS features;\")\n",
    "execute_write_query(\"DROP TABLE IF EXISTS media;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# postgres table definitions\n",
    "\n",
    "_table_media = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS media (\n",
    "        media_id SERIAL PRIMARY KEY,\n",
    "        media_path VARCHAR(500) UNIQUE,\n",
    "        original_path VARCHAR(500) NOT NULL,\n",
    "        created_at TIMESTAMP DEFAULT NOW(),\n",
    "        media_type VARCHAR(50) NOT NULL,\n",
    "        sub_type VARCHAR(50) NOT NULL,\n",
    "        size INTEGER NOT NULL,\n",
    "        archive_name VARCHAR (50) NOT NULL,\n",
    "        archive_id VARCHAR (50) NOT NULL,\n",
    "        metadata JSONB NOT NULL\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "_table_features = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS features (\n",
    "        feature_id SERIAL PRIMARY KEY,\n",
    "        feature_type VARCHAR(50) NOT NULL,\n",
    "        version VARCHAR(20) NOT NULL,\n",
    "        created_at TIMESTAMP DEFAULT NOW(),\n",
    "        model_name VARCHAR(200) NOT NULL,\n",
    "        model_params JSONB NOT NULL,\n",
    "        data JSONB NOT NULL,\n",
    "\n",
    "        embedding_size INTEGER,\n",
    "        embedding_1024 vector (1024),\n",
    "        embedding_2048 vector (2048),\n",
    "\n",
    "        media_id INTEGER,\n",
    "\n",
    "        CONSTRAINT FK_features_media_id FOREIGN KEY (media_id) \n",
    "            REFERENCES media (media_id)\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "execute_write_query(_table_media)\n",
    "execute_write_query(_table_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill tables with sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sample data for the tables, each media element can have multiple features\n",
    "\n",
    "swiss_cities = [\"Zurich\", \"Geneva\", \"Basel\", \"Lausanne\", \"Bern\", \"Winterthur\", \"Lucerne\", \"St. Gallen\", \"Lugano\", \"Biel/Bienne\"]\n",
    "years = [2015, 2016, 2017, 2018, 2019, 2020]\n",
    "\n",
    "for i in range(1, 21):\n",
    "    _table_media_sample = f\"\"\"\n",
    "        INSERT INTO media (media_path, original_path, media_type, sub_type, size, archive_name, archive_id, metadata)\n",
    "        VALUES \n",
    "            ('/path/to/media{i}', '/path/to/original{i}', 'image', 'jpg', 500, 'archive{i}', 'archive_id{i}', '{{\"key{i}\": \"value{i}\", \"city\": \"{swiss_cities[(i-1) % len(swiss_cities)]}\", \"year\": {years[(i-1) % len(years)]}}}')\n",
    "        RETURNING media_id;\n",
    "    \"\"\"\n",
    "    execute_write_query(_table_media_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  '/path/to/media1',\n",
       "  '/path/to/original1',\n",
       "  datetime.datetime(2023, 4, 28, 13, 0, 0, 700233),\n",
       "  'image',\n",
       "  'jpg',\n",
       "  500,\n",
       "  'archive1',\n",
       "  'archive_id1',\n",
       "  {'city': 'Zurich', 'key1': 'value1', 'year': 2015}),\n",
       " (2,\n",
       "  '/path/to/media2',\n",
       "  '/path/to/original2',\n",
       "  datetime.datetime(2023, 4, 28, 13, 0, 0, 738503),\n",
       "  'image',\n",
       "  'jpg',\n",
       "  500,\n",
       "  'archive2',\n",
       "  'archive_id2',\n",
       "  {'city': 'Geneva', 'key2': 'value2', 'year': 2016})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_query = \"\"\"SELECT * FROM media LIMIT 2;\"\"\"\n",
    "execute_read_query(_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert some samples with vectors\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "feature_types = [\"pose\", \"face\", \"object\", \"ner\"]\n",
    "color_meta = [\"red\", \"green\", \"blue\", \"yellow\", \"black\", \"white\", \"grey\", \"orange\", \"purple\", \"pink\"]\n",
    "\n",
    "for i in range(1, 11):\n",
    "    vector_1024 = np.random.rand(1024).tolist()\n",
    "    vector_2048 = np.random.rand(2048).tolist()\n",
    "    ner_tags = json.dumps([(\"person\", \"Ueli Steck\", 1, 9), (\"city\", \"geneva\", 10, 16), (\"city\", \"zurich\", 17, 23), (\"city\", \"bern\", 24, 28), (\"city\", \"basel\", 29, 34), (\"city\", \"winterthur\", 35, 46), (\"city\", \"lucerne\", 47, 54), (\"city\", \"st. gallen\", 55, 65), (\"city\", \"lugano\", 66, 72), (\"city\", \"biel/bienne\", 73, 85)])\n",
    "\n",
    "    _table_features_sample_vectors = f\"\"\"\n",
    "        INSERT INTO features (feature_type, version, model_name, model_params, data, media_id, embedding_size, embedding_1024)\n",
    "        VALUES\n",
    "            ('{feature_types[i % len(feature_types)]}', 'v1', 'resnet50', '{{\"param1\": \"{i}\"}}', '{{\"color\": \"{color_meta[i % len(color_meta)] }\", \"data1\": \"{i}\", \"ner\": {ner_tags} }}', {i}, 1024, ARRAY[{','.join([str(x) for x in vector_1024])}])\n",
    "        RETURNING feature_id;\n",
    "    \"\"\"\n",
    "    # print(_table_features_sample_vectors)\n",
    "    execute_write_query(_table_features_sample_vectors)\n",
    "\n",
    "    # At the moment we are only creating size 1024 vectors, for the sake of the next example queries to work, there can be only a single vector set per feature\n",
    "    # _table_features_sample_vectors = f\"\"\"\n",
    "    #     INSERT INTO features (feature_type, version, model_name, model_params, data, media_id, embedding_size, embedding_2048)\n",
    "    #     VALUES\n",
    "    #         ('image', 'v1', 'resnet50', '{{\"param1\": \"{i}\"}}', '{{\"data1\": \"{i}\"}}', {i}, 2048, ARRAY[{','.join([str(x) for x in vector_2048])}])\n",
    "    #     RETURNING feature_id;\n",
    "    # \"\"\"\n",
    "\n",
    "    # execute_write_query(_table_features_sample_vectors)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries\n",
    "\n",
    "### Scenario 1\n",
    "\n",
    "We have a media object and we want to find the 5 most similar media objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 12.7321838886941),\n",
       " (3, 12.8817617441207),\n",
       " (7, 12.9845741023454),\n",
       " (2, 13.0395603121536),\n",
       " (9, 13.0573006105726)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_query = \"\"\"\n",
    "    WITH target_embedding AS (\n",
    "    SELECT\n",
    "        media_id,\n",
    "        CASE\n",
    "            WHEN embedding_size = 1024 THEN embedding_1024\n",
    "            WHEN embedding_size = 2048 THEN embedding_2048\n",
    "            ELSE NULL\n",
    "        END AS embedding_vector\n",
    "    FROM \n",
    "        features\n",
    "    WHERE \n",
    "        media_id = 5\n",
    "    )\n",
    "\n",
    "    SELECT\n",
    "    f.media_id,\n",
    "    (target.embedding_vector <-> \n",
    "        CASE\n",
    "        WHEN f.embedding_size = 1024 THEN f.embedding_1024\n",
    "        WHEN f.embedding_size = 2048 THEN f.embedding_2048\n",
    "        ELSE NULL\n",
    "        END\n",
    "    ) AS distance\n",
    "    FROM\n",
    "    features f,\n",
    "    target_embedding target\n",
    "    WHERE\n",
    "    f.media_id != target.media_id\n",
    "    ORDER BY\n",
    "    distance ASC\n",
    "    LIMIT 5;\n",
    "\"\"\"\n",
    "\n",
    "execute_read_query(_query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2\n",
    "\n",
    "Find all media objects for Zurich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  '/path/to/media1',\n",
       "  '/path/to/original1',\n",
       "  datetime.datetime(2023, 4, 28, 13, 0, 0, 700233),\n",
       "  'image',\n",
       "  'jpg',\n",
       "  500,\n",
       "  'archive1',\n",
       "  'archive_id1',\n",
       "  {'city': 'Zurich', 'key1': 'value1', 'year': 2015}),\n",
       " (11,\n",
       "  '/path/to/media11',\n",
       "  '/path/to/original11',\n",
       "  datetime.datetime(2023, 4, 28, 13, 0, 1, 178896),\n",
       "  'image',\n",
       "  'jpg',\n",
       "  500,\n",
       "  'archive11',\n",
       "  'archive_id11',\n",
       "  {'city': 'Zurich', 'year': 2019, 'key11': 'value11'})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all media objects that have city: \"Zurich\" (queried from the jsonb metadata field)\n",
    "_query = \"\"\"\n",
    "    SELECT * FROM media WHERE metadata->>'city' = 'Zurich';\n",
    "\"\"\"\n",
    "execute_read_query(_query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 3\n",
    "\n",
    "Get all images from Geneva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2,\n",
       "  '/path/to/media2',\n",
       "  '/path/to/original2',\n",
       "  datetime.datetime(2023, 4, 28, 13, 0, 0, 738503),\n",
       "  'image',\n",
       "  'jpg',\n",
       "  500,\n",
       "  'archive2',\n",
       "  'archive_id2',\n",
       "  {'city': 'Geneva', 'key2': 'value2', 'year': 2016}),\n",
       " (12,\n",
       "  '/path/to/media12',\n",
       "  '/path/to/original12',\n",
       "  datetime.datetime(2023, 4, 28, 13, 0, 1, 229458),\n",
       "  'image',\n",
       "  'jpg',\n",
       "  500,\n",
       "  'archive12',\n",
       "  'archive_id12',\n",
       "  {'city': 'Geneva', 'year': 2020, 'key12': 'value12'})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_query = \"\"\"\n",
    "    SELECT * FROM media WHERE metadata->>'city' = 'Geneva' AND media_type = 'image';\n",
    "\"\"\"\n",
    "execute_read_query(_query)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 4\n",
    "\n",
    "Fulltext string matching on jsonb fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Basel', 'Bern', 'Biel/Bienne', 'Basel', 'Bern', 'Biel/Bienne']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['St. Gallen', 'St. Gallen']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query for cities that start with b\n",
    "_query = \"\"\"\n",
    "    SELECT * FROM media WHERE metadata->>'city' LIKE 'B%';\n",
    "\"\"\"\n",
    "print([x[9]['city'] for x in execute_read_query(_query)])\n",
    "\n",
    "_query = \"\"\"\n",
    "    SELECT * FROM media WHERE metadata->>'city' LIKE '%Gall%';\n",
    "\"\"\"\n",
    "[x[9]['city'] for x in execute_read_query(_query)]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 5\n",
    "\n",
    "Similarity to a computed vector. Example: we have a video camera installed and a user poses like a tennis player and we find tennis matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 12.7834132878445), (8, 13.2849294315309)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_1024 = \",\".join([str(x) for x in np.random.rand(1024).tolist()])  # feature that would be creating by the pose detection algorithm\n",
    "\n",
    "# query the feature table for similar vectors\n",
    "_query = f\"\"\"\n",
    "    SELECT\n",
    "    f.media_id,\n",
    "    ('[{vector_1024}]' <-> \n",
    "        CASE\n",
    "        WHEN f.embedding_size = 1024 THEN f.embedding_1024\n",
    "        WHEN f.embedding_size = 2048 THEN f.embedding_2048\n",
    "        ELSE NULL\n",
    "        END\n",
    "    ) AS distance\n",
    "    FROM\n",
    "    features f\n",
    "    WHERE\n",
    "    f.feature_type = 'pose'\n",
    "    ORDER BY\n",
    "    distance ASC\n",
    "    LIMIT 5;\n",
    "\"\"\"\n",
    "\n",
    "execute_read_query(_query)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 6\n",
    "\n",
    "Find people or locations with ner tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'green',\n",
       "   'data1': '1'}),\n",
       " (2,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'blue',\n",
       "   'data1': '2'}),\n",
       " (3,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'yellow',\n",
       "   'data1': '3'}),\n",
       " (4,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'black',\n",
       "   'data1': '4'}),\n",
       " (5,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'white',\n",
       "   'data1': '5'}),\n",
       " (6,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'grey',\n",
       "   'data1': '6'}),\n",
       " (7,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'orange',\n",
       "   'data1': '7'}),\n",
       " (8,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'purple',\n",
       "   'data1': '8'}),\n",
       " (9,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'pink',\n",
       "   'data1': '9'}),\n",
       " (10,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'red',\n",
       "   'data1': '10'})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person = \"Ueli Steck\"\n",
    "\n",
    "_query = f\"\"\"\n",
    "    SELECT media_id, data FROM features WHERE data->>'ner' LIKE '%{person}%';\n",
    "\"\"\"\n",
    "\n",
    "execute_read_query(_query)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 7\n",
    "\n",
    "Find aribitrary features by metadata (here we use the simple field color as an example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10,\n",
       "  {'ner': [['person', 'Ueli Steck', 1, 9],\n",
       "    ['city', 'geneva', 10, 16],\n",
       "    ['city', 'zurich', 17, 23],\n",
       "    ['city', 'bern', 24, 28],\n",
       "    ['city', 'basel', 29, 34],\n",
       "    ['city', 'winterthur', 35, 46],\n",
       "    ['city', 'lucerne', 47, 54],\n",
       "    ['city', 'st. gallen', 55, 65],\n",
       "    ['city', 'lugano', 66, 72],\n",
       "    ['city', 'biel/bienne', 73, 85]],\n",
       "   'color': 'red',\n",
       "   'data1': '10'})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color = \"red\"\n",
    "\n",
    "_query = f\"\"\"\n",
    "    SELECT media_id, data FROM features WHERE data->>'color' = '{color}';\n",
    "\"\"\"\n",
    "\n",
    "execute_read_query(_query)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest the clips to the media table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOTE_RTS_DATA = \"/media/sinergia/RTS/\"\n",
    "REMOTE_VIDEOS = '/mnt/rts/'\n",
    "\n",
    "LOCAL_RTS_DATA = \"/media/data/rts/\"\n",
    "METADATA = LOCAL_RTS_DATA + 'metadata'\n",
    "LOCAL_VIDEOS = LOCAL_RTS_DATA + 'archive'\n",
    "\n",
    "AIBOX = LOCAL_RTS_DATA + 'aibox-vectors'\n",
    "\n",
    "OUTDIR = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import orjson\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "import io\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from supabase import create_client, Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/rts/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# LOCAL imports\n",
    "import rts\n",
    "import rts.pipeline\n",
    "import rts.utils\n",
    "import rts.io.media\n",
    "import rts.features.audio\n",
    "import rts.features.text\n",
    "\n",
    "LOG = rts.utils.get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "supabase: Client = create_client(\n",
    "    os.getenv(\"SUPABASE_HOST\"), \n",
    "    os.getenv(\"SUPABASE_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "StorageException",
     "evalue": "{'statusCode': 400, 'error': 'invalid signature', 'message': 'invalid signature'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/rts/.venv/lib/python3.10/site-packages/storage3/_sync/bucket.py:28\u001b[0m, in \u001b[0;36mSyncStorageBucketAPI._request\u001b[0;34m(self, method, url, json)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 28\u001b[0m     response\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m     29\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError:\n",
      "File \u001b[0;32m~/rts/.venv/lib/python3.10/site-packages/httpx/_models.py:749\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    748\u001b[0m message \u001b[39m=\u001b[39m message\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m, error_type\u001b[39m=\u001b[39merror_type)\n\u001b[0;32m--> 749\u001b[0m \u001b[39mraise\u001b[39;00m HTTPStatusError(message, request\u001b[39m=\u001b[39mrequest, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '400 Bad Request' for url 'http://localhost:8000/storage/v1/bucket'\nFor more information check: https://httpstatuses.com/400",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mStorageException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrts\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m res \u001b[39m=\u001b[39m supabase\u001b[39m.\u001b[39;49mstorage\u001b[39m.\u001b[39;49mcreate_bucket(name)\n",
      "File \u001b[0;32m~/rts/.venv/lib/python3.10/site-packages/storage3/_sync/bucket.py:68\u001b[0m, in \u001b[0;36mSyncStorageBucketAPI.create_bucket\u001b[0;34m(self, id, name, public)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_bucket\u001b[39m(\n\u001b[1;32m     55\u001b[0m     \u001b[39mself\u001b[39m, \u001b[39mid\u001b[39m: \u001b[39mstr\u001b[39m, name: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, public: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     56\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m     57\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Creates a new storage bucket.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m        Whether the bucket you are creating should be publicly accessible. Defaults to False.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m     69\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     70\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/bucket\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     71\u001b[0m         json\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mid\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m\"\u001b[39;49m: name \u001b[39mor\u001b[39;49;00m \u001b[39mid\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mpublic\u001b[39;49m\u001b[39m\"\u001b[39;49m: public},\n\u001b[1;32m     72\u001b[0m     )\n\u001b[1;32m     73\u001b[0m     \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/rts/.venv/lib/python3.10/site-packages/storage3/_sync/bucket.py:30\u001b[0m, in \u001b[0;36mSyncStorageBucketAPI._request\u001b[0;34m(self, method, url, json)\u001b[0m\n\u001b[1;32m     28\u001b[0m     response\u001b[39m.\u001b[39mraise_for_status()\n\u001b[1;32m     29\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError:\n\u001b[0;32m---> 30\u001b[0m     \u001b[39mraise\u001b[39;00m StorageException(\n\u001b[1;32m     31\u001b[0m         {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresponse\u001b[39m.\u001b[39mjson(), \u001b[39m\"\u001b[39m\u001b[39mstatusCode\u001b[39m\u001b[39m\"\u001b[39m: response\u001b[39m.\u001b[39mstatus_code}\n\u001b[1;32m     32\u001b[0m     )\n\u001b[1;32m     34\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "\u001b[0;31mStorageException\u001b[0m: {'statusCode': 400, 'error': 'invalid signature', 'message': 'invalid signature'}"
     ]
    }
   ],
   "source": [
    "name = \"rts\"\n",
    "res = supabase.storage.create_bucket(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3177, 22)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = rts.utils.dataframe_from_hdf5(LOCAL_RTS_DATA + '/metadata', 'rts_aivectors')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2248, 5012)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the clips from the archive and put them into supabase s3. At the same time create the database entries on the media table\n",
    "\n",
    "error_count = 0\n",
    "no_clips = 0\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "\n",
    "    path = os.path.join(row.mediaFolderPath.replace(REMOTE_VIDEOS, LOCAL_VIDEOS + '/'), 'clips', 'videos')\n",
    "\n",
    "    # get all files in the folder\n",
    "    try:\n",
    "        files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "        no_clips += len(files)\n",
    "    except FileNotFoundError:\n",
    "        error_count += 1\n",
    "        continue\n",
    "\n",
    "error_count, no_clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/media/data/rts/archive/1/2/0/ZB187021/clips/videos',\n",
       " '/mnt/rts/1/2/0/ZB187021',\n",
       " ['ZB023013-L010.mp4',\n",
       "  'ZB023013-L009.mp4',\n",
       "  'ZB023013-L000.mp4',\n",
       "  'ZB023013-L023.mp4',\n",
       "  'ZB023013-L017.mp4',\n",
       "  'ZB023013-L024.mp4',\n",
       "  'ZB023013-L012.mp4',\n",
       "  'ZB023013-L018.mp4',\n",
       "  'ZB023013-L014.mp4',\n",
       "  'ZB023013-L015.mp4',\n",
       "  'ZB023013-L032.mp4',\n",
       "  'ZB023013-L004.mp4',\n",
       "  'ZB023013-L033.mp4',\n",
       "  'ZB023013-L001.mp4',\n",
       "  'ZB023013-L011.mp4',\n",
       "  'ZB023013-L028.mp4',\n",
       "  'ZB023013-L025.mp4',\n",
       "  'ZB023013-L031.mp4',\n",
       "  'ZB023013-L022.mp4',\n",
       "  'ZB023013-L013.mp4',\n",
       "  'ZB023013-L021.mp4',\n",
       "  'ZB023013-L016.mp4',\n",
       "  'ZB023013-L034.mp4',\n",
       "  'ZB023013-L019.mp4',\n",
       "  'ZB023013-L005.mp4',\n",
       "  'ZB023013-L002.mp4',\n",
       "  'ZB023013-L020.mp4',\n",
       "  'ZB023013-L027.mp4',\n",
       "  'ZB023013-L029.mp4',\n",
       "  'ZB023013-L030.mp4',\n",
       "  'ZB023013-L006.mp4',\n",
       "  'ZB023013-L008.mp4',\n",
       "  'ZB023013-L007.mp4',\n",
       "  'ZB023013-L003.mp4',\n",
       "  'ZB023013-L026.mp4'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path, row['mediaFolderPath'], files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:8000'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
