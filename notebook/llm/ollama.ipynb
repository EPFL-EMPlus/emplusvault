{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# LOCAL imports\n",
    "import emv\n",
    "import emv.utils\n",
    "import emv.io.media\n",
    "import emv.features.text\n",
    "import emv.llm.retriever\n",
    "import emv.db.queries\n",
    "\n",
    "\n",
    "from emv.db.dao import DataAccessObject\n",
    "DataAccessObject().set_user_id(3)\n",
    "\n",
    "LOG = emv.utils.get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m16:27:55 - LiteLLM:INFO\u001b[0m: Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Kirell Benzi is a renowned data artist and researcher known for his innovative work in the field of data visualization. He was born on March 3, 1990, in France. Benzi has a background in both art and science, holding a degree in Applied Mathematics from the University of Paris-Sud and a Master\\'s degree in Interactive Design and Digital Animation from the Ensci Les Ateliers.\\n\\nBenzi gained significant attention in 2015 when he created \"The Wave,\" a mesmerizing data visualization of the world\\'s stock exchanges, which was later featured in The New Yorker. In this project, Benzi employed a novel technique called \"Flow Maps\" to illustrate complex financial data in an engaging and intuitive manner.\\n\\nIn addition to his work as a data artist, Benzi is also a researcher at the Swiss Data Science Center, where he focuses on developing new methods for visualizing and interpreting large datasets. He has published numerous papers on these topics and frequently shares his insights through talks and workshops at conferences around the world.\\n\\nBenzi\\'s work has been recognized with various awards and accolades, including a Webby Award and an honorable mention from the Visually Impactful Dataviz category in the Kantar Information Is Beautiful Awards. His TEDx talk on \"The Art of Data\" is also widely popular, offering insights into his creative process and the potential of data visualization as a tool for understanding our world.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import litellm\n",
    "from litellm import completion\n",
    "\n",
    "litellm.set_verbose=False\n",
    "\n",
    "response = completion(\n",
    "            model=\"ollama/mixtral:8x7b-instruct-v0.1-fp16\", \n",
    "            messages = [{ \"content\": \"Tell me about Kirell Benzi\",\"role\": \"user\"}], \n",
    "            api_base=\"http://192.168.1.42:11434\"\n",
    ")\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'>Do you want a joke or a poem? A<span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> joke</span>.\n",
       "Okay, here is a one-liner:<span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> &quot;</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>Why</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> don</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>&#x27;t</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> scientists</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> trust</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> atoms</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>?</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Because</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> they</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> make</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> up</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> everything</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>!</span>&quot;\n",
       "</pre>"
      ],
      "text/plain": [
       "<guidance.models._lite_llm.LiteLLMCompletion at 0x7fd452067910>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from guidance import models, gen, select\n",
    "llm = models.LiteLLMCompletion(api_base=\"http://192.168.1.42:11434\", model='ollama/mixtral:8x7b-instruct-v0.1-fp16') \n",
    "\n",
    "# append text or generations to the model\n",
    "llm + f'''\\\n",
    "Do you want a joke or a poem? A {select(['joke', 'poem'])}.\n",
    "Okay, here is a one-liner: \"{gen(stop='\"')}\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = emv.llm.retriever.DocumentRetriever()\n",
    "retriever.fetch_similar(\"La Stratégie Energétique 2050 en Suisse a, entre autres, pour objectif d’accroître drastiquement le nombre d’installations solaires photovoltaïques. Au moins 35 TWh d'électricité devront être produits en 2035 grâce aux énergies renouvelables, sans compter l’hydraulique, et 45 TWh en 2050. Comment atteindre ces objectifs d’une manière efficace et équitable pour chaque ville et/ou commune suisse ?\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import Ollama\n",
    "from llama_index.llms import ChatMessage\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(base_url=\"http://192.168.1.42:11434\", model=\"mistral\", request_timeout=30.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a developer with a colorful personality\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What is my name\"),\n",
    "]\n",
    "resp = llm.stream_chat(messages)\n",
    "\n",
    "for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import make_url\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import psycopg2\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "# Get the environment variables\n",
    "db_host = os.getenv('DB_HOST')\n",
    "db_port = os.getenv('DB_PORT')\n",
    "db_name = os.getenv('DB_NAME')\n",
    "db_user = os.getenv('DB_USER')\n",
    "db_password = os.getenv('DB_PASSWORD')\n",
    "\n",
    "# Construct the connection string\n",
    "connection_string = f\"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    "url = make_url(connection_string)\n",
    "\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database=db_name,\n",
    "    host=url.host,\n",
    "    password=url.password,\n",
    "    port=url.port,\n",
    "    user=url.username,\n",
    "    table_name=\"feature\",\n",
    "    embed_dim=1024,  # openai embedding dimension\n",
    ")\n",
    "\n",
    "# storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "# index = VectorStoreIndex.from_documents(\n",
    "#     documents, storage_context=storage_context, show_progress=True\n",
    "# )\n",
    "# query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core.bridge.pydantic import PrivateAttr\n",
    "# from llama_index.core.embeddings import BaseEmbedding\n",
    "\n",
    "# class LlamaIndexEmbeddings(BaseEmbedding):\n",
    "#     _model: emv.features.text.TextEmbedder = PrivateAttr()\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         **kwargs: Any,\n",
    "#     ) -> None:\n",
    "#         self._model = emv.features.text.TextEmbedder()\n",
    "#         super().__init__(**kwargs)\n",
    "\n",
    "#     @classmethod\n",
    "#     def class_name(cls) -> str:\n",
    "#         return \"LlamaIndexEmbeddings\"\n",
    "\n",
    "#     async def _aget_query_embedding(self, query: str) -> List[float]:\n",
    "#         return self._get_query_embedding(query)\n",
    "\n",
    "#     async def _aget_text_embedding(self, text: str) -> List[float]:\n",
    "#         return self._get_text_embedding(text)\n",
    "\n",
    "#     def _get_query_embedding(self, query: str) -> List[float]:\n",
    "#         embeddings = self._model.encode(query)\n",
    "#         return embeddings[0]\n",
    "\n",
    "#     def _get_text_embedding(self, text: str) -> List[float]:\n",
    "#         embeddings = self._model.encode(text)\n",
    "#         return embeddings[0]\n",
    "\n",
    "#     def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "#         embeddings = self._model.encode(texts)\n",
    "#         return embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emv-IgKv7S_O-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
