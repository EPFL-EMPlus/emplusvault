{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../..\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import folium\n",
    "from collections import Counter\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ast import literal_eval\n",
    "\n",
    "import litellm\n",
    "from litellm import completion\n",
    "litellm.set_verbose=False\n",
    "\n",
    "from emv.features.wikidata import get_wikidata_id, get_property, get_wikidata_label\n",
    "from emv.features.wikidata import process_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/rts_sample.csv\", \n",
    "                 sep = \"\\t\", \n",
    "                 converters = {\n",
    "                     \"data\": literal_eval,\n",
    "                     \"locations\": literal_eval,\n",
    "                     \"people\": literal_eval,\n",
    "                     \"orgs\": literal_eval,\n",
    "                     \"misc\": literal_eval\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"transcript\"] = df[\"data\"].map(lambda x: x.get(\"transcript\", []))\n",
    "df = df[df.transcript.map(lambda x: type(x) == list)].reset_index(drop=True) # Get full videos with speaker diarization info\n",
    "print(f\"Processed {len(df)} videos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_people = [\"messieurs\", \"monsieur\", \"madame\", \"mesdames\"]\n",
    "\n",
    "df[\"people\"] = df[\"people\"].apply(lambda x: [p for p in x if p.lower() not in filter_people])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = df[\"transcript\"].to_frame()\n",
    "persons[\"entities\"] = df.transcript.map(lambda x: [t.get(\"entities\", None) for t in x])\n",
    "persons[\"context\"] = df.transcript.map(lambda x: [t[\"t\"] for t in x])\n",
    "persons = persons.explode([\"entities\", \"context\"]).explode(\"entities\").reset_index(drop=True).dropna(subset = [\"entities\"])\n",
    "persons[\"entities\"] = persons.entities.map(lambda x: x[0] if x[1] == \"PER\" else None)\n",
    "persons = persons.dropna(subset = [\"entities\"]).reset_index(drop=True)\n",
    "persons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_persons = df[[\"people\", \"year\"]].explode(\"people\").dropna().groupby(\"people\").agg(list).reset_index()\n",
    "top_persons[\"count\"] = top_persons[\"year\"].apply(len)\n",
    "top_persons[\"year\"] = top_persons.year.map(lambda x: Counter(x))\n",
    "top_persons = top_persons.sort_values(\"count\", ascending=False)\n",
    "print(f\"Found {len(top_persons)} persons in the dataset.\")\n",
    "print(f\"Mean number of mentions per person: {top_persons['count'].mean():.2f} +/- {top_persons['count'].sem():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 50\n",
    "top_persons = top_persons[top_persons[\"count\"] > min_count]\n",
    "print(f\"Found {len(top_persons)} persons with more than {min_count} occurrences.\")\n",
    "top_persons.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_persons[\"wikidata_search\"] = top_persons[\"people\"].map(lambda x: get_wikidata_id(x, top_n = 10, delay = 1))\n",
    "top_persons = top_persons[top_persons[\"wikidata_search\"].map(lambda x: len(x) > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_persons = top_persons[top_persons[\"wikidata_search\"].map(lambda x: len(x) > 0)]\n",
    "top_persons[\"wikidata_candidates\"] = top_persons[\"wikidata_search\"].map(lambda x: [(c.get(\"id\"), c.get(\"description\")) for c in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_candidates = top_persons[[\"people\", \"wikidata_candidates\"]].to_dict(orient=\"records\")\n",
    "persons_candidates = {p[\"people\"]: p[\"wikidata_candidates\"] for p in persons_candidates}\n",
    "persons_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_query(named_entity, context, candidates):\n",
    "\n",
    "   query = f\"\"\"\n",
    "   I have a list of named entities and the context they have been extracted from. \n",
    "   I will provide you with pairs (named entity, context) as well as a list of possible candidates for those named entities. \n",
    "   Given the context, choose the best candidate. \n",
    "   Return ONLY the best candidate, without any additional information or context. DO NOT add any other words.\n",
    "   I repeat, return ONLY THE BEST CANDIDATE.\n",
    "\n",
    "   Named entity: {named_entity}\n",
    "   Context: {context}\n",
    "   Candidates: {candidates}\n",
    "   \"\"\"\n",
    "   \n",
    "   return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "test_persons = list(persons_candidates.keys())[:20]\n",
    "test_pairs = persons[persons.entities.map(lambda x: x in test_persons)].drop_duplicates(\"context\")[[\"entities\", \"context\"]].sample(500).to_dict(\"records\")\n",
    "print(f\"Testing on {len(test_pairs)} pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [build_query(\n",
    "            pair[\"entities\"], \n",
    "            pair[\"context\"], \n",
    "            persons_candidates[pair[\"entities\"]]\n",
    "            ) \n",
    "            for pair in test_pairs\n",
    "        ]\n",
    "\n",
    "print(f\"Built {len(queries)} queries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"ollama/mixtral:8x7b-instruct-v0.1-fp16\"\n",
    "api_base = \"http://192.168.1.42:11434\"\n",
    "\n",
    "pattern = r'\\bQ\\d+\\b'\n",
    "responses = []\n",
    "\n",
    "for query in queries:\n",
    "    response = completion(\n",
    "                model=model, \n",
    "                messages = [{ \"content\": query, \"role\": \"user\"}], \n",
    "                api_base=api_base\n",
    "    )\n",
    "    match_id = re.findall(pattern, response.choices[0].message.content)\n",
    "    if len(match_id) > 0:\n",
    "        responses.append(match_id[0])\n",
    "    else:\n",
    "        responses.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/disambiguation_results.json\", \"w\") as f:\n",
    "    json.dump({\"queries\": queries, \"responses\": responses}, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/disambiguation_results.json\", \"r\") as f:\n",
    "    responses = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = pd.DataFrame(responses)\n",
    "responses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses[\"entities\"] = responses.queries.map(lambda x: re.findall(r'Named entity: (.*)\\n', x)[0])\n",
    "responses[\"context\"] = responses.queries.map(lambda x: re.findall(r'Context: (.*)\\n', x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emv-requDRed-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
