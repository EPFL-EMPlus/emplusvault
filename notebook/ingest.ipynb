{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kikohs/work\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "RTS_DATA = \"/mnt/d/rts/\"\n",
    "METADATA = RTS_DATA + 'metadata'\n",
    "VIDEOS = RTS_DATA + '0'\n",
    "REMOTE_VIDEOS = \"/mnt/rts\"\n",
    "OUTDIR = 'data'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import meilisearch\n",
    "import orjson\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "import io\n",
    "from typing import Dict, List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL imports\n",
    "import rts\n",
    "from rts.ingest import read_video_folder_index\n",
    "\n",
    "LOG = rts.utils.get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidx = read_video_folder_index(os.path.join(OUTDIR, 'vidx.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meilisearch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m client \u001b[39m=\u001b[39m meilisearch\u001b[39m.\u001b[39mClient(\u001b[39m'\u001b[39m\u001b[39mhttp://localhost:7700\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m1234\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[39m# client.get_keys()\u001b[39;00m\n\u001b[1;32m      3\u001b[0m  \n\u001b[1;32m      4\u001b[0m \u001b[39m# int(datetime.now().timestamp())\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# client.create_index('books', {'primaryKey': 'reference_number'})\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'meilisearch' is not defined"
     ]
    }
   ],
   "source": [
    "client = meilisearch.Client('http://localhost:7700', '1234')\n",
    "# client.get_keys()\n",
    " \n",
    "# int(datetime.now().timestamp())\n",
    "# client.create_index('books', {'primaryKey': 'reference_number'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:RTS:list index out of range\n",
      "ERROR:RTS:list index out of range\n"
     ]
    }
   ],
   "source": [
    "def parse_item_sequences(data: Dict, media: Dict) -> Dict:\n",
    "    seqs = {}\n",
    "    for id in data.get('idSequence', []):\n",
    "        seq = {\n",
    "            'guid': media['guid'],\n",
    "            'mediaId': media['mediaId'],\n",
    "            'seqid': id,\n",
    "            'geo': [],\n",
    "            'mat': [],\n",
    "            'pp': []\n",
    "        }\n",
    "        seqs[seq['seqid']] = seq\n",
    "\n",
    "    geo = data.get('VisuelsGEOSequence', [])\n",
    "    for g in geo:\n",
    "        seqid, loc = g.split('@')\n",
    "        seqs[seqid]['geo'].append(loc.lower())\n",
    "\n",
    "    mat = data.get('VisuelsMATSequence', [])\n",
    "    for m in mat:\n",
    "        seqid, mat = m.split('@')\n",
    "        seqs[seqid]['mat'].append(mat.lower())\n",
    "    \n",
    "    pp = data.get('VisuelsPPSequence', [])\n",
    "    for p in pp:\n",
    "        seqid, name = p.split('@')\n",
    "        seqs[seqid]['pp'].append(name.lower())\n",
    "    \n",
    "    return seqs\n",
    "\n",
    "\n",
    "def parse_item(raw: Dict, vidx: Dict) -> Optional[Dict]:\n",
    "    def find_media_id(support: Dict) -> Tuple[Optional[int], Optional[str]]:\n",
    "        for i, d in enumerate(support):\n",
    "            if d.startswith('Z'):\n",
    "                return i, d\n",
    "        return 0, None\n",
    "\n",
    "    try:\n",
    "        d = raw['response']['docs'][0]\n",
    "    except IndexError as e:\n",
    "        LOG.error(e, raw)\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        seq_idx, media_id = find_media_id(d['idSupport'])\n",
    "    except KeyError as e:\n",
    "        # LOG.error(e)\n",
    "        return None\n",
    "    \n",
    "    if not media_id:\n",
    "        return None\n",
    "\n",
    "    duration = d['DureeMediaSec'][seq_idx]\n",
    "    ratio = d['RatioMedia'][seq_idx]\n",
    "    mediaFolderPath = vidx.get(media_id)\n",
    "\n",
    "    if not mediaFolderPath:\n",
    "        return None\n",
    "\n",
    "    media = {\n",
    "        'guid': d['Guid'],\n",
    "        'mediaId': media_id,\n",
    "        'mediaFolderPath': vidx.get(media_id),\n",
    "        'mediaDuration': duration,\n",
    "        'ratio': ratio,\n",
    "        'formatType': d['FormatMedia'][seq_idx],\n",
    "        'formatResolution': d['DefinitionMedia'][seq_idx],\n",
    "        'materialType': d['TypeMaterielMedia'][seq_idx],\n",
    "        'publishedDate': d.get('DatePublication'),\n",
    "        'publishedBy': d.get('CanalPublication'),\n",
    "\n",
    "        'rights': d.get('SemaphoreDroit'),\n",
    "        'categoryName': d.get('CategorieAsset'),\n",
    "        'assetType': d.get('TypeAsset'),\n",
    "        'contentType': d.get('TypeContenu'),\n",
    "        'backgoundType': d.get('idTypeBackground'),\n",
    "        'collection': d.get('Collection'),\n",
    "        \n",
    "        'title': d.get('Titre'),\n",
    "        'resume': d.get('Resume'),\n",
    "        'geoTheme': d.get('ThematiquesGEO'),\n",
    "        'resumeSequence': d.get('ResumeSequence'),\n",
    "        'created': int(datetime.now().timestamp()),\n",
    "        'published': int(datetime.strptime(d.get('DatePublication'), \"%Y-%m-%dT%H:%M:%S%z\").timestamp())\n",
    "    }\n",
    "\n",
    "    seqs = parse_item_sequences(d, media)\n",
    "    media['sequences'] = seqs\n",
    "\n",
    "    return media\n",
    "\n",
    "\n",
    "def read_txt_transcript(srtz: zipfile.Path, media: Dict) -> Optional[Dict]:\n",
    "    try:\n",
    "        ts = {\n",
    "            'guid': media['guid'],\n",
    "            'mediaId': media['mediaId'],\n",
    "            'version': 1,\n",
    "            'text': ''\n",
    "        }\n",
    "        path = media['guid'] + '_0.txt'\n",
    "        current = srtz.joinpath(path)\n",
    "        with current.open('r') as fp:\n",
    "            wrap = io.TextIOWrapper(fp, encoding='latin-1')\n",
    "            ts['text'] = wrap.read()\n",
    "    except Exception as e:\n",
    "        LOG.error('Read txt ts:', e)\n",
    "        return None\n",
    "    return ts\n",
    "\n",
    "\n",
    "def read_metadata_zippart(root_dir: str, part_num: int, vidx: Dict) -> Dict:\n",
    "    path = os.path.join(root_dir, f'{part_num}.zip')\n",
    "    medias = {}\n",
    "    with zipfile.ZipFile(path, 'r') as z:\n",
    "        jsons = zipfile.Path(z, f'{part_num}/jsonData/')\n",
    "        for j in jsons.iterdir():\n",
    "            with j.open('r') as fp:\n",
    "                js = orjson.loads(fp.read())\n",
    "                media = parse_item(js, vidx)\n",
    "                if media:\n",
    "                # ts = read_txt_transcript(srts, media)\n",
    "                # media['ts'] = ts\n",
    "                    medias[media['guid']] = media\n",
    "\n",
    "    return medias\n",
    "\n",
    "\n",
    "def read_all_metadata(root_dir: str, vidx: Dict) -> Dict:\n",
    "    all_d = dict()\n",
    "    for i in range(0, 10):\n",
    "        d = read_metadata_zippart(root_dir, i, vidx)\n",
    "        all_d.update(d)\n",
    "    \n",
    "    return all_d\n",
    "\n",
    "\n",
    "medias = read_all_metadata(METADATA, vidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522103"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(medias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/kikohs/work/rts/data/data.pickle', 'wb') as fp:\n",
    "    pickle.dump(medias, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = rts.utils.dict_from_pickle('/home/kikohs/work/rts/data/data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "# result = model.transcribe(\"audio.mp3\")\n",
    "# print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522103"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = m2.values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('rts-DIiCth0j-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3302d3dcc6e58bb01d2919129e3db2b24bfcd2253c5885c52ed63a4927bacf6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
