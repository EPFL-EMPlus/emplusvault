{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../..\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "import cv2\n",
    "from numba import jit\n",
    "from ast import literal_eval\n",
    "\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from hdbscan import HDBSCAN\n",
    "from umap import UMAP\n",
    "from umap.umap_ import nearest_neighbors\n",
    "\n",
    "from emv.features.pose import load_poses \n",
    "from emv.features.pose_utils import draw_pose, CONNECTIONS, KEYPOINTS_NAMES, ANGLES_ASSOCIATIONS\n",
    "from emv.features.pose_utils import compute_hips_angles, normalize_angles\n",
    "\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.layouts import layout, column, row\n",
    "from bokeh.models.widgets import Div\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import HoverTool, ColumnDataSource\n",
    "from bokeh import palettes\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_poses_path = \"data/sample_pose_df.csv\"\n",
    "pose_df = load_poses(local_poses_path, filter_poses={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_df = pose_df[pose_df.keypoints.map(lambda x: x[7][2] > 0.5 and x[8][2] > 0.5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_df[\"hips_angles\"] = pose_df.keypoints.map(lambda x: compute_hips_angles(x)[0])\n",
    "pose_df[\"hips_angles\"] = pose_df[\"hips_angles\"].map(lambda x: normalize_angles(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = pd.DataFrame(pose_df.angle_vec.tolist(), columns = ANGLES_ASSOCIATIONS.keys())\n",
    "\n",
    "default_angles = []\n",
    "for angle in ANGLES_ASSOCIATIONS.keys():\n",
    "    non_missing_angles = angles[angles[angle] != 0][angle]\n",
    "    default_angles.append(non_missing_angles.mean())\n",
    "    \n",
    "random_size = 0.0001\n",
    "pose_df[\"angle_vec\"] = pose_df.angle_vec.map(lambda x: [a if a != 0 else default_angles[i] + random.random() * random_size for i,a in enumerate(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directions(keypoints):\n",
    "    directions = []\n",
    "    for connection in CONNECTIONS:\n",
    "        kp1, kp2 = connection\n",
    "        x1, y1, c1 = keypoints[KEYPOINTS_NAMES.index(kp1)]\n",
    "        x2, y2, c2 = keypoints[KEYPOINTS_NAMES.index(kp2)]\n",
    "        directions.append((x2 - x1, y2 - y1))\n",
    "    directions = np.array(directions)\n",
    "    \n",
    "    return directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_df[\"directions\"] = pose_df.keypoints.apply(get_directions)\n",
    "pose_df[\"norm_directions\"] = pose_df.directions.apply(lambda x: x.flatten() / np.linalg.norm(x.flatten()))\n",
    "pose_df[\"feature_angle_dir\"] = pose_df.apply(lambda df: np.concatenate([df.norm_directions, df.angle_vec]), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying clusters of interesting poses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport = \"Weightlifting\"\n",
    "sport_poses = pose_df[pose_df.sport == sport]\n",
    "print(f\"Testing with {len(sport_poses)} poses from {sport}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing UMAP params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_umap_embeddings(features, n_neighbors, min_dist = 0.01, metric = \"cosine\"):\n",
    "\n",
    "    knn = nearest_neighbors(features, \n",
    "                            n_neighbors=np.max(n_neighbors), \n",
    "                            metric=metric,\n",
    "                            metric_kwds={},\n",
    "                            angular=False,\n",
    "                            random_state=None)\n",
    "    umap_embeddings = []\n",
    "    for n in n_neighbors:\n",
    "        reducer = umap.UMAP(n_neighbors=n, min_dist=min_dist, metric=metric, precomputed_knn=knn)\n",
    "        embeddings = reducer.fit_transform(features)\n",
    "        pairwise_d = pairwise_distances(embeddings, metric=\"euclidean\")\n",
    "        umap_embeddings.append({\"n_neighbors\": n, \"embedding\": embeddings, \"pairwise_d\": pairwise_d})\n",
    "        \n",
    "    return umap_embeddings\n",
    "        \n",
    "def plot_umap_embeddings(embeddings, d = 4, min_dist = 0.01):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=len(n_neighbors), figsize=(len(n_neighbors) * d, d))\n",
    "    for i, result in enumerate(embeddings):\n",
    "        coords = result[\"embedding\"]\n",
    "        axs[i].scatter(coords[:,0], coords[:,1], s=0.1)\n",
    "        axs[i].set_xticks([])\n",
    "        axs[i].set_yticks([])\n",
    "        axs[i].set_title(f\"n_neighbors = {result['n_neighbors']}\")\n",
    "        if i == 0:\n",
    "            axs[i].set_ylabel(f\"min_dist = {min_dist}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [50, 100, 500, 1000]\n",
    "\n",
    "human_angles_embeddings = compute_umap_embeddings(features = np.array(sport_poses[\"angle_vec\"].tolist()), \n",
    "                                                  n_neighbors = n_neighbors)\n",
    "hips_angles_embeddings = compute_umap_embeddings(features = np.array(sport_poses[\"hips_angles\"].tolist()), \n",
    "                                                 n_neighbors = n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_umap_embeddings(human_angles_embeddings)\n",
    "plot_umap_embeddings(hips_angles_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing HDBSCAN params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport = \"Rugby\"\n",
    "sport_poses = pose_df[pose_df.sport == sport]\n",
    "embeddings = UMAP(n_neighbors=500, min_dist=0.01, metric='cosine').fit_transform(sport_poses[\"angle_vec\"].tolist())\n",
    "sport_poses[\"umap_x\"] = embeddings[:,0]\n",
    "sport_poses[\"umap_y\"] = embeddings[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings = [x[\"embedding\"] for x in umap_embeddings if x[\"n_neighbors\"] == 500][0]\n",
    "\n",
    "# Test HDBSCAN parameters\n",
    "min_cluster_sizes = [5, 10, 15, 20]\n",
    "min_samples = [5, 10, 15, 20]\n",
    "\n",
    "hdbscan_clusterings = []\n",
    "fig, axs = plt.subplots(nrows=len(min_cluster_sizes), ncols=len(min_samples), figsize=(len(min_samples) * 3, len(min_cluster_sizes) * 3))\n",
    "for i, min_cluster_size in enumerate(min_cluster_sizes):\n",
    "    for j, min_sample in enumerate(min_samples):\n",
    "        hdbscan = HDBSCAN(min_cluster_size=min_cluster_size, min_samples=min_sample, allow_single_cluster=True)\n",
    "        hdbscan.fit(embeddings)\n",
    "        \n",
    "        sport_poses.loc[:,\"label\"] = hdbscan.labels_\n",
    "        sport_poses.loc[:,\"probability\"] = hdbscan.probabilities_\n",
    "        \n",
    "        hdbscan_clusterings.append({\"min_cluster_size\": min_cluster_size, \"min_sample\": min_sample, \"labels\": hdbscan.labels_, \"probabilities\": hdbscan.probabilities_})\n",
    "        \n",
    "        for label in sport_poses[\"label\"].unique():\n",
    "            axs[i,j].scatter(sport_poses[sport_poses.label == label][\"umap_x\"], \n",
    "                             sport_poses[sport_poses.label == label][\"umap_y\"], \n",
    "                             s=1, label=label, alpha = sport_poses[sport_poses.label == label][\"probability\"].map(lambda x: np.clip(x, 0.1, 1)))\n",
    "        axs[i,j].set_xlabel(f\"Found {len(sport_poses['label'].unique())} clusters\", fontsize=10)\n",
    "        axs[i,j].set_xticks([])\n",
    "        axs[i,j].set_yticks([])\n",
    "        if j == 0:\n",
    "            axs[i,j].set_ylabel(f\"min_cluster_size = {min_cluster_size}\")\n",
    "        if i == 0:\n",
    "            axs[i,j].set_title(f\"min_samples = {min_sample}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_clusterings = pd.DataFrame(hdbscan_clusterings)\n",
    "hdbscan_clusterings[\"n_clusters\"] = hdbscan_clusterings.labels.map(lambda x: len(np.unique(x)))\n",
    "hdbscan_clusterings[\"mean_prob\"] = hdbscan_clusterings.probabilities.map(lambda x: np.mean(x))\n",
    "hdbscan_clusterings[\"std_prob\"] = hdbscan_clusterings.probabilities.map(lambda x: np.std(x))\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "sns.heatmap(hdbscan_clusterings.pivot(columns = \"min_cluster_size\", index = \"min_sample\", values = \"n_clusters\"), annot=True, fmt=\"d\", ax=axs[0])\n",
    "axs[0].set_title(\"Number of clusters\")\n",
    "sns.heatmap(hdbscan_clusterings.pivot(columns = \"min_cluster_size\", index = \"min_sample\", values = \"mean_prob\"), annot=True, ax=axs[1])\n",
    "axs[1].set_title(\"Mean probability\")\n",
    "sns.heatmap(hdbscan_clusterings.pivot(columns = \"min_cluster_size\", index = \"min_sample\", values = \"std_prob\"), annot=True, ax=axs[2])\n",
    "axs[2].set_title(\"Std probability\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By sport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_representative_poses(pose_df, sport, feature, reducer = UMAP(n_components=2, n_neighbors=1000, min_dist=0.1, metric=\"cosine\"), clusterer = DBSCAN(eps=0.2, min_samples=10)):\n",
    "    sport_poses = pose_df[pose_df.sport == sport]\n",
    "    \n",
    "    embeddings = reducer.fit_transform(sport_poses[feature].tolist())\n",
    "\n",
    "    sport_poses.loc[:,\"umap_x\"] = embeddings[:,0]\n",
    "    sport_poses.loc[:,\"umap_y\"] = embeddings[:,1]\n",
    "    \n",
    "    clusterer.fit(embeddings)\n",
    "\n",
    "    sport_poses.loc[:,\"label\"] = clusterer.labels_\n",
    "    sport_poses.loc[:,\"probability\"] = clusterer.probabilities_\n",
    "    \n",
    "    p1 = figure(title=\"UMAP\", width=500, height=500)\n",
    "\n",
    "    palette = palettes.Turbo256\n",
    "    labels = sport_poses[\"label\"].unique()\n",
    "    label_colors = {label:palette[int(256 * (label + 1) / (len(labels) + 1))] for label in labels}\n",
    "\n",
    "    representative_poses = []\n",
    "    for label in labels:\n",
    "        p1.scatter(sport_poses[sport_poses.label == label][\"umap_x\"], sport_poses[sport_poses.label == label][\"umap_y\"], \n",
    "                alpha = sport_poses[sport_poses.label == label][\"probability\"].map(lambda x: np.clip(x, 0.1, 1)),\n",
    "                color = label_colors[label], size = 1)\n",
    "        if label != -1:\n",
    "            representative_pose = sport_poses.iloc[np.argmin(np.linalg.norm(sport_poses[[\"umap_x\", \"umap_y\"]].values - sport_poses[sport_poses.label == label][[\"umap_x\", \"umap_y\"]].mean().values, axis=1))]\n",
    "            representative_poses.append(representative_pose)\n",
    "            \n",
    "    representative_poses = pd.concat([p.to_frame().T for p in representative_poses])      \n",
    "    p1.scatter(\"umap_x\", \"umap_y\", color=\"red\", alpha = 1, size=12, marker = \"x\", source = ColumnDataSource(representative_poses))\n",
    "    \n",
    "    # Hover info for the representative poses cluster label\n",
    "    hover = HoverTool(tooltips=[(\"Cluster\", \"@label\")])\n",
    "    p1.add_tools(hover)\n",
    "\n",
    "    p2 = figure(title=f\"Items not assigned: {len(sport_poses[sport_poses.label == -1])}\", width=700, height=250)\n",
    "    p2.vbar(x=sport_poses[sport_poses.label != -1].label.value_counts().index, top=sport_poses[sport_poses.label != -1].label.value_counts().values, width=0.9, color = \"blue\")\n",
    "    p2.xaxis.ticker = sport_poses[sport_poses.label != -1].label.value_counts().index\n",
    "\n",
    "    p3 = figure(title=\"Mean probability per cluster\", width=700, height=250)\n",
    "    mean_probs = sport_poses[sport_poses.label != -1].groupby(\"label\").probability.mean()\n",
    "    mean_stds = sport_poses[sport_poses.label != -1].groupby(\"label\").probability.std()\n",
    "    p3.circle(mean_probs.index, mean_probs.values, size=10, color=\"blue\", alpha=0.5)\n",
    "    err = list(zip((mean_probs - mean_stds).values, (mean_probs + mean_stds).values))\n",
    "    p3.multi_line(list(zip(mean_probs.index, mean_probs.index)), err, color='blue')\n",
    "    p3.xaxis.ticker = sport_poses[sport_poses.label != -1].label.value_counts().index\n",
    "\n",
    "    title = Div(text=f\"<h1>Representative poses for {sport}</h1>\")\n",
    "    layout = column([title, row([p1, column(p2, p3)])])\n",
    "    show(layout)\n",
    "    \n",
    "    return representative_poses, sport_poses\n",
    "\n",
    "def plot_representative_poses(representative_poses, ncols = 6):\n",
    "    nrows = np.ceil(len(representative_poses) / ncols).astype(int)\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols * 3, nrows * 3))\n",
    "    axs = axs.flatten()\n",
    "    for i, pose in enumerate(representative_poses):\n",
    "        draw_pose(pose, ax = axs[i], cut = True, show_frame=True)\n",
    "        axs[i].set_title(pose[\"label\"])\n",
    "    [ax.set_axis_off() for ax in axs[i+1:]]\n",
    "    fig.suptitle(f\"Representative poses for {sport}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_clusters(sport_poses, save = False):\n",
    "    clusters = sorted(sport_poses.label.unique())\n",
    "    ncols = 6\n",
    "    nrows = len(clusters) - 1\n",
    "    \n",
    "    sport_poses[\"distance_to_cluster_centre\"] = sport_poses.apply(lambda x: np.linalg.norm(x[[\"umap_x\", \"umap_y\"]] - sport_poses[sport_poses.label == x.label][[\"umap_x\", \"umap_y\"]].mean().values), axis=1)\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols * 3, nrows * 3))\n",
    "    axs = axs.flatten()\n",
    "    for k in clusters:\n",
    "        if k == -1:\n",
    "            continue\n",
    "        sample_poses = sport_poses[sport_poses.label == k].sort_values(\"distance_to_cluster_centre\").head(ncols).reset_index(drop=True)\n",
    "        for j, pose in sample_poses.iterrows():\n",
    "            draw_pose(pose, ax = axs[k * ncols + j], cut = True, show_frame=True)\n",
    "            axs[k * ncols + j].set_title(pose[\"label\"])\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(f\"data/ioc_clusters/clusters_{sport}.png\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_df_clustered = pd.DataFrame()\n",
    "representative_poses_per_sport = []\n",
    "for sport in pose_df.sport.unique():\n",
    "    print(f\"Testing with {sport}\")\n",
    "    representative_poses, sport_poses = get_representative_poses(pose_df = pose_df,\n",
    "                                                             sport = sport, \n",
    "                                                             feature = \"angle_vec\",\n",
    "                                                             reducer = UMAP(n_components=2, n_neighbors=500, min_dist=0.01, metric=\"cosine\"), \n",
    "                                                             clusterer = HDBSCAN(min_cluster_size=50, min_samples=50))\n",
    "    pose_df_clustered = pd.concat([pose_df_clustered, sport_poses])\n",
    "    representative_poses_per_sport.append({\"sport\": sport, \"representative_poses\": representative_poses})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = sorted(sport_poses.label.unique())\n",
    "ncols = 2\n",
    "nrows = np.ceil((len(clusters) - 1) / ncols).astype(int)\n",
    "\n",
    "spread_threshold = 0.1\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols * 6, nrows * 2))\n",
    "axs = axs.flatten()\n",
    "for k in clusters:\n",
    "    if k == -1:\n",
    "        continue\n",
    "    angles = pd.DataFrame(sport_poses[sport_poses.label == k].angle_vec.tolist(), columns = ANGLES_ASSOCIATIONS.keys())\n",
    "    for j,angle in enumerate(angles.columns):\n",
    "        mean_angle = angles[angle].mean()\n",
    "        std_angle = angles[angle].std()\n",
    "        axs[k].errorbar(j, mean_angle, std_angle, fmt='o', color = \"black\" if std_angle < spread_threshold else \"red\")\n",
    "    axs[k].set_xticks(range(len(angles.columns)), angles.columns, rotation=0, fontsize = 6)\n",
    "    axs[k].set_title(f\"Cluster {k}\", fontsize = 10)\n",
    "[ax.set_axis_off() for ax in axs[k+1:]]\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sport in pose_df_clustered.sport.unique():\n",
    "    print(f\"Inspecting {sport}\")\n",
    "    inspect_clusters(pose_df_clustered[pose_df_clustered.sport == sport], save = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poses to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_df_clustered = pd.read_csv(\"data/sample_pose_df_clustered.csv\", converters={\"keypoints\": literal_eval, \"angle_vec\": literal_eval, \"angle_vec\": literal_eval, \"bbox\": literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_to_keep = {\n",
    "    'Archery':[0, 1, 2, 3, 10, 11, 14], \n",
    "    'Athletics':[1, 5, 9, 10, 11, 16, 17, 18, 20, 23], \n",
    "    'Badminton':[32, 33, 45, 47], \n",
    "    'Baseball':[0, 1, 2, 3, 4, 5, 6, 11, 23], \n",
    "    'Basketball':[5, 6, 8, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 26, 27, 28, 29],\n",
    "    'Boxing':[2, 3, 4, 6, 16, 17], \n",
    "    'Canoeing':[], # No interesting clusters\n",
    "    'Cycling':[0, 6, 7, 18, 19, 20, 21, 22, 23, 24, 25], \n",
    "    'Diving':[0, 1, 3, 4, 19, 25, 26], \n",
    "    'Fencing':[1, 2, 7, 8, 10], \n",
    "    'Football':[0, 1, 2, 3, 4, 5, 6, 7, 8], # All clusters but poses are not actually interesting\n",
    "    'Golf':[0, 3, 4, 8, 9, 11, 12, 15, 16, 17, 18], \n",
    "    'Judo':[3, 12, 15, 20], \n",
    "    'Rowing':[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 15, 17, 18], \n",
    "    'Sailing':[2, 10, 32, 33, 36], \n",
    "    'Shooting':[11, 13, 32], \n",
    "    'Sport Climbing':[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 18, 19],\n",
    "    'Surfing':[6], \n",
    "    'Swimming':[0], \n",
    "    'Table Tennis':[8, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 25, 26, 32, 33], \n",
    "    'Taekwondo':[], # No interesting clusters / Not working\n",
    "    'Tennis':[1, 2, 6, 21, 25],\n",
    "    'Weightlifting':[0, 1, 2, 15, 19, 20], \n",
    "    'Wrestling':[1, 6], \n",
    "    'Skateboarding':[8, 9, 14, 24, 27, 28, 29], \n",
    "    'Gymnastics':[0, 1, 2, 3, 4, 27],\n",
    "    'Equestrian':[15, 19, 20, 21, 29, 30, 31, 32, 33, 34, 38, 38, 39, 40] # Athletes on horse but poses are not actually interesting\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses_to_keep = pd.DataFrame()\n",
    "prop_poses_kept_per_sport = {}\n",
    "for sport, clusters in clusters_to_keep.items():\n",
    "    sport_poses = pose_df_clustered[pose_df_clustered.sport == sport]\n",
    "    sport_poses_to_keep = sport_poses[sport_poses.label.isin(clusters)]\n",
    "    poses_to_keep = pd.concat([poses_to_keep, sport_poses_to_keep])\n",
    "    prop_poses_kept_per_sport[sport] = len(sport_poses_to_keep) / len(sport_poses)\n",
    "\n",
    "print(f\"Keeping {len(poses_to_keep)} poses in total from {len(pose_df_clustered)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(range(len(prop_poses_kept_per_sport)), prop_poses_kept_per_sport.values())\n",
    "plt.xticks(range(len(prop_poses_kept_per_sport)), prop_poses_kept_per_sport.keys(), rotation=45)\n",
    "plt.title(\"Proportion of poses kept per sport\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_probs_means = poses_to_keep.groupby(\"sport\").probability.mean()\n",
    "clustering_probs_stds = poses_to_keep.groupby(\"sport\").probability.std()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.errorbar(clustering_probs_means.index, clustering_probs_means, clustering_probs_stds, fmt='o')\n",
    "plt.title(\"Mean probability of HDBSCAN clustering per sport\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses_to_keep[['guid', 'media_id', 'frame_number', 'sport', 'angle_score', 'keypoints', 'bbox', 'angle_vec']].to_csv(\"data/sample_poses_to_keep.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses_to_keep = pd.read_csv(\"data/sample_poses_to_keep.csv\", converters={\"keypoints\": literal_eval, \"bbox\": literal_eval, \"angle_vec\": literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [50, 100, 500, 1000]\n",
    "min_dist = 0.01\n",
    "metric = \"cosine\"\n",
    "feature = \"angle_vec\"\n",
    "\n",
    "features = np.array(poses_to_keep[feature].tolist())\n",
    "knn = nearest_neighbors(features, \n",
    "                        n_neighbors=np.max(n_neighbors), \n",
    "                        metric=metric,\n",
    "                        metric_kwds={},\n",
    "                        angular=False,\n",
    "                        random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_embeddings = []\n",
    "for n in n_neighbors:\n",
    "    reducer = umap.UMAP(n_neighbors=n, min_dist=min_dist, metric=metric, precomputed_knn=knn)\n",
    "    embeddings = reducer.fit_transform(features)\n",
    "    umap_embeddings.append({\"n_neighbors\": n, \"embedding\": embeddings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=len(n_neighbors), figsize=(len(n_neighbors) * 4, 4))\n",
    "for i, result in enumerate(umap_embeddings):\n",
    "    embeddings = result[\"embedding\"]\n",
    "    axs[i].scatter(embeddings[:,0], embeddings[:,1], s=0.01)\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "    axs[i].set_title(f\"n_neighbors = {result['n_neighbors']}\")\n",
    "    if i == 0:\n",
    "        axs[i].set_ylabel(f\"min_dist = {min_dist}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = [x[\"embedding\"] for x in umap_embeddings if x[\"n_neighbors\"] == 1000][0]\n",
    "poses_to_keep[\"umap_x\"] = embedding[:,0]\n",
    "poses_to_keep[\"umap_y\"] = embedding[:,1]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for sport in poses_to_keep.sport.unique():\n",
    "    sport_p = poses_to_keep[poses_to_keep.sport == sport]\n",
    "    plt.scatter(sport_p[\"umap_x\"], sport_p[\"umap_y\"], s=1, label=sport, alpha = 0.5)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = UMAP(n_neighbors=1000, min_dist=0.01, metric='cosine')\n",
    "embeddings = umap_model.fit_transform(poses_to_keep[\"angle_vec\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = palettes.Turbo256\n",
    "indices = np.linspace(0, len(palette) - 1, len(poses_to_keep.sport.unique()), dtype=int)\n",
    "palette = [palette[i] for i in indices]\n",
    "palette = {sport:color for sport,color in zip(poses_to_keep.sport.unique(), palette)}\n",
    "poses_to_keep[\"color\"] = poses_to_keep.sport.map(palette)\n",
    "\n",
    "data = ColumnDataSource(data={\"x\": embeddings[:,0], \"y\": embeddings[:,1], \"sport\": poses_to_keep.sport, \"color\": poses_to_keep.color})\n",
    "\n",
    "p = figure(title=\"UMAP\", width=800, height=800)\n",
    "p.scatter(\"x\", \"y\", color=\"color\", source=data, legend_group=\"sport\", alpha=0.5, size=1)\n",
    "hover = HoverTool(tooltips=[(\"Sport\", \"@sport\")])\n",
    "p.add_tools(hover)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rts-o0uzL038-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
