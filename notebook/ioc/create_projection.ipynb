{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a projection from the IOC data\n",
    "\n",
    "There a 3 components to a projection with the poses:\n",
    "1. Features from the feature table (Feature Table)\n",
    "2. A Projection (Projection table)\n",
    "3. Mappings of the coordinates to the projection and features (MapProjectionFeature Table)\n",
    "\n",
    "As the keypoints and angles are already provided in the associated feature data, the atlas is not needed to create the projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../..\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emv.db.dao import DataAccessObject\n",
    "from emv.db.queries import get_features_by_type_paginated, count_features_by_type\n",
    "from sqlalchemy.sql import text\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "from emv.api.models import Feature\n",
    "from emv.api.models import Projection, MapProjectionFeatureCreate\n",
    "from emv.db.queries import create_projection, create_map_projection_feature, create_feature, get_library_id_from_name, get_all_media_by_library_id, count_media_by_library_id, get_media_by_id\n",
    "from umap import UMAP\n",
    "import numba\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "#from emv.features.pose import load_poses \n",
    "from emv.client.get_content import get_features\n",
    "from emv.utils import dataframe_from_hdf5\n",
    "from emv.settings import DRIVE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(fastmath=True)\n",
    "def cylinder_euclidean_grad(x, y, cylinder_dimension=2*np.pi, linear_dimension=1.0):\n",
    "    \"\"\"Euclidean distance and gradient for cylindrical projection.\n",
    "\n",
    "    x, y: Points between which the distance and gradient are computed.\n",
    "    cylinder_dimension: The dimension of the cylindrical wraparound (default 2*pi).\n",
    "    linear_dimension: The linear dimension (default 1.0).\n",
    "    \"\"\"\n",
    "    distance_sqr = 0.0\n",
    "    g = np.zeros_like(x)\n",
    "    \n",
    "    # Cylindrical dimension (e.g., angular wraparound)\n",
    "    a = abs(x[0] - y[0])\n",
    "    if 2 * a < cylinder_dimension:\n",
    "        distance_sqr += a ** 2\n",
    "        g[0] = (x[0] - y[0])\n",
    "    else:\n",
    "        distance_sqr += (cylinder_dimension - a) ** 2\n",
    "        g[0] = (x[0] - y[0]) * (a - cylinder_dimension) / a\n",
    "    \n",
    "    # Linear dimension (e.g., height)\n",
    "    b = abs(x[1] - y[1])\n",
    "    distance_sqr += b ** 2\n",
    "    g[1] = (x[1] - y[1])\n",
    "    \n",
    "    distance = np.sqrt(distance_sqr)\n",
    "    return distance, g / (1e-6 + distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add filtered poses as new features to the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_poses_path = \"data/sample_poses_to_keep.csv\"\n",
    "pose_df = load_poses(access_point=\"LOCAL\", local_fp=local_poses_path, filter_poses={})\n",
    "pose_df[\"angle_vec\"] = pose_df.angle_vec_fix.map(lambda x: literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_df = pose_df[pose_df.keypoints.map(lambda x: x[7][2] > 0.5 and x[8][2] > 0.5)]\n",
    "print(pose_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centralize_and_scale_keypoints(keypoints, reference_points=['left_hip', 'right_hip'], target_diameter=1):\n",
    "\n",
    "    keypoint_names = [\n",
    "        'nose', 'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',\n",
    "        'left_wrist', 'right_wrist', 'left_hip', 'right_hip', 'left_knee', 'right_knee',\n",
    "        'left_ankle', 'right_ankle'\n",
    "    ]\n",
    "    keypoints = np.array(keypoints)\n",
    "\n",
    "    # Calculate the reference point (midpoint between hips)\n",
    "    left_hip = keypoints[keypoint_names.index(reference_points[0])]\n",
    "    right_hip = keypoints[keypoint_names.index(reference_points[1])]\n",
    "    center_point = (left_hip + right_hip) / 2\n",
    "\n",
    "    # Translate pose to center it at the origin\n",
    "    translated_keypoints = keypoints - center_point\n",
    "\n",
    "    # Determine the maximum distance from the center point to any keypoint\n",
    "    max_distance = np.max(np.linalg.norm(translated_keypoints, axis=1)) \n",
    "\n",
    "    # Calculate the scale factor to make the maximum distance equal to 0.5\n",
    "    scale_factor = 0.5 / max_distance\n",
    "\n",
    "    # Scale keypoints to have the target diameter\n",
    "    scaled_keypoints = translated_keypoints * scale_factor\n",
    "\n",
    "    return scaled_keypoints\n",
    "\n",
    "def get_angle_feature_vector(keypoints):\n",
    "    def calculate_angle(points):\n",
    "        assert len(\n",
    "            points) == 3, \"Three points are required to calculate the angles\"\n",
    "\n",
    "        hip1, hip2, ref = np.array(points)\n",
    "\n",
    "        if (hip1[0] == ref[0] and hip1[1] == ref[1]) or \\\n",
    "                (hip2[0] == ref[0] and hip2[1] == ref[1]) or \\\n",
    "                (hip1[0] == hip2[0] and hip1[1] == hip2[1]):\n",
    "            return np.nan, np.nan, np.nan\n",
    "\n",
    "        # Calculate the lengths of the sides of the triangle\n",
    "        a = np.linalg.norm(hip2 - ref)\n",
    "        b = np.linalg.norm(hip1 - ref)\n",
    "        c = np.linalg.norm(hip1 - hip2)\n",
    "\n",
    "        # Law of cosines to find the angles\n",
    "        angle_hip2_hip1_ref = np.degrees(\n",
    "            np.arccos((b**2 + c**2 - a**2) / (2 * b * c)))\n",
    "        angle_hip1_hip2_ref = np.degrees(\n",
    "            np.arccos((a**2 + c**2 - b**2) / (2 * a * c)))\n",
    "        angle_hip1_ref_hip2 = np.degrees(\n",
    "            np.arccos((a**2 + b**2 - c**2) / (2 * a * b)))\n",
    "\n",
    "        return angle_hip2_hip1_ref, angle_hip1_hip2_ref, angle_hip1_ref_hip2\n",
    "\n",
    "    angles = []\n",
    "\n",
    "    # Using indices for reference points, these should be the two hips.\n",
    "    ref_indices = [7, 8]  # Indices of the reference points\n",
    "\n",
    "    # Calculate angles for each keypoint relative to the two reference points\n",
    "    for i, keypoint in enumerate(keypoints):\n",
    "        if i not in ref_indices:\n",
    "            angles.extend(calculate_angle(\n",
    "                [keypoints[ref_indices[0]], keypoint, keypoints[ref_indices[1]]]))\n",
    "\n",
    "    feature_vector = np.array(angles)\n",
    "    return feature_vector / 180.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_df[\"keypoints\"] = pose_df.keypoints.map(lambda x: [list(k) for k in x])\n",
    "pose_df[\"keypoints_norm\"] = pose_df.keypoints.map(lambda x: centralize_and_scale_keypoints([k[:2] for k in x]))\n",
    "pose_df[\"embedding_33\"] = pose_df.keypoints_norm.map(lambda x: get_angle_feature_vector(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_df = pose_df[pose_df.embedding_33.map(lambda x: not np.isnan(x).any())] # Remove poses with NaN angles\n",
    "print(pose_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in pose_df.iloc.iterrows():\n",
    "    feature = Feature(\n",
    "        feature_type='pose_filtered',\n",
    "        version=\"1\",\n",
    "        model_name='PifPafModel.fast',\n",
    "        model_params={'PifPafModel': 'fast'},\n",
    "        data={\n",
    "            \"frame\":row[\"frame_number\"],\n",
    "            \"sport\":row[\"sport\"],\n",
    "            \"keypoints\":row[\"keypoints\"],\n",
    "            \"keypoints_norm\":row[\"keypoints_norm\"].tolist()\n",
    "            },\n",
    "        media_id=row['media_id'], \n",
    "        embedding_size=33,\n",
    "        embedding_33=row['embedding_33']\n",
    "    )\n",
    "    create_feature(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load features from DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load poses filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the transformed features for the poses, feature_type = 'pose_image' is a smaller dataset than just 'pose'\n",
    "# In comparison to the full data, it has normalized keypoints and embeddings\n",
    "query = text(\"SELECT * FROM feature WHERE feature_type = 'pose_filtered'\")\n",
    "df = pd.DataFrame(DataAccessObject().fetch_all(query))\n",
    "df['embedding_33'] = df['embedding_33'].apply(lambda x: literal_eval(x))\n",
    "df[\"sport\"] = df.data.map(lambda x: x[\"sport\"])\n",
    "\n",
    "print(f\"{df.shape[0]} poses retrieved\")\n",
    "\n",
    "N_sample = 500\n",
    "category = \"sport\"\n",
    "sample_df = []\n",
    "for label in df[category].unique():\n",
    "    n_poses_in_sport = len(df[df[category] == label])\n",
    "    if n_poses_in_sport < N_sample:\n",
    "        sample_df.append(df[df[category] == label])\n",
    "    else:\n",
    "        sample_df.append(df[df[category] == label].sample(N_sample, random_state=42))\n",
    "sample_df = pd.concat(sample_df)\n",
    "sample_df = sample_df.reset_index(drop=True)\n",
    "print(f\"Testing with {len(sample_df)} poses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centralize_and_scale_keypoints(keypoints, reference_points=['left_hip', 'right_hip'], target_diameter=1):\n",
    "\n",
    "    keypoint_names = [\n",
    "        'nose', 'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',\n",
    "        'left_wrist', 'right_wrist', 'left_hip', 'right_hip', 'left_knee', 'right_knee',\n",
    "        'left_ankle', 'right_ankle'\n",
    "    ]\n",
    "    keypoints = np.array(keypoints)\n",
    "\n",
    "    # Calculate the reference point (midpoint between hips)\n",
    "    left_hip = keypoints[keypoint_names.index(reference_points[0])]\n",
    "    right_hip = keypoints[keypoint_names.index(reference_points[1])]\n",
    "    center_point = (left_hip + right_hip) / 2\n",
    "\n",
    "    # Translate pose to center it at the origin\n",
    "    translated_keypoints = keypoints - center_point\n",
    "\n",
    "    # Determine the maximum distance from the center point to any keypoint\n",
    "    max_distance = np.max(np.linalg.norm(translated_keypoints, axis=1)) \n",
    "\n",
    "    # Calculate the scale factor to make the maximum distance equal to 0.5\n",
    "    scale_factor = 0.5 / max_distance\n",
    "\n",
    "    # Scale keypoints to have the target diameter\n",
    "    scaled_keypoints = translated_keypoints * scale_factor\n",
    "\n",
    "    return scaled_keypoints\n",
    "\n",
    "def get_angle_feature_vector(keypoints):\n",
    "    def calculate_angle(points):\n",
    "        assert len(points) == 3, \"Three points are required to calculate the angles\"\n",
    "\n",
    "        hip1, hip2, ref = np.array(points)\n",
    "\n",
    "        if (hip1[0] == ref[0] and hip1[1] == ref[1]) or \\\n",
    "           (hip2[0] == ref[0] and hip2[1] == ref[1]) or \\\n",
    "           (hip1[0] == hip2[0] and hip1[1] == hip2[1]):\n",
    "           return np.nan, np.nan, np.nan\n",
    "\n",
    "        # Calculate the lengths of the sides of the triangle\n",
    "        a = np.linalg.norm(hip2 - ref)\n",
    "        b = np.linalg.norm(hip1 - ref)\n",
    "        c = np.linalg.norm(hip1 - hip2)\n",
    "\n",
    "        # Law of cosines to find the angles\n",
    "        angle_hip2_hip1_ref = np.degrees(\n",
    "            np.arccos((b**2 + c**2 - a**2) / (2 * b * c)))\n",
    "        angle_hip1_hip2_ref = np.degrees(\n",
    "            np.arccos((a**2 + c**2 - b**2) / (2 * a * c)))\n",
    "        angle_hip1_ref_hip2 = np.degrees(\n",
    "            np.arccos((a**2 + b**2 - c**2) / (2 * a * b)))\n",
    "\n",
    "        return angle_hip2_hip1_ref, angle_hip1_hip2_ref, angle_hip1_ref_hip2\n",
    "\n",
    "    angles = []\n",
    "\n",
    "    # Using indices for reference points, these should be the two hips.\n",
    "    ref_indices = [7, 8]  # Indices of the reference points\n",
    "\n",
    "    # Calculate angles for each keypoint relative to the two reference points\n",
    "    for i, keypoint in enumerate(keypoints):\n",
    "        if i not in ref_indices:\n",
    "            angles.extend(calculate_angle(\n",
    "                [keypoints[ref_indices[0]], keypoint, keypoints[ref_indices[1]]]))\n",
    "\n",
    "    feature_vector = np.array(angles)\n",
    "    return feature_vector / 180.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 10000\n",
    "poses = get_features_by_type_paginated(\"pose\", page_size=1000)\n",
    "\n",
    "while len(poses) < MAX_FEATURES:\n",
    "    last_seen_id = poses[-1].get(\"feature_id\", None)\n",
    "    if last_seen_id is None:\n",
    "        break\n",
    "    poses.extend(get_features_by_type_paginated(\"pose\", page_size=1000, last_seen_feature_id=last_seen_id))\n",
    "    \n",
    "print(f\"Retrieved {len(poses)} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(poses)\n",
    "df[\"frames\"] = df[\"data\"].map(lambda x: x[\"frames\"])\n",
    "df = df.explode(\"frames\")\n",
    "\n",
    "df[\"frame\"] = df[\"frames\"].map(lambda x: x[\"frame\"])\n",
    "df[\"annotations\"] = df[\"frames\"].map(lambda x: x[\"data\"][\"annotations\"])\n",
    "df = df.explode(\"annotations\")\n",
    "\n",
    "df.dropna(subset = [\"annotations\"], inplace=True)\n",
    "\n",
    "df[\"score\"] = df[\"annotations\"].map(lambda x: x[\"score\"])\n",
    "\n",
    "# Cumulative sum of the scores binned by 0.05\n",
    "df.score.hist(bins=20, cumulative=True)\n",
    "plt.title(f\"Cumulative score distribution on {len(df)} poses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.score > 0.6]\n",
    "metadata = pd.read_hdf(\"data/metadata.hdf5\")\n",
    "metadata[\"media_id\"] = metadata.seq_id.map(lambda x: f\"ioc-{x}\")\n",
    "df = df.merge(metadata[[\"media_id\", \"sport\"]], on=\"media_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_sample = 10000\n",
    "category = \"sport\"\n",
    "sample_df = []\n",
    "for label in df[category].unique():\n",
    "    n_poses_in_sport = len(df[df[category] == label])\n",
    "    if n_poses_in_sport < N_sample:\n",
    "        sample_df.append(df[df[category] == label])\n",
    "    else:\n",
    "        sample_df.append(df[df[category] == label].sample(N_sample, random_state=42))\n",
    "sample_df = pd.concat(sample_df)\n",
    "sample_df = sample_df.reset_index(drop=True)\n",
    "df = sample_df\n",
    "print(f\"Testing with {len(df)} poses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bbox\"] = df[\"annotations\"].map(lambda x: x[\"bbox\"])\n",
    "df[\"keypoints\"] = df[\"annotations\"].map(lambda x: x[\"keypoints\"])\n",
    "df[\"keypoints\"] = df[\"keypoints\"].map(lambda x: [x[i:i+3] for i in range(0, len(x), 3)])\n",
    "df[\"keypoints\"] = df[\"keypoints\"].map(lambda x: [k for i,k in enumerate(x) if i not in [1,2,3,4]]) # Remove eyes and ears\n",
    "df[\"keypoints_norm\"] = df[\"keypoints\"].map(lambda x: centralize_and_scale_keypoints([k[:2] for k in x]))\n",
    "df[\"embedding_33\"] = df.keypoints_norm.map(lambda x: get_angle_feature_vector(x))\n",
    "df = df[df.embedding_33.map(lambda x: not np.isnan(x).any())] # Remove poses with NaN angles\n",
    "\n",
    "df = df[[\"media_id\", \"frame\", \"keypoints\", \"keypoints_norm\", \"embedding_33\", \"bbox\", \"score\", \"sport\"]]\n",
    "\n",
    "print(f\"Retrieved {df.shape[0]} poses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"feature_id\"] = df.apply(lambda x: create_feature(Feature(\n",
    "                                                        feature_type='pose_all',\n",
    "                                                        version=\"1\",\n",
    "                                                        model_name='PifPafModel.fast',\n",
    "                                                        model_params={'PifPafModel': 'fast'},\n",
    "                                                        data={\n",
    "                                                            \"frame\":x[\"frame\"],\n",
    "                                                            \"sport\":x[\"sport\"],\n",
    "                                                            \"keypoints\":x[\"keypoints\"],\n",
    "                                                            \"keypoints_norm\":x[\"keypoints_norm\"].tolist()\n",
    "                                                            },\n",
    "                                                        media_id=x['media_id'], \n",
    "                                                        embedding_size=33,\n",
    "                                                        embedding_33=x['embedding_33'].tolist()\n",
    "                                                    )), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"feature_id\"] = df[\"feature_id\"].map(lambda x: x.get(\"feature_id\", None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default values that assume an atlas, not necessary, \n",
    "# but it's good to give the correct values when creating the projection\n",
    "\n",
    "total_tiles = len(df) # either all features or a subset of features\n",
    "atlas_width = 4096\n",
    "max_tile_size = 512\n",
    "max_tiles_per_atlas = (atlas_width // max_tile_size) ** 2\n",
    "atlas_count = int(total_tiles / max_tiles_per_atlas) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cylindrical Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cylinder_mapper = UMAP(output_metric=cylinder_euclidean_grad, min_dist=0.1, n_neighbors=100, random_state=42)\n",
    "data = np.array(df['embedding_33'].tolist())\n",
    "embedding = cylinder_mapper.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette = sns.color_palette(\"Set2\", n_colors=len(df.sport.unique()))\n",
    "colors = df.sport.map(lambda x: color_palette[list(df.sport.unique()).index(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panorama dimensions\n",
    "R_pano = 1\n",
    "H_pano = 1\n",
    "\n",
    "# Cylindrical dimension (theta) and height (h)\n",
    "cylinder_dimension = 2 * np.pi\n",
    "radius = R_pano  # Radius of the cylinder\n",
    "\n",
    "# Extract the cylindrical (theta) and linear (h) coordinates\n",
    "theta_coords = cylinder_mapper.embedding_[:, 0] % cylinder_dimension\n",
    "h_coords = cylinder_mapper.embedding_[:, 1]\n",
    "h_coords = H_pano * (h_coords - np.min(h_coords)) / (np.max(h_coords) - np.min(h_coords)) # Remap height to [0, H_pano] size of the Panorama\n",
    "\n",
    "# Convert cylindrical coordinates to Cartesian coordinates\n",
    "x = radius * np.cos(theta_coords)\n",
    "y = radius * np.sin(theta_coords)\n",
    "z = h_coords\n",
    "\n",
    "embedding_cartesian = np.stack([x, y, z], axis=1)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax1.scatter(x, y, z, s = 0.1)\n",
    "ax1.set_title(\"Cylindrical projection\", fontweight = \"bold\")\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.scatter(theta_coords, h_coords, s = 0.1)\n",
    "ax2.set_title(\"Unwrapped cylinder\", fontweight = \"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the projection, replace the names with the desired ones, library_id = 2 is for the IOC\n",
    "projection = Projection(\n",
    "    projection_name=\"IOC Poses All Cylindrical UMAP 1\",\n",
    "    version=\"0.0.1\",\n",
    "    library_id=2,\n",
    "    model_name=\"openpifpaf_fast\",\n",
    "    model_params={},\n",
    "    data={},\n",
    "    dimension=3,\n",
    "    atlas_folder_path=\"\",\n",
    "    atlas_width=atlas_width,\n",
    "    tile_size=max_tile_size,\n",
    "    atlas_count=atlas_count,\n",
    "    total_tiles=total_tiles,\n",
    "    tiles_per_atlas=max_tiles_per_atlas,\n",
    ")\n",
    "\n",
    "projection_id = create_projection(projection)['projection_id']\n",
    "print(f\"Projection ID: {projection_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an entry in the map_projection_feature table for each feature, links features, media and coordinates\n",
    "for i, row in df.iterrows():\n",
    "    create_map_projection_feature(MapProjectionFeatureCreate(\n",
    "        projection_id=projection_id,\n",
    "        media_id=row.media_id,\n",
    "        atlas_order=-1,\n",
    "        index_in_atlas=-1,\n",
    "        coordinates=[embedding_cartesian[i, 0], embedding_cartesian[i, 1], embedding_cartesian[i, 2]],\n",
    "        feature_id=row.feature_id\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threed_mapper = UMAP(n_components=3, min_dist=0.1, n_neighbors=100, random_state=42)\n",
    "data = np.array(df['embedding_33'].tolist())\n",
    "embedding_threed = threed_mapper.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax1.scatter(embedding_threed[:, 0], embedding_threed[:, 1], embedding_threed[:, 2], c=colors, s = 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the projection, replace the names with the desired ones, library_id = 2 is for the IOC\n",
    "projection = Projection(\n",
    "    projection_name=\"IOC Poses Filtered 3D UMAP\",\n",
    "    version=\"0.0.1\",\n",
    "    library_id=2,\n",
    "    model_name=\"openpifpaf_fast\",\n",
    "    model_params={},\n",
    "    data={},\n",
    "    dimension=3,\n",
    "    atlas_folder_path=\"\",\n",
    "    atlas_width=atlas_width,\n",
    "    tile_size=max_tile_size,\n",
    "    atlas_count=atlas_count,\n",
    "    total_tiles=total_tiles,\n",
    "    tiles_per_atlas=max_tiles_per_atlas,\n",
    ")\n",
    "\n",
    "projection_id = create_projection(projection)['projection_id']\n",
    "print(f\"Projection ID: {projection_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an entry in the map_projection_feature table for each feature, links features, media and coordinates\n",
    "for i, row in df.iterrows():\n",
    "    create_map_projection_feature(MapProjectionFeatureCreate(\n",
    "        projection_id=projection_id,\n",
    "        media_id=row.media_id,\n",
    "        atlas_order=-1,\n",
    "        index_in_atlas=-1,\n",
    "        coordinates=[embedding_threed[i, 0], embedding_threed[i, 1], embedding_threed[i, 2]],\n",
    "        feature_id=row.feature_id\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary files Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emv.pipelines.ioc import PipelineIOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ioc = PipelineIOC()\n",
    "pipeline_ioc.create_binary_pose_embeddings(force = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_features = count_features_by_type(\"pose-binary-extracted\")\n",
    "print(f\"Total features: {total_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = total_features + 1\n",
    "data = get_features_by_type_paginated(\"pose-binary-extracted\", page_size=10000)\n",
    "\n",
    "for _ in tqdm(range(MAX_FEATURES // 10000)):\n",
    "    last_seen_id = data[-1].get(\"feature_id\", None)\n",
    "    if last_seen_id is None:\n",
    "        break\n",
    "    data.extend(get_features_by_type_paginated(\"pose-binary-extracted\", page_size=10000, last_seen_feature_id=last_seen_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ioc_metadata = pd.read_hdf(\"data/metadata.hdf5\")\n",
    "ioc_metadata[\"media_id\"] = ioc_metadata.seq_id.map(lambda x: f\"ioc-{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(ioc_metadata[[\"media_id\", \"sport\"]], on=\"media_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_df_by_category_round_robin(df, N, category_col=\"sport\"):\n",
    "    \"\"\"\n",
    "    Sample N rows from a DataFrame using a round-robin strategy across categories.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with a categorical column.\n",
    "        N (int): Total number of rows to sample.\n",
    "        category_col (str): Name of the column containing category labels.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Sampled rows.\n",
    "    \"\"\"\n",
    "    # Group items by category\n",
    "    grouped = {cat: group_df.index.tolist() for cat, group_df in df.groupby(category_col)}\n",
    "    \n",
    "    # Track sampled indices\n",
    "    sampled_indices = []\n",
    "    \n",
    "    # Round-robin sampling\n",
    "    while len(sampled_indices) < N:\n",
    "        did_sample = False\n",
    "        for cat in sorted(grouped):  # consistent category order\n",
    "            if grouped[cat]:\n",
    "                idx = random.choice(grouped[cat])\n",
    "                grouped[cat].remove(idx)\n",
    "                sampled_indices.append(idx)\n",
    "                did_sample = True\n",
    "                if len(sampled_indices) >= N:\n",
    "                    break\n",
    "        if not did_sample:\n",
    "            break  # All groups exhausted\n",
    "\n",
    "    return df.loc[sampled_indices].reset_index(drop=True)\n",
    "\n",
    "\n",
    "def sample_df_proportional_no_replacement(df, N, category_col=\"sport\", random_state=None):\n",
    "    \"\"\"\n",
    "    Sample exactly N unique rows from df, proportionally to category size, \n",
    "    without replacement. If some categories are too small, redistribute the \n",
    "    shortfall to larger categories.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with a categorical column.\n",
    "        N (int): Total number of rows to sample.\n",
    "        category_col (str): Column with categorical labels.\n",
    "        random_state (int, optional): Seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Sampled DataFrame with exactly N unique rows.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    grouped = df.groupby(category_col)\n",
    "\n",
    "    # Step 1: Initial allocation\n",
    "    category_counts = grouped.size()\n",
    "    proportions = category_counts / category_counts.sum()\n",
    "    allocated = (proportions * N).astype(int)\n",
    "\n",
    "    # Step 2: Redistribute remainder fairly\n",
    "    remainder = N - allocated.sum()\n",
    "    if remainder > 0:\n",
    "        fractions = (proportions * N) - allocated\n",
    "        for cat in fractions.sort_values(ascending=False).index:\n",
    "            if remainder == 0:\n",
    "                break\n",
    "            allocated[cat] += 1\n",
    "            remainder -= 1\n",
    "\n",
    "    # Step 3: Sample without replacement, track shortfall\n",
    "    sampled_dfs = []\n",
    "    deficit = 0\n",
    "    available_pool = {}\n",
    "\n",
    "    for cat, count in allocated.items():\n",
    "        df_cat = grouped.get_group(cat)\n",
    "        max_available = len(df_cat)\n",
    "\n",
    "        if count <= max_available:\n",
    "            sampled_dfs.append(df_cat.sample(n=count, random_state=rng.integers(0, 1e9)))\n",
    "        else:\n",
    "            # Take all available, note deficit\n",
    "            sampled_dfs.append(df_cat)\n",
    "            deficit += (count - max_available)\n",
    "\n",
    "        # Store remaining pool for redistribution\n",
    "        available_pool[cat] = df_cat.copy()\n",
    "\n",
    "    # Step 4: Redistribute deficit to large categories with leftovers\n",
    "    already_sampled_ids = pd.concat(sampled_dfs).index\n",
    "    remaining_pool = df.loc[~df.index.isin(already_sampled_ids)]\n",
    "\n",
    "    if deficit > 0 and len(remaining_pool) >= deficit:\n",
    "        redistribute_sample = remaining_pool.sample(n=deficit, random_state=rng.integers(0, 1e9))\n",
    "        sampled_dfs.append(redistribute_sample)\n",
    "    elif deficit > 0:\n",
    "        raise ValueError(\"Not enough unique items in the dataset to satisfy N without replacement.\")\n",
    "\n",
    "    return pd.concat(sampled_dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_df_with_external_proportions(df, N, proportions_dict, category_col=\"sport\", random_state=None):\n",
    "    \"\"\"\n",
    "    Sample exactly N unique rows from a DataFrame according to external proportions,\n",
    "    without replacement. Shortfalls in undersized categories are reallocated.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the items to sample from.\n",
    "        N (int): Total number of rows to sample.\n",
    "        proportions_dict (dict): Desired proportions per category (e.g., {\"soccer\": 0.5}).\n",
    "        category_col (str): Name of the column with categories.\n",
    "        random_state (int, optional): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Sampled DataFrame with exactly N rows.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    # Normalize external proportions\n",
    "    total_weight = sum(proportions_dict.values())\n",
    "    normalized_props = {k: v / total_weight for k, v in proportions_dict.items()}\n",
    "\n",
    "    # Initial allocation\n",
    "    allocated = {cat: int(normalized_props.get(cat, 0) * N) for cat in df[category_col].unique()}\n",
    "    \n",
    "    # Distribute the remainder fairly\n",
    "    allocated_total = sum(allocated.values())\n",
    "    remainder = N - allocated_total\n",
    "    if remainder > 0:\n",
    "        # Distribute to categories with highest fractional part\n",
    "        fractional_parts = {\n",
    "            cat: (normalized_props.get(cat, 0) * N) - allocated.get(cat, 0)\n",
    "            for cat in df[category_col].unique()\n",
    "        }\n",
    "        for cat in sorted(fractional_parts, key=fractional_parts.get, reverse=True):\n",
    "            if remainder == 0:\n",
    "                break\n",
    "            allocated[cat] += 1\n",
    "            remainder -= 1\n",
    "\n",
    "    # Sampling phase\n",
    "    sampled_dfs = []\n",
    "    deficit = 0\n",
    "    used_indices = set()\n",
    "\n",
    "    for cat, count in allocated.items():\n",
    "        df_cat = df[df[category_col] == cat]\n",
    "        available = len(df_cat)\n",
    "\n",
    "        if count <= available:\n",
    "            sampled = df_cat.sample(n=count, random_state=rng.integers(0, 1e9))\n",
    "        else:\n",
    "            sampled = df_cat\n",
    "            deficit += (count - available)\n",
    "        sampled_dfs.append(sampled)\n",
    "        used_indices.update(sampled.index)\n",
    "\n",
    "    # Redistribute deficit if needed\n",
    "    if deficit > 0:\n",
    "        remaining_pool = df.loc[~df.index.isin(used_indices)]\n",
    "        if len(remaining_pool) < deficit:\n",
    "            raise ValueError(\"Not enough data to sample N items without replacement.\")\n",
    "        redistribute_sample = remaining_pool.sample(n=deficit, random_state=rng.integers(0, 1e9))\n",
    "        sampled_dfs.append(redistribute_sample)\n",
    "\n",
    "    return pd.concat(sampled_dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_n = 220000\n",
    "round_robin_sample = sample_df_by_category_round_robin(data, sample_n, category_col=\"sport\")\n",
    "proportional_sample = sample_df_proportional_no_replacement(data, sample_n, category_col=\"sport\", random_state=42)\n",
    "\n",
    "print(len(round_robin_sample), len(proportional_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sport counts for each sample\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "round_robin_sample.sport.value_counts().plot(kind='bar', ax=axes[0], color='skyblue')\n",
    "axes[0].set_title(\"Round Robin Sample\")\n",
    "axes[0].set_xlabel(\"Sport\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "proportional_sample.sport.value_counts().plot(kind='bar', ax=axes[1], color='salmon')\n",
    "axes[1].set_title(\"Proportional Sample\")\n",
    "axes[1].set_xlabel(\"Sport\")\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ioc_metadata.groupby(\"sport\").duration_sec.sum().sort_values(ascending=False).plot(kind=\"barh\", ax=axs[0])\n",
    "axs[0].set_title(\"Total duration per sport\", fontweight = \"bold\")\n",
    "ioc_metadata.groupby(\"sport\").duration_sec.count().sort_values(ascending=False).plot(kind=\"barh\", ax=axs[1])\n",
    "axs[1].set_title(\"Total number of videos per sport\", fontweight = \"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_n = 220000\n",
    "\n",
    "duration_per_sport = ioc_metadata.groupby(\"sport\").duration_sec.sum()\n",
    "duration_per_sport = duration_per_sport / duration_per_sport.sum()\n",
    "\n",
    "duration_prop_sample = sample_df_with_external_proportions(\n",
    "    data, sample_n, duration_per_sport.to_dict(), category_col=\"sport\", random_state=42\n",
    ")\n",
    "\n",
    "n_videos_per_sport = ioc_metadata.groupby(\"sport\").duration_sec.count()\n",
    "n_videos_per_sport = n_videos_per_sport / n_videos_per_sport.sum()\n",
    "\n",
    "n_videos_prop_sample = sample_df_with_external_proportions(\n",
    "    data, sample_n, n_videos_per_sport.to_dict(), category_col=\"sport\", random_state=42\n",
    ")\n",
    "\n",
    "print(len(duration_prop_sample), len(n_videos_prop_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sport counts for each sample\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "duration_prop_sample.sport.value_counts().plot(kind='bar', ax=axes[0], color='lightgreen')\n",
    "axes[0].set_title(\"Duration Proportional Sample\")\n",
    "axes[0].set_xlabel(\"Sport\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "n_videos_prop_sample.sport.value_counts().plot(kind='bar', ax=axes[1], color='lightcoral')\n",
    "axes[1].set_title(\"Video Count Proportional Sample\")\n",
    "axes[1].set_xlabel(\"Sport\")\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cylinder_projection(df, min_dist=0.1, n_neighbors=100):\n",
    "    cylinder_mapper = UMAP(output_metric=cylinder_euclidean_grad, min_dist=0.1, n_neighbors=100, random_state=42)\n",
    "    features = np.array(df['embedding_33'].map(lambda x: literal_eval(x)).tolist())\n",
    "    embedding = cylinder_mapper.fit_transform(features)\n",
    "    df[\"projection\"] = embedding.tolist()\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map sports to colors\n",
    "color_palette = sns.color_palette(\"Set2\", n_colors=len(data.sport.unique()))\n",
    "colors = data.sport.map(lambda x: color_palette[list(data.sport.unique()).index(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_prop_sample = compute_cylinder_projection(duration_prop_sample)\n",
    "#n_videos_prop_sample = compute_cylinder_projection(n_videos_prop_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cylinder_projection(df, colors):\n",
    "    # Panorama dimensions\n",
    "    R_pano = 1\n",
    "    H_pano = 1\n",
    "\n",
    "    # Cylindrical dimension (theta) and height (h)\n",
    "    cylinder_dimension = 2 * np.pi\n",
    "    radius = R_pano  # Radius of the cylinder\n",
    "\n",
    "    embedding = np.array(df['projection'].tolist())\n",
    "\n",
    "    # Extract the cylindrical (theta) and linear (h) coordinates\n",
    "    theta_coords = embedding[:, 0] % cylinder_dimension\n",
    "    h_coords = embedding[:, 1]\n",
    "    h_coords = H_pano * (h_coords - np.min(h_coords)) / (np.max(h_coords) - np.min(h_coords)) # Remap height to [0, H_pano] size of the Panorama\n",
    "\n",
    "    # Convert cylindrical coordinates to Cartesian coordinates\n",
    "    x = radius * np.cos(theta_coords)\n",
    "    y = radius * np.sin(theta_coords)\n",
    "    z = h_coords\n",
    "\n",
    "    embedding_cartesian = np.stack([x, y, z], axis=1)\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 8))\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    ax1.scatter(x, y, z, c=colors, s=0.1)\n",
    "    ax1.set_title(\"Cylindrical projection\", fontweight=\"bold\")\n",
    "\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.scatter(theta_coords, h_coords, c=colors, s=0.1)\n",
    "    ax2.set_title(\"Unwrapped cylinder\", fontweight=\"bold\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cylinder_projection(duration_prop_sample, [\"black\"] * len(duration_prop_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tiles = len(duration_prop_sample) # either all features or a subset of features\n",
    "atlas_width = 4096\n",
    "max_tile_size = 512\n",
    "max_tiles_per_atlas = (atlas_width // max_tile_size) ** 2\n",
    "atlas_count = int(total_tiles / max_tiles_per_atlas) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the projection, replace the names with the desired ones, library_id = 2 is for the IOC\n",
    "projection = Projection(\n",
    "    projection_name=\"IOC Poses Binary Cylindrical UMAP Duration Proportional\",\n",
    "    version=\"0.0.2\",\n",
    "    library_id=2,\n",
    "    model_name=\"openpifpaf_fast\",\n",
    "    model_params={},\n",
    "    data={},\n",
    "    dimension=3,\n",
    "    atlas_folder_path=\"\",\n",
    "    atlas_width=atlas_width,\n",
    "    tile_size=max_tile_size,\n",
    "    atlas_count=atlas_count,\n",
    "    total_tiles=total_tiles,\n",
    "    tiles_per_atlas=max_tiles_per_atlas,\n",
    ")\n",
    "\n",
    "projection_id = create_projection(projection)['projection_id']\n",
    "print(f\"Projection ID: {projection_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cartesian_projection(embedding):\n",
    "    # Panorama dimensions\n",
    "    R_pano = 1\n",
    "    H_pano = 1\n",
    "\n",
    "    # Cylindrical dimension (theta) and height (h)\n",
    "    cylinder_dimension = 2 * np.pi\n",
    "    radius = R_pano  # Radius of the cylinder\n",
    "\n",
    "    # Extract the cylindrical (theta) and linear (h) coordinates\n",
    "    theta_coords = embedding[:, 0] % cylinder_dimension\n",
    "    h_coords = embedding[:, 1]\n",
    "    h_coords = H_pano * (h_coords - np.min(h_coords)) / (np.max(h_coords) - np.min(h_coords)) # Remap height to [0, H_pano] size of the Panorama\n",
    "\n",
    "    # Convert cylindrical coordinates to Cartesian coordinates\n",
    "    x = radius * np.cos(theta_coords)\n",
    "    y = radius * np.sin(theta_coords)\n",
    "    z = h_coords\n",
    "\n",
    "    return np.stack([x, y, z], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_cartesian = compute_cartesian_projection(np.array(duration_prop_sample[\"projection\"].tolist()))\n",
    "\n",
    "# Create an entry in the map_projection_feature table for each feature, links features, media and coordinates\n",
    "for i, row in duration_prop_sample.iterrows():\n",
    "    create_map_projection_feature(MapProjectionFeatureCreate(\n",
    "        projection_id=projection_id,\n",
    "        media_id=row.media_id,\n",
    "        atlas_order=-1,\n",
    "        index_in_atlas=-1,\n",
    "        coordinates=[embedding_cartesian[i, 0], embedding_cartesian[i, 1], embedding_cartesian[i, 2]],\n",
    "        feature_id=row.feature_id\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emv-requDRed-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
