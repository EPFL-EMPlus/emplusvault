{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a projection from the IOC data\n",
    "\n",
    "There a 3 components to a projection with the poses:\n",
    "1. Features from the feature table (Feature Table)\n",
    "2. A Projection (Projection table)\n",
    "3. Mappings of the coordinates to the projection and features (MapProjectionFeature Table)\n",
    "\n",
    "As the keypoints and angles are already provided in the associated feature data, the atlas is not needed to create the projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../..\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emv.db.dao import DataAccessObject\n",
    "from emv.db.queries import get_features_by_type_paginated\n",
    "from sqlalchemy.sql import text\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "from emv.api.models import Feature\n",
    "from emv.api.models import Projection, MapProjectionFeatureCreate\n",
    "from emv.db.queries import create_projection, create_map_projection_feature, create_feature\n",
    "from umap import UMAP\n",
    "import numba\n",
    "\n",
    "#from emv.features.pose import load_poses \n",
    "from emv.client.get_content import get_features\n",
    "from emv.utils import dataframe_from_hdf5\n",
    "from emv.settings import DRIVE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add filtered poses as new features to the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_poses_path = \"data/sample_poses_to_keep.csv\"\n",
    "pose_df = load_poses(access_point=\"LOCAL\", local_fp=local_poses_path, filter_poses={})\n",
    "pose_df[\"angle_vec\"] = pose_df.angle_vec_fix.map(lambda x: literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_df = pose_df[pose_df.keypoints.map(lambda x: x[7][2] > 0.5 and x[8][2] > 0.5)]\n",
    "print(pose_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centralize_and_scale_keypoints(keypoints, reference_points=['left_hip', 'right_hip'], target_diameter=1):\n",
    "\n",
    "    keypoint_names = [\n",
    "        'nose', 'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',\n",
    "        'left_wrist', 'right_wrist', 'left_hip', 'right_hip', 'left_knee', 'right_knee',\n",
    "        'left_ankle', 'right_ankle'\n",
    "    ]\n",
    "    keypoints = np.array(keypoints)\n",
    "\n",
    "    # Calculate the reference point (midpoint between hips)\n",
    "    left_hip = keypoints[keypoint_names.index(reference_points[0])]\n",
    "    right_hip = keypoints[keypoint_names.index(reference_points[1])]\n",
    "    center_point = (left_hip + right_hip) / 2\n",
    "\n",
    "    # Translate pose to center it at the origin\n",
    "    translated_keypoints = keypoints - center_point\n",
    "\n",
    "    # Determine the maximum distance from the center point to any keypoint\n",
    "    max_distance = np.max(np.linalg.norm(translated_keypoints, axis=1)) \n",
    "\n",
    "    # Calculate the scale factor to make the maximum distance equal to 0.5\n",
    "    scale_factor = 0.5 / max_distance\n",
    "\n",
    "    # Scale keypoints to have the target diameter\n",
    "    scaled_keypoints = translated_keypoints * scale_factor\n",
    "\n",
    "    return scaled_keypoints\n",
    "\n",
    "def get_angle_feature_vector(keypoints):\n",
    "    def calculate_angle(points):\n",
    "        assert len(\n",
    "            points) == 3, \"Three points are required to calculate the angles\"\n",
    "\n",
    "        hip1, hip2, ref = np.array(points)\n",
    "\n",
    "        if (hip1[0] == ref[0] and hip1[1] == ref[1]) or \\\n",
    "                (hip2[0] == ref[0] and hip2[1] == ref[1]) or \\\n",
    "                (hip1[0] == hip2[0] and hip1[1] == hip2[1]):\n",
    "            return np.nan, np.nan, np.nan\n",
    "\n",
    "        # Calculate the lengths of the sides of the triangle\n",
    "        a = np.linalg.norm(hip2 - ref)\n",
    "        b = np.linalg.norm(hip1 - ref)\n",
    "        c = np.linalg.norm(hip1 - hip2)\n",
    "\n",
    "        # Law of cosines to find the angles\n",
    "        angle_hip2_hip1_ref = np.degrees(\n",
    "            np.arccos((b**2 + c**2 - a**2) / (2 * b * c)))\n",
    "        angle_hip1_hip2_ref = np.degrees(\n",
    "            np.arccos((a**2 + c**2 - b**2) / (2 * a * c)))\n",
    "        angle_hip1_ref_hip2 = np.degrees(\n",
    "            np.arccos((a**2 + b**2 - c**2) / (2 * a * b)))\n",
    "\n",
    "        return angle_hip2_hip1_ref, angle_hip1_hip2_ref, angle_hip1_ref_hip2\n",
    "\n",
    "    angles = []\n",
    "\n",
    "    # Using indices for reference points, these should be the two hips.\n",
    "    ref_indices = [7, 8]  # Indices of the reference points\n",
    "\n",
    "    # Calculate angles for each keypoint relative to the two reference points\n",
    "    for i, keypoint in enumerate(keypoints):\n",
    "        if i not in ref_indices:\n",
    "            angles.extend(calculate_angle(\n",
    "                [keypoints[ref_indices[0]], keypoint, keypoints[ref_indices[1]]]))\n",
    "\n",
    "    feature_vector = np.array(angles)\n",
    "    return feature_vector / 180.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_df[\"keypoints\"] = pose_df.keypoints.map(lambda x: [list(k) for k in x])\n",
    "pose_df[\"keypoints_norm\"] = pose_df.keypoints.map(lambda x: centralize_and_scale_keypoints([k[:2] for k in x]))\n",
    "pose_df[\"embedding_33\"] = pose_df.keypoints_norm.map(lambda x: get_angle_feature_vector(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_df = pose_df[pose_df.embedding_33.map(lambda x: not np.isnan(x).any())] # Remove poses with NaN angles\n",
    "print(pose_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in pose_df.iloc.iterrows():\n",
    "    feature = Feature(\n",
    "        feature_type='pose_filtered',\n",
    "        version=\"1\",\n",
    "        model_name='PifPafModel.fast',\n",
    "        model_params={'PifPafModel': 'fast'},\n",
    "        data={\n",
    "            \"frame\":row[\"frame_number\"],\n",
    "            \"sport\":row[\"sport\"],\n",
    "            \"keypoints\":row[\"keypoints\"],\n",
    "            \"keypoints_norm\":row[\"keypoints_norm\"].tolist()\n",
    "            },\n",
    "        media_id=row['media_id'], \n",
    "        embedding_size=33,\n",
    "        embedding_33=row['embedding_33']\n",
    "    )\n",
    "    create_feature(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load features from DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load poses filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the transformed features for the poses, feature_type = 'pose_image' is a smaller dataset than just 'pose'\n",
    "# In comparison to the full data, it has normalized keypoints and embeddings\n",
    "query = text(\"SELECT * FROM feature WHERE feature_type = 'pose_filtered'\")\n",
    "df = pd.DataFrame(DataAccessObject().fetch_all(query))\n",
    "df['embedding_33'] = df['embedding_33'].apply(lambda x: literal_eval(x))\n",
    "df[\"sport\"] = df.data.map(lambda x: x[\"sport\"])\n",
    "\n",
    "print(f\"{df.shape[0]} poses retrieved\")\n",
    "\n",
    "N_sample = 500\n",
    "category = \"sport\"\n",
    "sample_df = []\n",
    "for label in df[category].unique():\n",
    "    n_poses_in_sport = len(df[df[category] == label])\n",
    "    if n_poses_in_sport < N_sample:\n",
    "        sample_df.append(df[df[category] == label])\n",
    "    else:\n",
    "        sample_df.append(df[df[category] == label].sample(N_sample, random_state=42))\n",
    "sample_df = pd.concat(sample_df)\n",
    "sample_df = sample_df.reset_index(drop=True)\n",
    "print(f\"Testing with {len(sample_df)} poses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centralize_and_scale_keypoints(keypoints, reference_points=['left_hip', 'right_hip'], target_diameter=1):\n",
    "\n",
    "    keypoint_names = [\n",
    "        'nose', 'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',\n",
    "        'left_wrist', 'right_wrist', 'left_hip', 'right_hip', 'left_knee', 'right_knee',\n",
    "        'left_ankle', 'right_ankle'\n",
    "    ]\n",
    "    keypoints = np.array(keypoints)\n",
    "\n",
    "    # Calculate the reference point (midpoint between hips)\n",
    "    left_hip = keypoints[keypoint_names.index(reference_points[0])]\n",
    "    right_hip = keypoints[keypoint_names.index(reference_points[1])]\n",
    "    center_point = (left_hip + right_hip) / 2\n",
    "\n",
    "    # Translate pose to center it at the origin\n",
    "    translated_keypoints = keypoints - center_point\n",
    "\n",
    "    # Determine the maximum distance from the center point to any keypoint\n",
    "    max_distance = np.max(np.linalg.norm(translated_keypoints, axis=1)) \n",
    "\n",
    "    # Calculate the scale factor to make the maximum distance equal to 0.5\n",
    "    scale_factor = 0.5 / max_distance\n",
    "\n",
    "    # Scale keypoints to have the target diameter\n",
    "    scaled_keypoints = translated_keypoints * scale_factor\n",
    "\n",
    "    return scaled_keypoints\n",
    "\n",
    "def get_angle_feature_vector(keypoints):\n",
    "    def calculate_angle(points):\n",
    "        assert len(points) == 3, \"Three points are required to calculate the angles\"\n",
    "\n",
    "        hip1, hip2, ref = np.array(points)\n",
    "\n",
    "        if (hip1[0] == ref[0] and hip1[1] == ref[1]) or \\\n",
    "           (hip2[0] == ref[0] and hip2[1] == ref[1]) or \\\n",
    "           (hip1[0] == hip2[0] and hip1[1] == hip2[1]):\n",
    "           return np.nan, np.nan, np.nan\n",
    "\n",
    "        # Calculate the lengths of the sides of the triangle\n",
    "        a = np.linalg.norm(hip2 - ref)\n",
    "        b = np.linalg.norm(hip1 - ref)\n",
    "        c = np.linalg.norm(hip1 - hip2)\n",
    "\n",
    "        # Law of cosines to find the angles\n",
    "        angle_hip2_hip1_ref = np.degrees(\n",
    "            np.arccos((b**2 + c**2 - a**2) / (2 * b * c)))\n",
    "        angle_hip1_hip2_ref = np.degrees(\n",
    "            np.arccos((a**2 + c**2 - b**2) / (2 * a * c)))\n",
    "        angle_hip1_ref_hip2 = np.degrees(\n",
    "            np.arccos((a**2 + b**2 - c**2) / (2 * a * b)))\n",
    "\n",
    "        return angle_hip2_hip1_ref, angle_hip1_hip2_ref, angle_hip1_ref_hip2\n",
    "\n",
    "    angles = []\n",
    "\n",
    "    # Using indices for reference points, these should be the two hips.\n",
    "    ref_indices = [7, 8]  # Indices of the reference points\n",
    "\n",
    "    # Calculate angles for each keypoint relative to the two reference points\n",
    "    for i, keypoint in enumerate(keypoints):\n",
    "        if i not in ref_indices:\n",
    "            angles.extend(calculate_angle(\n",
    "                [keypoints[ref_indices[0]], keypoint, keypoints[ref_indices[1]]]))\n",
    "\n",
    "    feature_vector = np.array(angles)\n",
    "    return feature_vector / 180.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 10000\n",
    "poses = get_features_by_type_paginated(\"pose\", page_size=1000)\n",
    "\n",
    "while len(poses) < MAX_FEATURES:\n",
    "    last_seen_id = poses[-1].get(\"feature_id\", None)\n",
    "    if last_seen_id is None:\n",
    "        break\n",
    "    poses.extend(get_features_by_type_paginated(\"pose\", page_size=1000, last_seen_feature_id=last_seen_id))\n",
    "    \n",
    "print(f\"Retrieved {len(poses)} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(poses)\n",
    "df[\"frames\"] = df[\"data\"].map(lambda x: x[\"frames\"])\n",
    "df = df.explode(\"frames\")\n",
    "\n",
    "df[\"frame\"] = df[\"frames\"].map(lambda x: x[\"frame\"])\n",
    "df[\"annotations\"] = df[\"frames\"].map(lambda x: x[\"data\"][\"annotations\"])\n",
    "df = df.explode(\"annotations\")\n",
    "\n",
    "df.dropna(subset = [\"annotations\"], inplace=True)\n",
    "\n",
    "df[\"score\"] = df[\"annotations\"].map(lambda x: x[\"score\"])\n",
    "\n",
    "# Cumulative sum of the scores binned by 0.05\n",
    "df.score.hist(bins=20, cumulative=True)\n",
    "plt.title(f\"Cumulative score distribution on {len(df)} poses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.score > 0.6]\n",
    "metadata = pd.read_hdf(\"data/metadata.hdf5\")\n",
    "metadata[\"media_id\"] = metadata.seq_id.map(lambda x: f\"ioc-{x}\")\n",
    "df = df.merge(metadata[[\"media_id\", \"sport\"]], on=\"media_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_sample = 10000\n",
    "category = \"sport\"\n",
    "sample_df = []\n",
    "for label in df[category].unique():\n",
    "    n_poses_in_sport = len(df[df[category] == label])\n",
    "    if n_poses_in_sport < N_sample:\n",
    "        sample_df.append(df[df[category] == label])\n",
    "    else:\n",
    "        sample_df.append(df[df[category] == label].sample(N_sample, random_state=42))\n",
    "sample_df = pd.concat(sample_df)\n",
    "sample_df = sample_df.reset_index(drop=True)\n",
    "df = sample_df\n",
    "print(f\"Testing with {len(df)} poses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bbox\"] = df[\"annotations\"].map(lambda x: x[\"bbox\"])\n",
    "df[\"keypoints\"] = df[\"annotations\"].map(lambda x: x[\"keypoints\"])\n",
    "df[\"keypoints\"] = df[\"keypoints\"].map(lambda x: [x[i:i+3] for i in range(0, len(x), 3)])\n",
    "df[\"keypoints\"] = df[\"keypoints\"].map(lambda x: [k for i,k in enumerate(x) if i not in [1,2,3,4]]) # Remove eyes and ears\n",
    "df[\"keypoints_norm\"] = df[\"keypoints\"].map(lambda x: centralize_and_scale_keypoints([k[:2] for k in x]))\n",
    "df[\"embedding_33\"] = df.keypoints_norm.map(lambda x: get_angle_feature_vector(x))\n",
    "df = df[df.embedding_33.map(lambda x: not np.isnan(x).any())] # Remove poses with NaN angles\n",
    "\n",
    "df = df[[\"media_id\", \"frame\", \"keypoints\", \"keypoints_norm\", \"embedding_33\", \"bbox\", \"score\", \"sport\"]]\n",
    "\n",
    "print(f\"Retrieved {df.shape[0]} poses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"feature_id\"] = df.apply(lambda x: create_feature(Feature(\n",
    "                                                        feature_type='pose_all',\n",
    "                                                        version=\"1\",\n",
    "                                                        model_name='PifPafModel.fast',\n",
    "                                                        model_params={'PifPafModel': 'fast'},\n",
    "                                                        data={\n",
    "                                                            \"frame\":x[\"frame\"],\n",
    "                                                            \"sport\":x[\"sport\"],\n",
    "                                                            \"keypoints\":x[\"keypoints\"],\n",
    "                                                            \"keypoints_norm\":x[\"keypoints_norm\"].tolist()\n",
    "                                                            },\n",
    "                                                        media_id=x['media_id'], \n",
    "                                                        embedding_size=33,\n",
    "                                                        embedding_33=x['embedding_33'].tolist()\n",
    "                                                    )), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"feature_id\"] = df[\"feature_id\"].map(lambda x: x.get(\"feature_id\", None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default values that assume an atlas, not necessary, \n",
    "# but it's good to give the correct values when creating the projection\n",
    "\n",
    "total_tiles = len(df) # either all features or a subset of features\n",
    "atlas_width = 4096\n",
    "max_tile_size = 512\n",
    "max_tiles_per_atlas = (atlas_width // max_tile_size) ** 2\n",
    "atlas_count = int(total_tiles / max_tiles_per_atlas) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cylindrical Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(fastmath=True)\n",
    "def cylinder_euclidean_grad(x, y, cylinder_dimension=2*np.pi, linear_dimension=1.0):\n",
    "    \"\"\"Euclidean distance and gradient for cylindrical projection.\n",
    "\n",
    "    x, y: Points between which the distance and gradient are computed.\n",
    "    cylinder_dimension: The dimension of the cylindrical wraparound (default 2*pi).\n",
    "    linear_dimension: The linear dimension (default 1.0).\n",
    "    \"\"\"\n",
    "    distance_sqr = 0.0\n",
    "    g = np.zeros_like(x)\n",
    "    \n",
    "    # Cylindrical dimension (e.g., angular wraparound)\n",
    "    a = abs(x[0] - y[0])\n",
    "    if 2 * a < cylinder_dimension:\n",
    "        distance_sqr += a ** 2\n",
    "        g[0] = (x[0] - y[0])\n",
    "    else:\n",
    "        distance_sqr += (cylinder_dimension - a) ** 2\n",
    "        g[0] = (x[0] - y[0]) * (a - cylinder_dimension) / a\n",
    "    \n",
    "    # Linear dimension (e.g., height)\n",
    "    b = abs(x[1] - y[1])\n",
    "    distance_sqr += b ** 2\n",
    "    g[1] = (x[1] - y[1])\n",
    "    \n",
    "    distance = np.sqrt(distance_sqr)\n",
    "    return distance, g / (1e-6 + distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cylinder_mapper = UMAP(output_metric=cylinder_euclidean_grad, min_dist=0.1, n_neighbors=100, random_state=42)\n",
    "data = np.array(df['embedding_33'].tolist())\n",
    "embedding = cylinder_mapper.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette = sns.color_palette(\"Set2\", n_colors=len(df.sport.unique()))\n",
    "colors = df.sport.map(lambda x: color_palette[list(df.sport.unique()).index(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panorama dimensions\n",
    "R_pano = 1\n",
    "H_pano = 1\n",
    "\n",
    "# Cylindrical dimension (theta) and height (h)\n",
    "cylinder_dimension = 2 * np.pi\n",
    "radius = R_pano  # Radius of the cylinder\n",
    "\n",
    "# Extract the cylindrical (theta) and linear (h) coordinates\n",
    "theta_coords = cylinder_mapper.embedding_[:, 0] % cylinder_dimension\n",
    "h_coords = cylinder_mapper.embedding_[:, 1]\n",
    "h_coords = H_pano * (h_coords - np.min(h_coords)) / (np.max(h_coords) - np.min(h_coords)) # Remap height to [0, H_pano] size of the Panorama\n",
    "\n",
    "# Convert cylindrical coordinates to Cartesian coordinates\n",
    "x = radius * np.cos(theta_coords)\n",
    "y = radius * np.sin(theta_coords)\n",
    "z = h_coords\n",
    "\n",
    "embedding_cartesian = np.stack([x, y, z], axis=1)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax1.scatter(x, y, z, s = 0.1)\n",
    "ax1.set_title(\"Cylindrical projection\", fontweight = \"bold\")\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.scatter(theta_coords, h_coords, s = 0.1)\n",
    "ax2.set_title(\"Unwrapped cylinder\", fontweight = \"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the projection, replace the names with the desired ones, library_id = 2 is for the IOC\n",
    "projection = Projection(\n",
    "    projection_name=\"IOC Poses All Cylindrical UMAP 1\",\n",
    "    version=\"0.0.1\",\n",
    "    library_id=2,\n",
    "    model_name=\"openpifpaf_fast\",\n",
    "    model_params={},\n",
    "    data={},\n",
    "    dimension=3,\n",
    "    atlas_folder_path=\"\",\n",
    "    atlas_width=atlas_width,\n",
    "    tile_size=max_tile_size,\n",
    "    atlas_count=atlas_count,\n",
    "    total_tiles=total_tiles,\n",
    "    tiles_per_atlas=max_tiles_per_atlas,\n",
    ")\n",
    "\n",
    "projection_id = create_projection(projection)['projection_id']\n",
    "print(f\"Projection ID: {projection_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an entry in the map_projection_feature table for each feature, links features, media and coordinates\n",
    "for i, row in df.iterrows():\n",
    "    create_map_projection_feature(MapProjectionFeatureCreate(\n",
    "        projection_id=projection_id,\n",
    "        media_id=row.media_id,\n",
    "        atlas_order=-1,\n",
    "        index_in_atlas=-1,\n",
    "        coordinates=[embedding_cartesian[i, 0], embedding_cartesian[i, 1], embedding_cartesian[i, 2]],\n",
    "        feature_id=row.feature_id\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threed_mapper = UMAP(n_components=3, min_dist=0.1, n_neighbors=100, random_state=42)\n",
    "data = np.array(df['embedding_33'].tolist())\n",
    "embedding_threed = threed_mapper.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax1.scatter(embedding_threed[:, 0], embedding_threed[:, 1], embedding_threed[:, 2], c=colors, s = 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the projection, replace the names with the desired ones, library_id = 2 is for the IOC\n",
    "projection = Projection(\n",
    "    projection_name=\"IOC Poses Filtered 3D UMAP\",\n",
    "    version=\"0.0.1\",\n",
    "    library_id=2,\n",
    "    model_name=\"openpifpaf_fast\",\n",
    "    model_params={},\n",
    "    data={},\n",
    "    dimension=3,\n",
    "    atlas_folder_path=\"\",\n",
    "    atlas_width=atlas_width,\n",
    "    tile_size=max_tile_size,\n",
    "    atlas_count=atlas_count,\n",
    "    total_tiles=total_tiles,\n",
    "    tiles_per_atlas=max_tiles_per_atlas,\n",
    ")\n",
    "\n",
    "projection_id = create_projection(projection)['projection_id']\n",
    "print(f\"Projection ID: {projection_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an entry in the map_projection_feature table for each feature, links features, media and coordinates\n",
    "for i, row in df.iterrows():\n",
    "    create_map_projection_feature(MapProjectionFeatureCreate(\n",
    "        projection_id=projection_id,\n",
    "        media_id=row.media_id,\n",
    "        atlas_order=-1,\n",
    "        index_in_atlas=-1,\n",
    "        coordinates=[embedding_threed[i, 0], embedding_threed[i, 1], embedding_threed[i, 2]],\n",
    "        feature_id=row.feature_id\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emv-requDRed-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
