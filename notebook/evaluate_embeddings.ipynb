{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import textwrap as tw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "import cv2\n",
    "from numba import jit\n",
    "from ast import literal_eval\n",
    "\n",
    "from emv.features.pose import load_poses \n",
    "from emv.features.pose_utils import draw_pose, CONNECTIONS, KEYPOINTS_NAMES, ANGLES_ASSOCIATIONS\n",
    "from emv.features.pose_utils import compute_hips_angles, normalize_angles\n",
    "\n",
    "# Clustering\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "# DR\n",
    "from umap import UMAP\n",
    "from umap.umap_ import nearest_neighbors\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from trimap import TRIMAP\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from coranking import coranking_matrix\n",
    "from coranking.metrics import trustworthiness, continuity, LCMC\n",
    "import mantel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_poses_path = \"data/sample_pose_df.csv\"\n",
    "pose_df = load_poses(local_poses_path, filter_poses={})\n",
    "\n",
    "pose_df = pose_df[pose_df.keypoints.map(lambda x: x[7][2] > 0.5 and x[8][2] > 0.5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_df[\"hips_angles\"] = pose_df.keypoints.map(lambda x: compute_hips_angles(x)[0])\n",
    "pose_df[\"hips_angles\"] = pose_df[\"hips_angles\"].map(lambda x: normalize_angles(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_names = [k for k in KEYPOINTS_NAMES if k != \"left_hip\" and k != \"right_hip\"]\n",
    "\n",
    "hips_angles = pd.DataFrame(pose_df[\"hips_angles\"].to_list(), columns = keypoints_names)\n",
    "hips_angles_means = hips_angles.mean()\n",
    "hips_angles_std = hips_angles.std()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "hips_angles.boxplot()\n",
    "plt.title(\"Hips angles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = pd.DataFrame(pose_df.angle_vec.tolist(), columns = ANGLES_ASSOCIATIONS.keys())\n",
    "\n",
    "default_angles = []\n",
    "for angle in ANGLES_ASSOCIATIONS.keys():\n",
    "    non_missing_angles = angles[angles[angle] != 0][angle]\n",
    "    default_angles.append(non_missing_angles.mean())\n",
    "\n",
    "random_size = 0.0001\n",
    "pose_df[\"angle_vec\"] = pose_df.angle_vec.map(lambda x: [a if a != 0 else default_angles[i] + random.random() * random_size for i,a in enumerate(x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport = \"Weightlifting\"\n",
    "sport_poses = pose_df[pose_df.sport == sport]\n",
    "print(f\"Testing with {len(sport_poses)} poses from {sport}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(features, reducer, params):\n",
    "    embeddings = reducer(**params).fit_transform(features)\n",
    "    pairwise_dist = pairwise_distances(embeddings, metric = \"euclidean\")\n",
    "    \n",
    "    return {\n",
    "        \"reducer\": reducer,\n",
    "        \"reducer_params\": params,\n",
    "        \"embeddings\": embeddings,\n",
    "        \"pairwise_dist\": pairwise_dist\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_umap_embeddings(features, n_neighbors, min_dist = 0.01, metric = \"cosine\"):\n",
    "    knn = nearest_neighbors(features, \n",
    "                            n_neighbors=np.max(n_neighbors), \n",
    "                            metric=metric,\n",
    "                            metric_kwds={},\n",
    "                            angular=False,\n",
    "                            random_state=None)\n",
    "    umap_embeddings = []\n",
    "    for n in n_neighbors:\n",
    "        embeddings_results = compute_embeddings(features, UMAP, {\"n_neighbors\": n, \"min_dist\": min_dist, \"metric\": metric, \"precomputed_knn\": knn})\n",
    "        umap_embeddings.append(embeddings_results)\n",
    "        \n",
    "    return umap_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_angles = np.array(sport_poses[\"angle_vec\"].tolist())\n",
    "\n",
    "# UMAP embeddings\n",
    "n_neighbors = [50, 100, 500]\n",
    "human_angles_embeddings = compute_umap_embeddings(features = human_angles, n_neighbors = n_neighbors)\n",
    "\n",
    "# Other embeddings\n",
    "human_angles_embeddings.append(compute_embeddings(features = human_angles, reducer = PCA, params = {\"n_components\": 2}))\n",
    "\n",
    "perps = [5, 10, 50, 100]\n",
    "for perp in perps:\n",
    "    human_angles_embeddings.append(compute_embeddings(features = human_angles, reducer = TSNE, params = {\"n_components\": 2, \"metric\": \"cosine\", \"perplexity\": perp}))\n",
    "    \n",
    "# TRIMAP embeddings\n",
    "n_inliers_values = [10, 20, 50] # Ratio of 2:1:1 for n_inliers:n_outliers:n_random (as recommended in the paper)\n",
    "for n in n_inliers_values:\n",
    "    m = int(0.5 * n)\n",
    "    human_angles_embeddings.append(compute_embeddings(features = human_angles, reducer = TRIMAP, params = {\"n_inliers\": n, \"n_outliers\": m, \"n_random\": m, \"distance\": \"cosine\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_params(params):\n",
    "    return \", \".join([f\"{k}={v}\" for k,v in params.items() if k != \"precomputed_knn\"])\n",
    "\n",
    "def plot_embeddings(embeddings_results, fig_title, d = 4):\n",
    "    n_plots = len(embeddings_results)\n",
    "    n_cols = 4\n",
    "    n_rows = int(np.ceil(n_plots / n_cols))\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(n_cols * d, n_rows * d))\n",
    "    axs = axs.flatten()\n",
    "    for i, result in enumerate(embeddings_results):\n",
    "        coords = result[\"embeddings\"]\n",
    "        reducer = result[\"reducer\"]\n",
    "        params = result[\"reducer_params\"]\n",
    "        axs[i].scatter(coords[:,0], coords[:,1], s=0.1)\n",
    "        axs[i].set_xticks([])\n",
    "        axs[i].set_yticks([])\n",
    "        title = f\"{reducer.__name__} - params: {format_params(params)}\"\n",
    "        axs[i].set_title(tw.fill(title, width = 40), fontsize=10)\n",
    "    [axs[i].axis(\"off\") for i in range(n_plots, n_rows * n_cols)]\n",
    "    plt.suptitle(fig_title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings(human_angles_embeddings, fig_title = \"Human angles embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = PCA(n_components = 2)\n",
    "pca_model.fit(human_angles)\n",
    "\n",
    "pca_embeddings = pca_model.transform(human_angles)\n",
    "pca_components = pd.DataFrame(pca_model.components_.T, columns = [\"PC1\", \"PC2\"], index = ANGLES_ASSOCIATIONS.keys())\n",
    "pca_model.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_components[\"PC1\"].abs().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_components[\"PC2\"].abs().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pca_embeddings[:,0], pca_embeddings[:,1], s=0.1)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"PCA embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-ranking Metrics: Trustworthiness and Continuity\n",
    "\n",
    "References:\n",
    "* https://towardsdatascience.com/on-the-validating-umap-embeddings-2c8907588175\n",
    "* https://github.com/MoritzM00/drcomp/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [10, 50, 100, 500, 1000]\n",
    "for result in human_angles_embeddings:\n",
    "    Q = coranking_matrix(human_angles, result[\"embeddings\"])\n",
    "    t_values = []\n",
    "    c_values = []\n",
    "    for k in ks:\n",
    "        t_values.append(trustworthiness(Q, min_k = k, max_k = k + 1)[0])\n",
    "        c_values.append(continuity(Q, min_k = k, max_k = k + 1)[0])\n",
    "    result[\"trustworthiness\"] = t_values\n",
    "    result[\"continuity\"] = c_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestyles = {\"PCA\": \"-.\", \"TSNE\": \"--\", \"UMAP\": \":\", \"TRIMAP\": \"-\"}\n",
    "plt.figure(figsize=(10, 5)) \n",
    "\n",
    "for i, result in enumerate(human_angles_embeddings):\n",
    "    plt.plot(ks, result[\"trustworthiness\"], \n",
    "             label = f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", \n",
    "             marker = \"x\", \n",
    "             linestyle = linestyles[result[\"reducer\"].__name__])\n",
    "\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Trustworthiness\")\n",
    "plt.title(\"Trustworthiness of the different embeddings (features: human angles)\")\n",
    "plt.legend(loc = [1.01, 0.2], fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5)) \n",
    "\n",
    "for i, result in enumerate(human_angles_embeddings):\n",
    "    plt.plot(ks, result[\"continuity\"], \n",
    "             label = f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", \n",
    "             marker = \"x\", \n",
    "             linestyle = linestyles[result[\"reducer\"].__name__])\n",
    "\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Continuity\")\n",
    "plt.title(\"Continuity of the different embeddings (features: human angles)\")\n",
    "plt.legend(loc = [1.01, 0.2], fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Triplet Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplets_random(n_features, n_triplets = 1000):\n",
    "    triplets = [np.random.randint(0, n_features, 3) for _ in range(n_triplets)]\n",
    "    return triplets\n",
    " \n",
    "def get_triplets(knn, sampling, n_triplets = 1000, n_neighbors = 10):\n",
    "    initial_points = np.random.randint(0, knn.shape[0], n_triplets)\n",
    "    triplets = []\n",
    "    for i in initial_points:\n",
    "        if sampling == \"local\": # Sample both j and k from the neighborhood of i\n",
    "            j, k = np.random.choice(knn[i,1:n_neighbors], 2, replace = False)            \n",
    "        elif sampling == \"mixed\": # Sample j from the neighborhood of i and k from outside the neighborhood of i\n",
    "            j = np.random.choice(knn[i,1:n_neighbors])\n",
    "            k = np.random.choice(knn[i,n_neighbors:]) \n",
    "        elif sampling == \"global\": # Sample both j and k from outside the neighborhood of i\n",
    "            j, k = np.random.choice(knn[i,n_neighbors:], 2, replace = False)            \n",
    "        else:\n",
    "            raise ValueError(\"Invalid sampling method. Choose between 'local', 'mixed' or 'global'.\")\n",
    "\n",
    "        triplets.append((i,j,k))\n",
    "    return triplets\n",
    "\n",
    "def compute_relative_distances(original_d, embeddings_d, triplets):\n",
    "    relative_d_original = [np.sign(original_d[i,j] - original_d[i,k]) for i,j,k in triplets]\n",
    "    relative_d_embedded = [np.sign(embeddings_d[i,j] - embeddings_d[i,k]) for i,j,k in triplets]\n",
    "\n",
    "    return np.array(relative_d_original), np.array(relative_d_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_triplet_accuracy(data_high_dim, embeddings_result, sampling, n_triplets = 1000, n_repetitions = 10, size_neighborhood = 10):\n",
    "    original_d = pairwise_distances(data_high_dim, metric = \"euclidean\")\n",
    "    dists,knn = NearestNeighbors(n_neighbors=len(data_high_dim) - 1).fit(data_high_dim).kneighbors()\n",
    "    \n",
    "    accs = []\n",
    "    for _ in range(n_repetitions):\n",
    "        triplets = get_triplets(knn, n_triplets = n_triplets, sampling = sampling, n_neighbors = size_neighborhood)\n",
    "        relative_d_original, relative_d_embedded = compute_relative_distances(original_d, embeddings_result[\"pairwise_dist\"], triplets)\n",
    "        acc = np.mean(relative_d_original == relative_d_embedded)\n",
    "        accs.append(acc)\n",
    "\n",
    "    mean_acc = np.mean(accs)\n",
    "    std_acc = np.std(accs)\n",
    "    \n",
    "    return mean_acc, std_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_d = pairwise_distances(human_angles, metric=\"euclidean\")\n",
    "\n",
    "for result in human_angles_embeddings:\n",
    "    result[\"triplet_accuracy_local\"] = random_triplet_accuracy(human_angles, result, sampling = \"local\", n_repetitions=100)\n",
    "    result[\"triplet_accuracy_mixed\"] = random_triplet_accuracy(human_angles, result, sampling = \"mixed\", n_repetitions=100)\n",
    "    result[\"triplet_accuracy_global\"] = random_triplet_accuracy(human_angles, result, sampling = \"global\", n_repetitions=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in human_angles_embeddings]\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(20, 15))\n",
    "for i, sampling in enumerate([\"local\", \"mixed\", \"global\"]):\n",
    "    for j, result in enumerate(human_angles_embeddings):\n",
    "        acc, std = result[f\"triplet_accuracy_{sampling}\"]\n",
    "        axs[i].errorbar(j, acc, yerr = std, fmt = \"o\", color = \"black\")\n",
    "    axs[i].set_ylabel(\"Accuracy\")\n",
    "    axs[i].set_title(f\"Random triplet accuracy ({sampling} sampling)\")\n",
    "    axs[i].set_xticks(range(len(human_angles_embeddings)), labels, rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density Preservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_densities(data, ks, metric = \"euclidean\"):\n",
    "    max_k = np.max(ks)\n",
    "    knn = NearestNeighbors(n_neighbors=max_k+1, metric=metric).fit(data)\n",
    "    mean_local_densities_at_k = []\n",
    "    for k in ks:\n",
    "        distances, _ = knn.kneighbors(data, n_neighbors=k+1)\n",
    "        avg_distances = np.mean(distances[:, 1:], axis=1)\n",
    "        mean_local_densities_at_k.append(np.mean(1 / avg_distances))\n",
    "    return mean_local_densities_at_k\n",
    "\n",
    "def density_preservation(data_high_dim, data_low_dim, ks, metric = \"euclidean\"):\n",
    "    densities_high_dim = local_densities(data_high_dim, ks, metric)\n",
    "    densities_low_dim = local_densities(data_low_dim, ks, metric)\n",
    "    \n",
    "    mean_relative_densities = [np.mean(d_low / d_high) for d_low, d_high in zip(densities_low_dim, densities_high_dim)]\n",
    "    std_relative_densities = [np.std(d_low / d_high) for d_low, d_high in zip(densities_low_dim, densities_high_dim)]\n",
    "    return densities_low_dim, mean_relative_densities, std_relative_densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [10, 50, 100, 500, 1000]\n",
    "for result in human_angles_embeddings:\n",
    "    densities_low_dim, mean_relative_densities, std_relative_densities = density_preservation(human_angles, result[\"embeddings\"], ks)\n",
    "    result[\"local_densities\"] = densities_low_dim\n",
    "    result[\"densities_preservation\"] = mean_relative_densities, std_relative_densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_points_2D = np.random.uniform(-1, 1, (len(human_angles), 2))\n",
    "random_points_densities = local_densities(random_points_2D, ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "for i, result in enumerate(human_angles_embeddings):\n",
    "    if result[\"reducer\"] == PCA:\n",
    "        continue\n",
    "    plt.plot(ks, result[\"local_densities\"], marker=\"x\", label=f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", linestyle = linestyles[result[\"reducer\"].__name__])\n",
    "plt.plot(ks, random_points_densities, marker=\"x\", label=\"Random points in 2D\", linestyle = linestyles[\"PCA\"])\n",
    "plt.legend(loc = [1.01, 0.2], fontsize = 10)\n",
    "plt.title(\"Mean local density of the embedded space\")\n",
    "plt.ylabel(\"Mean local density at k\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Correlation Coefficient (PCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "def compute_pcc(data_high_dim, data_low_dim, n_clusters = 100, n_sample = 10000, n_repetitions = 100):\n",
    "    pccs = []\n",
    "    if n_sample > len(data_high_dim):\n",
    "        n_sample = len(data_high_dim)\n",
    "    for _ in range(n_repetitions):\n",
    "        sample_idx = np.random.choice(len(data_high_dim), n_sample, replace=False)\n",
    "        kmeans_high_dim = KMeans(n_clusters=n_clusters).fit(data_high_dim[sample_idx])\n",
    "        kmeans_low_dim = KMeans(n_clusters=n_clusters).fit(data_low_dim[sample_idx])\n",
    "        \n",
    "        clusters_centers_high_dim = kmeans_high_dim.cluster_centers_\n",
    "        clusters_centers_low_dim = kmeans_low_dim.cluster_centers_\n",
    "        \n",
    "        clusters_d_high = pdist(clusters_centers_high_dim, metric=\"euclidean\")\n",
    "        clusters_d_low = pdist(clusters_centers_low_dim, metric=\"euclidean\")\n",
    "        \n",
    "        pcc = mantel.test(clusters_d_high, clusters_d_low, perms=1000, method=\"pearson\")\n",
    "        pccs.append(pcc.r)\n",
    "    return np.mean(pccs), np.std(pccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "S_points, _ = datasets.make_s_curve(n_samples=1000, noise=0.1, random_state=42)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "S_pca = pca.fit_transform(S_points)\n",
    "\n",
    "print(compute_pcc(S_points, S_pca, n_clusters=100, n_sample=1000, n_repetitions=100))\n",
    "\n",
    "umap_model = UMAP()\n",
    "S_umap = umap_model.fit_transform(S_points)\n",
    "\n",
    "print(compute_pcc(S_points, S_umap, n_clusters=100, n_sample=1000, n_repetitions=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in human_angles_embeddings:\n",
    "    result[\"pcc\"] = compute_pcc(human_angles, result[\"embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "for i,result in enumerate(human_angles_embeddings):\n",
    "    plt.errorbar(i, result[\"pcc\"][0], yerr=result[\"pcc\"][1], fmt=\"x\", color = \"black\")\n",
    "plt.xticks(range(len(human_angles_embeddings)), [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in human_angles_embeddings], rotation=0)\n",
    "plt.ylabel(\"PCC\")\n",
    "plt.title(\"Pearson Correlation Coefficient (PCC) between the clusters in the high and low dimensional spaces\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Score (GS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_score(X, Y):\n",
    "    \"\"\"\n",
    "    From https://github.com/eamid/trimap/blob/master/trimap/trimap_.py\n",
    "    X: high-dimensional data\n",
    "    Y: low-dimensional data\n",
    "    \"\"\"\n",
    "\n",
    "    def global_loss_(X, Y):\n",
    "        X = X - np.mean(X, axis=0)\n",
    "        Y = Y - np.mean(Y, axis=0)\n",
    "        A = X.T @ (Y @ np.linalg.inv(Y.T @ Y))\n",
    "        return np.mean(np.power(X.T - A @ Y.T, 2))\n",
    "\n",
    "    n_dims = Y.shape[1]\n",
    "    Y_pca = PCA(n_components=n_dims).fit_transform(X)\n",
    "    gs_pca = global_loss_(X, Y_pca)\n",
    "    gs_emb = global_loss_(X, Y)\n",
    "    return np.exp(-(gs_emb - gs_pca) / gs_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in human_angles_embeddings:\n",
    "    result[\"global_score\"] = global_score(human_angles, result[\"embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "for i,result in enumerate(human_angles_embeddings):\n",
    "    plt.bar(i, result[\"global_score\"], color = \"black\")\n",
    "plt.xticks(range(len(human_angles_embeddings)), [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in human_angles_embeddings], rotation=0)\n",
    "plt.ylabel(\"GS\")\n",
    "plt.title(\"Global Score (GS) of the embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in human_angles_embeddings:\n",
    "    hdscan = HDBSCAN(min_cluster_size=10, min_samples=10, metric=\"euclidean\").fit(result[\"embeddings\"])\n",
    "    result[\"clusters_labels\"] = hdscan.labels_\n",
    "    result[\"clusters_probs\"] = hdscan.probabilities_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters(embeddings_results, fig_title, d = 4):\n",
    "    n_plots = len(embeddings_results)\n",
    "    n_cols = 4\n",
    "    n_rows = int(np.ceil(n_plots / n_cols))\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(n_cols * d, n_rows * d))\n",
    "    axs = axs.flatten()\n",
    "    for i, result in enumerate(embeddings_results):\n",
    "        coords = result[\"embeddings\"]\n",
    "        reducer = result[\"reducer\"]\n",
    "        params = result[\"reducer_params\"]\n",
    "        labels = result[\"clusters_labels\"]\n",
    "        probs = result[\"clusters_probs\"]\n",
    "        \n",
    "        for cluster in np.unique(labels):\n",
    "            cluster_mask = labels == cluster\n",
    "            cluster_coords = coords[cluster_mask]\n",
    "            cluster_probs = np.clip(probs[cluster_mask], 0.1, 1)\n",
    "            alpha = 0.5 if cluster != -1 else 0.1\n",
    "            axs[i].scatter(cluster_coords[:,0], cluster_coords[:,1], s = cluster_probs, alpha = alpha, label=f\"Cluster {cluster}\")\n",
    "\n",
    "        axs[i].set_xticks([])\n",
    "        axs[i].set_yticks([])\n",
    "        title = f\"{reducer.__name__} - params: {format_params(params)}\"\n",
    "        axs[i].set_title(tw.fill(title, width = 40), fontsize=10)\n",
    "    [axs[i].axis(\"off\") for i in range(n_plots, n_rows * n_cols)]\n",
    "    plt.suptitle(fig_title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_clusters(human_angles_embeddings, fig_title = \"HDSCAN clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clusters_distances(data_high_dim, cluster_labels):\n",
    "\n",
    "    intra_cluster_d = []\n",
    "    for cluster_id in np.unique(cluster_labels):\n",
    "        cluster_points = data_high_dim[cluster_labels == cluster_id]\n",
    "        if len(cluster_points) > 1:  # Ensure there's more than one point in the cluster\n",
    "            cluster_pair_d = pairwise_distances(cluster_points, metric = \"cosine\")\n",
    "            cluster_pair_d = np.triu(cluster_pair_d, k=1)\n",
    "            mean_d = np.mean(cluster_pair_d)\n",
    "            std_d = np.std(cluster_pair_d)\n",
    "            intra_cluster_d.append((mean_d, std_d))\n",
    "\n",
    "    between_cluster_d = []\n",
    "    for i, cluster_id1 in enumerate(np.unique(cluster_labels)):\n",
    "        for cluster_id2 in np.unique(cluster_labels):\n",
    "            if cluster_id1 != cluster_id2:\n",
    "                cluster1_points = data_high_dim[cluster_labels == cluster_id1]\n",
    "                cluster2_points = data_high_dim[cluster_labels == cluster_id2]\n",
    "                ds = pairwise_distances(cluster1_points, cluster2_points, metric = \"cosine\")\n",
    "                mean_d = np.mean(ds)\n",
    "                std_d = np.std(ds)\n",
    "                between_cluster_d.append((mean_d, std_d))\n",
    "\n",
    "    return intra_cluster_d, between_cluster_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in human_angles_embeddings:\n",
    "    intra_cluster_d, between_cluster_d = compute_clusters_distances(human_angles, result[\"clusters_labels\"])\n",
    "    result[\"intra_cluster_d\"] = intra_cluster_d\n",
    "    result[\"between_cluster_d\"] = between_cluster_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.boxplot([[d[0] for d in result[\"intra_cluster_d\"]] for result in human_angles_embeddings], positions = range(len(human_angles_embeddings)), showfliers=False)\n",
    "plt.xticks(range(len(human_angles_embeddings)), [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in human_angles_embeddings], rotation=0)\n",
    "plt.ylabel(\"Mean intra-cluster distance\")\n",
    "plt.title(\"Intra-cluster distances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.boxplot([[d[0] for d in result[\"between_cluster_d\"]] for result in human_angles_embeddings], positions = range(len(human_angles_embeddings)), showfliers=False)\n",
    "plt.xticks(range(len(human_angles_embeddings)), [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in human_angles_embeddings], rotation=0)\n",
    "plt.ylabel(\"Mean between-cluster distance\")\n",
    "plt.title(\"Between-cluster distances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "metric = \"euclidean\"\n",
    "for result in human_angles_embeddings:\n",
    "    labels = result[\"clusters_labels\"]\n",
    "    if len(np.unique(labels)) == 1:\n",
    "        result[\"silhouette_score\"] = 0\n",
    "        result[\"davies_bouldin_score\"] = 0\n",
    "        result[\"calinski_harabasz_score\"] = 0\n",
    "    else:\n",
    "        result[\"silhouette_score\"] = silhouette_score(result[\"embeddings\"], labels, metric = metric)\n",
    "        result[\"davies_bouldin_score\"] = davies_bouldin_score(result[\"embeddings\"], labels)\n",
    "        result[\"calinski_harabasz_score\"] = calinski_harabasz_score(result[\"embeddings\"], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(20, 15))\n",
    "for i, score in enumerate([\"silhouette_score\", \"davies_bouldin_score\", \"calinski_harabasz_score\"]):\n",
    "    scores = [result[score] for result in human_angles_embeddings]\n",
    "    axs[i].bar(range(len(human_angles_embeddings)), scores)\n",
    "    axs[i].set_xticks(range(len(human_angles_embeddings)))\n",
    "    axs[i].set_xticklabels([tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in human_angles_embeddings], rotation=0)\n",
    "    axs[i].set_title(score)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emv-requDRed-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
