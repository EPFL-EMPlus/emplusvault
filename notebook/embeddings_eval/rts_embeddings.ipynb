{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../..\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import textwrap as tw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from ast import literal_eval\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from emv.settings import DRIVE_PATH\n",
    "\n",
    "# Clustering\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "# DR\n",
    "from umap import UMAP\n",
    "from umap.umap_ import nearest_neighbors\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from trimap import TRIMAP\n",
    "\n",
    "# Metrics\n",
    "from emv.embeddings.dr_eval import compute_embeddings, compute_umap_embeddings, plot_embeddings\n",
    "from emv.embeddings.dr_eval import \\\n",
    "    compute_coranking_metrics, \\\n",
    "    random_triplet_accuracy, \\\n",
    "    compute_pcc, \\\n",
    "    global_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Imagenet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(DRIVE_PATH + \"rts/aibox-vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_FOLDER = DRIVE_PATH + \"rts/aibox-vectors/\"\n",
    "rts_videos = pd.read_csv(DRIVE_PATH + \"rts/aibox-vectors/videos.csv\")\n",
    "rts_videos[\"path\"] = rts_videos.id_result.map(lambda x: SAMPLE_FOLDER + \"videos/\" + x[-1] + \"/\" + x[-2] + \"/\" + x[-3] + \"/\" + x + \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_features_per_video = {}\n",
    "for umid,video in zip(rts_videos.umid, rts_videos.path):\n",
    "    npz = np.load(video + \"features_mean.npz\", allow_pickle=True)\n",
    "    imagenet_features_per_video[umid] = {item: npz[item] for item in npz.files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rts_videos[\"imagenet_features\"] = rts_videos.umid.map(lambda x: imagenet_features_per_video[x])\n",
    "rts_videos[\"scenes_tc\"] = rts_videos.imagenet_features.map(lambda x: x.get(\"scenes_tc\"))\n",
    "rts_videos[\"imagenet_features\"] = rts_videos.imagenet_features.map(lambda x: x.get(\"imagenet_features_mean\"))\n",
    "rts_videos[\"scenes_ids\"] = rts_videos.scenes_tc.map(lambda x: [i for i,w in enumerate(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rts_videos = rts_videos.explode([\"imagenet_features\", \"scenes_tc\", \"scenes_ids\"]).reset_index(drop=True)\n",
    "rts_videos.dropna(inplace=True)\n",
    "rts_videos[\"scenes_length\"] = rts_videos.scenes_tc.map(lambda x: x[1] - x[0])\n",
    "rts_videos[\"thumbnail\"] = rts_videos.apply(lambda df: df[\"path\"] + \"ims_scene/\" + str(df[\"scenes_ids\"]) + \".jpg\", axis = 1)\n",
    "rts_videos = rts_videos[rts_videos.scenes_length > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rts_videos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = rts_videos.sample(1000, random_state=42)\n",
    "features = np.array(sample.imagenet_features.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA embeddings\n",
    "embeddings_results = [compute_embeddings(features = features, reducer = PCA, params = {\"n_components\": 2})]\n",
    "\n",
    "# UMAP embeddings\n",
    "n_neighbors = [50, 100, 500]\n",
    "embeddings_results.extend(compute_umap_embeddings(features = features, n_neighbors = n_neighbors))\n",
    "\n",
    "# TSNE embeddings\n",
    "perps = [5, 10, 50, 100]\n",
    "for perp in perps:\n",
    "    embeddings_results.append(compute_embeddings(features = features, reducer = TSNE, params = {\"n_components\": 2, \"metric\": \"cosine\", \"perplexity\": perp}))\n",
    "    \n",
    "# TRIMAP embeddings\n",
    "n_inliers_values = [10, 20, 50] # Ratio of 2:1:1 for n_inliers:n_outliers:n_random (as recommended in the paper)\n",
    "for n in n_inliers_values:\n",
    "    m = int(0.5 * n)\n",
    "    embeddings_results.append(compute_embeddings(features = features, reducer = TRIMAP, params = {\"n_inliers\": n, \"n_outliers\": m, \"n_random\": m, \"distance\": \"cosine\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings(embeddings_results, \"Embeddings on the RTS sample imagenet features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a maximum of 1000 thumbnails on the plot\n",
    "EVERY_N = int(len(thumbnails) / 1000) \n",
    "if EVERY_N < 1:\n",
    "    EVERY_N = 1\n",
    "thumbnails = sample.thumbnail.tolist()[::EVERY_N]\n",
    "thumbnails = [Image.open(thumbnail) for thumbnail in thumbnails]\n",
    "embeddings = embeddings_results[-1][\"embeddings\"][::EVERY_N]\n",
    "\n",
    "plot_embeddings_with_images(embeddings, thumbnails, zoom = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emv-requDRed-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
