{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../..\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import textwrap as tw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from ast import literal_eval\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from emv.features.pose import load_poses \n",
    "from emv.features.pose_utils import draw_pose, CONNECTIONS, KEYPOINTS_NAMES, ANGLES_ASSOCIATIONS\n",
    "from emv.features.pose_utils import compute_hips_angles, normalize_angles\n",
    "\n",
    "# Clustering\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "# DR\n",
    "from umap import UMAP\n",
    "from umap.umap_ import nearest_neighbors\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from trimap import TRIMAP\n",
    "\n",
    "# Metrics\n",
    "from emv-embeddings.dr_eval import compute_embeddings, compute_umap_embeddings, plot_embeddings\n",
    "from emv.embeddings.dr_eval import \\\n",
    "    compute_coranking_metrics, \\\n",
    "    random_triplet_accuracy, \\\n",
    "    compute_pcc, \\\n",
    "    global_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_poses_path = \"data/sample_pose_df.csv\"\n",
    "pose_df = load_poses(local_poses_path, filter_poses={})\n",
    "\n",
    "pose_df = pose_df[pose_df.keypoints.map(lambda x: x[7][2] > 0.5 and x[8][2] > 0.5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = pd.DataFrame(pose_df.angle_vec.tolist(), columns = ANGLES_ASSOCIATIONS.keys())\n",
    "\n",
    "default_angles = []\n",
    "for angle in ANGLES_ASSOCIATIONS.keys():\n",
    "    non_missing_angles = angles[angles[angle] != 0][angle]\n",
    "    default_angles.append(non_missing_angles.mean())\n",
    "\n",
    "random_size = 0.0001\n",
    "pose_df[\"angle_vec\"] = pose_df.angle_vec.map(lambda x: [a if a != 0 else default_angles[i] + random.random() * random_size for i,a in enumerate(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_df[\"hips_angles\"] = pose_df.keypoints.map(lambda x: compute_hips_angles(x)[0])\n",
    "pose_df[\"hips_angles\"] = pose_df[\"hips_angles\"].map(lambda x: normalize_angles(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_names = [k for k in KEYPOINTS_NAMES if k != \"left_hip\" and k != \"right_hip\"]\n",
    "\n",
    "hips_angles = pd.DataFrame(pose_df[\"hips_angles\"].to_list(), columns = keypoints_names)\n",
    "hips_angles_means = hips_angles.mean()\n",
    "hips_angles_std = hips_angles.std()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "hips_angles.boxplot()\n",
    "plt.title(\"Hips angles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport = \"Weightlifting\"\n",
    "sport_poses = pose_df[pose_df.sport == sport]\n",
    "print(f\"Testing with {len(sport_poses)} poses from {sport}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_angles = np.array(sport_poses[\"angle_vec\"].tolist())\n",
    "\n",
    "# PCA embeddings\n",
    "human_angles_embeddings = [compute_embeddings(features = human_angles, reducer = PCA, params = {\"n_components\": 2})]\n",
    "\n",
    "# UMAP embeddings\n",
    "n_neighbors = [50, 100, 500]\n",
    "human_angles_embeddings.extend(compute_umap_embeddings(features = human_angles, n_neighbors = n_neighbors))\n",
    "\n",
    "# TSNE embeddings\n",
    "perps = [5, 10, 50, 100]\n",
    "for perp in perps:\n",
    "    human_angles_embeddings.append(compute_embeddings(features = human_angles, reducer = TSNE, params = {\"n_components\": 2, \"metric\": \"cosine\", \"perplexity\": perp}))\n",
    "    \n",
    "# TRIMAP embeddings\n",
    "n_inliers_values = [10, 20, 50] # Ratio of 2:1:1 for n_inliers:n_outliers:n_random (as recommended in the paper)\n",
    "for n in n_inliers_values:\n",
    "    m = int(0.5 * n)\n",
    "    human_angles_embeddings.append(compute_embeddings(features = human_angles, reducer = TRIMAP, params = {\"n_inliers\": n, \"n_outliers\": m, \"n_random\": m, \"distance\": \"cosine\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings(human_angles_embeddings, fig_title = \"Human angles embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-ranking Metrics: Trustworthiness and Continuity\n",
    "\n",
    "References:\n",
    "* https://towardsdatascience.com/on-the-validating-umap-embeddings-2c8907588175\n",
    "* https://github.com/MoritzM00/drcomp/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [10, 50, 100, 500, 1000]\n",
    "for result in human_angles_embeddings:\n",
    "    t_values, c_values = compute_coranking_metrics(human_angles, result[\"embeddings\"], ks = ks)\n",
    "    result[\"trustworthiness\"] = t_values\n",
    "    result[\"continuity\"] = c_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestyles = {\"PCA\": \"-.\", \"TSNE\": \"--\", \"UMAP\": \":\", \"TRIMAP\": \"-\"}\n",
    "plt.figure(figsize=(10, 5)) \n",
    "\n",
    "for i, result in enumerate(human_angles_embeddings):\n",
    "    plt.plot(ks, result[\"trustworthiness\"], \n",
    "             label = f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", \n",
    "             marker = \"x\", \n",
    "             linestyle = linestyles[result[\"reducer\"].__name__])\n",
    "\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Trustworthiness\")\n",
    "plt.title(\"Trustworthiness of the different embeddings (features: human angles)\")\n",
    "plt.legend(loc = [1.01, 0.2], fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5)) \n",
    "\n",
    "for i, result in enumerate(human_angles_embeddings):\n",
    "    plt.plot(ks, result[\"continuity\"], \n",
    "             label = f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", \n",
    "             marker = \"x\", \n",
    "             linestyle = linestyles[result[\"reducer\"].__name__])\n",
    "\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Continuity\")\n",
    "plt.title(\"Continuity of the different embeddings (features: human angles)\")\n",
    "plt.legend(loc = [1.01, 0.2], fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Triplet Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_d = pairwise_distances(human_angles, metric=\"euclidean\")\n",
    "dists,knn = NearestNeighbors(n_neighbors=len(human_angles) - 1).fit(human_angles).kneighbors()\n",
    "\n",
    "for result in human_angles_embeddings:\n",
    "    result[\"triplet_accuracy_local\"] = random_triplet_accuracy(knn, original_d, result[\"pairwise_dist\"], sampling = \"local\", n_repetitions=100)\n",
    "    result[\"triplet_accuracy_mixed\"] = random_triplet_accuracy(knn, original_d, result[\"pairwise_dist\"], sampling = \"mixed\", n_repetitions=100)\n",
    "    result[\"triplet_accuracy_global\"] = random_triplet_accuracy(knn, original_d, result[\"pairwise_dist\"], sampling = \"global\", n_repetitions=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in human_angles_embeddings]\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(20, 15))\n",
    "for i, sampling in enumerate([\"local\", \"mixed\", \"global\"]):\n",
    "    for j, result in enumerate(human_angles_embeddings):\n",
    "        acc, std = result[f\"triplet_accuracy_{sampling}\"]\n",
    "        axs[i].errorbar(j, acc, yerr = std, fmt = \"o\", color = \"black\")\n",
    "    axs[i].set_ylabel(\"Accuracy\")\n",
    "    axs[i].set_title(f\"Random triplet accuracy ({sampling} sampling)\")\n",
    "    axs[i].set_xticks(range(len(human_angles_embeddings)), labels, rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Correlation Coefficient (PCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in human_angles_embeddings:\n",
    "    result[\"pcc\"] = compute_pcc(human_angles, result[\"embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "for i,result in enumerate(human_angles_embeddings):\n",
    "    plt.errorbar(i, result[\"pcc\"][0], yerr=result[\"pcc\"][1], fmt=\"x\", color = \"black\")\n",
    "plt.xticks(range(len(human_angles_embeddings)), [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in human_angles_embeddings], rotation=0)\n",
    "plt.ylabel(\"PCC\")\n",
    "plt.title(\"Pearson Correlation Coefficient (PCC) between the clusters in the high and low dimensional spaces\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Score (GS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in human_angles_embeddings:\n",
    "    result[\"global_score\"] = global_score(human_angles, result[\"embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "for i,result in enumerate(human_angles_embeddings):\n",
    "    plt.bar(i, result[\"global_score\"], color = \"black\")\n",
    "plt.xticks(range(len(human_angles_embeddings)), [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in human_angles_embeddings], rotation=0)\n",
    "plt.ylabel(\"GS\")\n",
    "plt.title(\"Global Score (GS) of the embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in human_angles_embeddings:\n",
    "    hdscan = HDBSCAN(min_cluster_size=10, min_samples=10, metric=\"euclidean\").fit(result[\"embeddings\"])\n",
    "    result[\"clusters_labels\"] = hdscan.labels_\n",
    "    result[\"clusters_probs\"] = hdscan.probabilities_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters(embeddings_results, fig_title, d = 4):\n",
    "    n_plots = len(embeddings_results)\n",
    "    n_cols = 4\n",
    "    n_rows = int(np.ceil(n_plots / n_cols))\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(n_cols * d, n_rows * d))\n",
    "    axs = axs.flatten()\n",
    "    for i, result in enumerate(embeddings_results):\n",
    "        coords = result[\"embeddings\"]\n",
    "        reducer = result[\"reducer\"]\n",
    "        params = result[\"reducer_params\"]\n",
    "        labels = result[\"clusters_labels\"]\n",
    "        probs = result[\"clusters_probs\"]\n",
    "        \n",
    "        for cluster in np.unique(labels):\n",
    "            cluster_mask = labels == cluster\n",
    "            cluster_coords = coords[cluster_mask]\n",
    "            cluster_probs = np.clip(probs[cluster_mask], 0.1, 1)\n",
    "            alpha = 0.5 if cluster != -1 else 0.1\n",
    "            axs[i].scatter(cluster_coords[:,0], cluster_coords[:,1], s = cluster_probs, alpha = alpha, label=f\"Cluster {cluster}\")\n",
    "\n",
    "        axs[i].set_xticks([])\n",
    "        axs[i].set_yticks([])\n",
    "        title = f\"{reducer.__name__} - params: {format_params(params)}\"\n",
    "        axs[i].set_title(tw.fill(title, width = 40), fontsize=10)\n",
    "    [axs[i].axis(\"off\") for i in range(n_plots, n_rows * n_cols)]\n",
    "    plt.suptitle(fig_title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_clusters(human_angles_embeddings, fig_title = \"HDSCAN clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "for i,result in enumerate(human_angles_embeddings):\n",
    "    mean_prob = np.mean(result[\"clusters_probs\"])\n",
    "    std_prob = np.std(result[\"clusters_probs\"])\n",
    "    plt.errorbar(i, mean_prob, yerr = std_prob, fmt = \"o\", color = \"black\")\n",
    "plt.xticks(range(len(human_angles_embeddings)), [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in human_angles_embeddings], rotation=0)\n",
    "plt.ylabel(\"Mean cluster probability\")\n",
    "plt.title(\"Mean cluster probability of the embeddings\")\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clusters_distances(data_high_dim, cluster_labels):\n",
    "\n",
    "    intra_cluster_d = []\n",
    "    for cluster_id in np.unique(cluster_labels):\n",
    "        cluster_points = data_high_dim[cluster_labels == cluster_id]\n",
    "        if len(cluster_points) > 1:  # Ensure there's more than one point in the cluster\n",
    "            cluster_pair_d = pairwise_distances(cluster_points, metric = \"cosine\")\n",
    "            cluster_pair_d = np.triu(cluster_pair_d, k=1)\n",
    "            mean_d = np.mean(cluster_pair_d)\n",
    "            std_d = np.std(cluster_pair_d)\n",
    "            intra_cluster_d.append((mean_d, std_d))\n",
    "\n",
    "    between_cluster_d = []\n",
    "    for i, cluster_id1 in enumerate(np.unique(cluster_labels)):\n",
    "        for cluster_id2 in np.unique(cluster_labels):\n",
    "            if cluster_id1 != cluster_id2:\n",
    "                cluster1_points = data_high_dim[cluster_labels == cluster_id1]\n",
    "                cluster2_points = data_high_dim[cluster_labels == cluster_id2]\n",
    "                ds = pairwise_distances(cluster1_points, cluster2_points, metric = \"cosine\")\n",
    "                mean_d = np.mean(ds)\n",
    "                std_d = np.std(ds)\n",
    "                between_cluster_d.append((mean_d, std_d))\n",
    "\n",
    "    return intra_cluster_d, between_cluster_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in human_angles_embeddings:\n",
    "    intra_cluster_d, between_cluster_d = compute_clusters_distances(human_angles, result[\"clusters_labels\"])\n",
    "    result[\"intra_cluster_d\"] = intra_cluster_d\n",
    "    result[\"between_cluster_d\"] = between_cluster_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.boxplot([[d[0] for d in result[\"intra_cluster_d\"]] for result in human_angles_embeddings], positions = range(len(human_angles_embeddings)), showfliers=False)\n",
    "plt.xticks(range(len(human_angles_embeddings)), [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in human_angles_embeddings], rotation=0)\n",
    "plt.ylabel(\"Mean intra-cluster distance\")\n",
    "plt.title(\"Intra-cluster distances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.boxplot([[d[0] for d in result[\"between_cluster_d\"]] for result in human_angles_embeddings], positions = range(len(human_angles_embeddings)), showfliers=False)\n",
    "plt.xticks(range(len(human_angles_embeddings)), [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in human_angles_embeddings], rotation=0)\n",
    "plt.ylabel(\"Mean between-cluster distance\")\n",
    "plt.title(\"Between-cluster distances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "metric = \"euclidean\"\n",
    "for result in human_angles_embeddings:\n",
    "    labels = result[\"clusters_labels\"]\n",
    "    if len(np.unique(labels)) == 1:\n",
    "        result[\"silhouette_score\"] = 0\n",
    "        result[\"davies_bouldin_score\"] = 0\n",
    "        result[\"calinski_harabasz_score\"] = 0\n",
    "    else:\n",
    "        result[\"silhouette_score\"] = silhouette_score(result[\"embeddings\"], labels, metric = metric)\n",
    "        result[\"davies_bouldin_score\"] = davies_bouldin_score(result[\"embeddings\"], labels)\n",
    "        result[\"calinski_harabasz_score\"] = calinski_harabasz_score(result[\"embeddings\"], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(20, 15))\n",
    "for i, score in enumerate([\"silhouette_score\", \"davies_bouldin_score\", \"calinski_harabasz_score\"]):\n",
    "    scores = [result[score] for result in human_angles_embeddings]\n",
    "    axs[i].bar(range(len(human_angles_embeddings)), scores)\n",
    "    axs[i].set_xticks(range(len(human_angles_embeddings)))\n",
    "    axs[i].set_xticklabels([tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in human_angles_embeddings], rotation=0)\n",
    "    axs[i].set_title(score)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emv-requDRed-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
