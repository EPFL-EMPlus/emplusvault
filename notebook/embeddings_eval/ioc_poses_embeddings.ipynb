{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../..\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import textwrap as tw\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from ast import literal_eval\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "from emv.features.pose import load_poses \n",
    "from emv.features.pose_utils import draw_pose, CONNECTIONS, KEYPOINTS_NAMES, ANGLES_ASSOCIATIONS\n",
    "from emv.features.pose_utils import compute_hips_angles, normalize_angles\n",
    "\n",
    "# Clustering\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "# DR\n",
    "from umap import UMAP\n",
    "from umap.umap_ import nearest_neighbors\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from trimap import TRIMAP\n",
    "\n",
    "# Metrics\n",
    "from emv.embeddings.dr_eval import compute_embeddings, compute_umap_embeddings, plot_embeddings, format_params\n",
    "from emv.embeddings.dr_eval import \\\n",
    "    compute_coranking_metrics, \\\n",
    "    random_triplet_accuracy, \\\n",
    "    compute_pcc, \\\n",
    "    global_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_poses_path = \"data/sample_poses_to_keep.csv\"\n",
    "pose_df = load_poses(local_poses_path, filter_poses={})\n",
    "pose_df[\"angle_vec\"] = pose_df.angle_vec_fix.map(lambda x: literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_df.sport.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = pd.DataFrame(pose_df.angle_vec.tolist(), columns = ANGLES_ASSOCIATIONS.keys())\n",
    "\n",
    "default_angles = []\n",
    "for angle in ANGLES_ASSOCIATIONS.keys():\n",
    "    non_missing_angles = angles[angles[angle] != 0][angle]\n",
    "    default_angles.append(non_missing_angles.mean())\n",
    "\n",
    "random_size = 0.0001\n",
    "pose_df[\"angle_vec\"] = pose_df.angle_vec.map(lambda x: [a if a != 0 else default_angles[i] + random.random() * random_size for i,a in enumerate(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_df = pose_df[pose_df.keypoints.map(lambda x: x[7][2] > 0.5 and x[8][2] > 0.5)] # Keep only poses with both hips\n",
    "pose_df[\"hips_angles\"] = pose_df.keypoints.map(lambda x: compute_hips_angles(x)[0])\n",
    "pose_df[\"hips_angles\"] = pose_df[\"hips_angles\"].map(lambda x: normalize_angles(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_names = [k for k in KEYPOINTS_NAMES if k != \"left_hip\" and k != \"right_hip\"]\n",
    "\n",
    "hips_angles = pd.DataFrame(pose_df[\"hips_angles\"].to_list(), columns = keypoints_names)\n",
    "hips_angles_means = hips_angles.mean()\n",
    "hips_angles_std = hips_angles.std()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "hips_angles.boxplot()\n",
    "plt.title(\"Hips angles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_sample = 500\n",
    "sport_poses = []\n",
    "for sport in pose_df.sport.unique():\n",
    "    n_poses_in_sport = len(pose_df[pose_df.sport == sport])\n",
    "    if n_poses_in_sport < N_sample:\n",
    "        sport_poses.append(pose_df[pose_df.sport == sport])\n",
    "    else:\n",
    "        sport_poses.append(pose_df[pose_df.sport == sport].sample(N_sample, random_state=42))\n",
    "sport_poses = pd.concat(sport_poses)\n",
    "print(f\"Testing with {len(sport_poses)} poses.\")\n",
    "\n",
    "human_angles = np.array(sport_poses[\"angle_vec\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA embeddings\n",
    "human_angles_embeddings = [compute_embeddings(features = human_angles, reducer = PCA, params = {\"n_components\": 2})]\n",
    "\n",
    "# UMAP embeddings\n",
    "n_neighbors = [50, 100, 500]\n",
    "human_angles_embeddings.extend(compute_umap_embeddings(features = human_angles, n_neighbors = n_neighbors, min_dist = 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_angles = np.array(sport_poses[\"angle_vec\"].tolist())\n",
    "\n",
    "# PCA embeddings\n",
    "human_angles_embeddings = [compute_embeddings(features = human_angles, reducer = PCA, params = {\"n_components\": 2})]\n",
    "\n",
    "# UMAP embeddings\n",
    "n_neighbors = [50, 100, 500]\n",
    "human_angles_embeddings.extend(compute_umap_embeddings(features = human_angles, n_neighbors = n_neighbors))\n",
    "\n",
    "# TSNE embeddings\n",
    "perps = [5, 10, 50, 100]\n",
    "for perp in perps:\n",
    "    human_angles_embeddings.append(compute_embeddings(features = human_angles, reducer = TSNE, params = {\"n_components\": 2, \"metric\": \"cosine\", \"perplexity\": perp}))\n",
    "    \n",
    "# TRIMAP embeddings\n",
    "n_inliers_values = [10, 20, 50] # Ratio of 2:1:1 for n_inliers:n_outliers:n_random (as recommended in the paper)\n",
    "for n in n_inliers_values:\n",
    "    m = int(0.5 * n)\n",
    "    human_angles_embeddings.append(compute_embeddings(features = human_angles, reducer = TRIMAP, params = {\"n_inliers\": n, \"n_outliers\": m, \"n_random\": m, \"distance\": \"cosine\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings(human_angles_embeddings, fig_title = \"Human angles embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot with thumbnails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import base64\n",
    "\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from emv.features.pose_utils import CONNECTIONS, KEYPOINTS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_annotation_pose(pose, threshold = 0.1, linewidth = 5, color = \"black\", alpha = 1):\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    \n",
    "    keypoints = pose[\"keypoints\"]\n",
    "    plt.scatter([k[0] for k in keypoints if k[2] > threshold], \n",
    "                [k[1] for k in keypoints if k[2] > threshold], \n",
    "                s=10, color=color, alpha = alpha)\n",
    "    for c in CONNECTIONS:\n",
    "        k1 = keypoints[KEYPOINTS_NAMES.index(c[0])]\n",
    "        k2 = keypoints[KEYPOINTS_NAMES.index(c[1])]\n",
    "        if k1[2] > threshold and k2[2] > threshold:\n",
    "            plt.plot([k1[0], k2[0]], \n",
    "                    [k1[1], k2[1]], \n",
    "                    linewidth=linewidth, color=color, alpha = alpha)\n",
    "    \n",
    "    bbox = pose[\"bbox\"]\n",
    "    plt.xlim(int(bbox[0]),int(bbox[0] + bbox[2]))\n",
    "    plt.ylim(int(bbox[1] + bbox[3]), int(bbox[1]))\n",
    "    \n",
    "    plt.axis(\"off\")\n",
    "    plt.gca().patch.set_alpha(0)\n",
    "    \n",
    "    buffer = BytesIO()\n",
    "    fig.savefig(buffer)\n",
    "    buffer.seek(0)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    img = Image.open(buffer).resize((128,128), Image.Resampling.BICUBIC)\n",
    "    \n",
    "    img = img.convert(\"RGBA\")  \n",
    "    datas = img.getdata()\n",
    "    newData = []\n",
    "    for item in datas:\n",
    "        if item[0] == 255 and item[1] == 255 and item[2] == 255:\n",
    "            newData.append((255, 255, 255, 0))\n",
    "        else:\n",
    "            newData.append(item)\n",
    "    img.putdata(newData)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports = sport_poses.sport.unique()\n",
    "colors = sns.color_palette(\"hsv\", len(sports))\n",
    "colors_map = {s: c for s,c in zip(sports, colors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings = compute_umap_embeddings(features = human_angles, n_neighbors = [500], min_dist = 0.5)[0][\"embeddings\"]\n",
    "embeddings = human_angles_embeddings[-1][\"embeddings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the embedding colored by sport\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(embeddings[:,0], embeddings[:,1], c = [colors_map[s] for s in sport_poses.sport], s = 0.1)\n",
    "plt.legend(handles=[plt.Line2D([0], [0], marker='o', color='w', label=s, markerfacecolor=colors_map[s], markersize=10) for s in sports], loc = [1.01, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sport_poses[\"embedding\"] = embeddings.tolist()\n",
    "\n",
    "n_rows = 4\n",
    "n_cols = int(len(sports) / n_rows) + 1\n",
    "d = 3\n",
    "\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * d, n_rows * d))\n",
    "axs = axs.flatten()\n",
    "for i,sport in enumerate(sports):\n",
    "    axs[i].scatter(embeddings[sport_poses.sport == sport,0], embeddings[sport_poses.sport == sport,1], c = colors_map[sport], s = 0.1)\n",
    "    axs[i].set_title(sport)\n",
    "    axs[i].set_xlim(-0.1,1.1)\n",
    "    axs[i].set_ylim(-0.1,1.1)\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "[ax.set_visible(False) for ax in axs[len(sports):]]\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a maximum of N thumbnails on the plot\n",
    "N = 1000\n",
    "EVERY_N = int(len(sport_poses) / N) \n",
    "if EVERY_N < 1:\n",
    "    EVERY_N = 1\n",
    "    \n",
    "sample_poses = sport_poses.iloc[::EVERY_N]\n",
    "\n",
    "thumbnails = []\n",
    "for i,pose in tqdm(sample_poses.iterrows()):\n",
    "    #color = colors_map[pose[\"sport\"]]\n",
    "    img = draw_annotation_pose(pose, color = \"black\")\n",
    "    thumbnails.append(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emv.embeddings.dr_eval import plot_embeddings_with_images\n",
    "\n",
    "#embeddings = human_angles_embeddings[3][\"embeddings\"][::EVERY_N]\n",
    "sample_embeddings = embeddings[::EVERY_N]\n",
    "plot_embeddings_with_images(sample_embeddings, thumbnails, zoom = 0.2, figsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "radius = 0.05\n",
    "\n",
    "knn = NearestNeighbors(radius = radius)\n",
    "knn.fit(sample_embeddings)\n",
    "dists, ids = knn.radius_neighbors(sample_embeddings)\n",
    "\n",
    "sample_poses[\"coords\"] = list(sample_embeddings)\n",
    "sample_poses[\"nearest_ids\"] = list(ids)\n",
    "sample_poses[\"nearest_sports\"] = sample_poses.nearest_ids.map(lambda x: Counter(sample_poses.iloc[x].sport.tolist()).most_common())\n",
    "\n",
    "\n",
    "for _ in range(10):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    random_pose = sample_poses.sample(1)\n",
    "    \n",
    "    draw_pose(random_pose.squeeze(axis = 0), ax = axs[0], show_frame = True)\n",
    "    \n",
    "    axs[1].scatter(sample_embeddings[:,0], sample_embeddings[:,1], s = 1)\n",
    "    axs[1].scatter(random_pose[\"coords\"].values[0][0], random_pose[\"coords\"].values[0][1], s = 30, color = \"red\", marker = \"x\")\n",
    "    axs[1].add_patch(plt.Circle((random_pose[\"coords\"].values[0][0], random_pose[\"coords\"].values[0][1]), radius, color='red', fill = False))\n",
    "\n",
    "    axs[1].set_title(f\"Embedded poses - Matched pose from {random_pose.sport.values[0]}\")\n",
    "    axs[1].set_xticks([])\n",
    "    axs[1].set_yticks([])\n",
    "\n",
    "    matches = random_pose[\"nearest_sports\"].values[0][:k][::-1]\n",
    "    total_matches = np.sum([m[1] for m in matches])\n",
    "    axs[2].barh([m[0] for m in matches], [m[1] / total_matches for m in matches])\n",
    "    axs[2].set_title(\"Top sports for the top100 nearest poses\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-ranking Metrics: Trustworthiness and Continuity\n",
    "\n",
    "References:\n",
    "* https://towardsdatascience.com/on-the-validating-umap-embeddings-2c8907588175\n",
    "* https://github.com/MoritzM00/drcomp/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [10, 50, 100, 500, 1000]\n",
    "for result in human_angles_embeddings:\n",
    "    t_values, c_values = compute_coranking_metrics(human_angles, result[\"embeddings\"], ks = ks)\n",
    "    result[\"trustworthiness\"] = t_values\n",
    "    result[\"continuity\"] = c_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestyles = {\"PCA\": \"-.\", \"TSNE\": \"--\", \"UMAP\": \":\", \"TRIMAP\": \"-\"}\n",
    "plt.figure(figsize=(10, 5)) \n",
    "\n",
    "for i, result in enumerate(human_angles_embeddings):\n",
    "    plt.plot(ks, result[\"trustworthiness\"], \n",
    "             label = f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", \n",
    "             marker = \"x\", \n",
    "             linestyle = linestyles[result[\"reducer\"].__name__])\n",
    "\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Trustworthiness\")\n",
    "plt.title(\"Trustworthiness of the different embeddings (features: human angles)\")\n",
    "plt.legend(loc = [1.01, 0.2], fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5)) \n",
    "\n",
    "for i, result in enumerate(human_angles_embeddings):\n",
    "    plt.plot(ks, result[\"continuity\"], \n",
    "             label = f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", \n",
    "             marker = \"x\", \n",
    "             linestyle = linestyles[result[\"reducer\"].__name__])\n",
    "\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Continuity\")\n",
    "plt.title(\"Continuity of the different embeddings (features: human angles)\")\n",
    "plt.legend(loc = [1.01, 0.2], fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Triplet Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_d = squareform(pdist(human_angles, metric=\"euclidean\"))\n",
    "dists,knn = NearestNeighbors(n_neighbors=len(human_angles) - 1).fit(human_angles).kneighbors()\n",
    "\n",
    "for result in human_angles_embeddings:\n",
    "    embeddings_d = squareform(pdist(result[\"embeddings\"], metric=\"euclidean\"))\n",
    "    result[\"triplet_accuracy_local\"] = random_triplet_accuracy(knn, original_d, embeddings_d, sampling = \"local\", n_repetitions=100)\n",
    "    result[\"triplet_accuracy_mixed\"] = random_triplet_accuracy(knn, original_d, embeddings_d, sampling = \"mixed\", n_repetitions=100)\n",
    "    result[\"triplet_accuracy_global\"] = random_triplet_accuracy(knn, original_d, embeddings_d, sampling = \"global\", n_repetitions=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in human_angles_embeddings]\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(20, 15))\n",
    "for i, sampling in enumerate([\"local\", \"mixed\", \"global\"]):\n",
    "    for j, result in enumerate(human_angles_embeddings):\n",
    "        acc, std = result[f\"triplet_accuracy_{sampling}\"]\n",
    "        axs[i].errorbar(j, acc, yerr = std, fmt = \"o\", color = \"black\")\n",
    "    axs[i].set_ylabel(\"Accuracy\")\n",
    "    axs[i].set_title(f\"Random triplet accuracy ({sampling} sampling)\")\n",
    "    axs[i].set_xticks(range(len(human_angles_embeddings)), labels, rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Correlation Coefficient (PCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in human_angles_embeddings:\n",
    "    result[\"pcc\"] = compute_pcc(human_angles, result[\"embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "for i,result in enumerate(human_angles_embeddings):\n",
    "    plt.errorbar(i, result[\"pcc\"][0], yerr=result[\"pcc\"][1], fmt=\"x\", color = \"black\")\n",
    "plt.xticks(range(len(human_angles_embeddings)), [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in human_angles_embeddings], rotation=0)\n",
    "plt.ylabel(\"PCC\")\n",
    "plt.title(\"Pearson Correlation Coefficient (PCC) between the clusters in the high and low dimensional spaces\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Score (GS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in human_angles_embeddings:\n",
    "    result[\"global_score\"] = global_score(human_angles, result[\"embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "for i,result in enumerate(human_angles_embeddings):\n",
    "    plt.bar(i, result[\"global_score\"], color = \"black\")\n",
    "plt.xticks(range(len(human_angles_embeddings)), [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in human_angles_embeddings], rotation=0)\n",
    "plt.ylabel(\"GS\")\n",
    "plt.title(\"Global Score (GS) of the embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in human_angles_embeddings:\n",
    "    hdscan = HDBSCAN(min_cluster_size=10, min_samples=10, metric=\"euclidean\").fit(result[\"embeddings\"])\n",
    "    result[\"clusters_labels\"] = hdscan.labels_\n",
    "    result[\"clusters_probs\"] = hdscan.probabilities_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters(embeddings_results, fig_title, d = 4):\n",
    "    n_plots = len(embeddings_results)\n",
    "    n_cols = 4\n",
    "    n_rows = int(np.ceil(n_plots / n_cols))\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(n_cols * d, n_rows * d))\n",
    "    axs = axs.flatten()\n",
    "    for i, result in enumerate(embeddings_results):\n",
    "        coords = result[\"embeddings\"]\n",
    "        reducer = result[\"reducer\"]\n",
    "        params = result[\"reducer_params\"]\n",
    "        labels = result[\"clusters_labels\"]\n",
    "        probs = result[\"clusters_probs\"]\n",
    "        \n",
    "        for cluster in np.unique(labels):\n",
    "            cluster_mask = labels == cluster\n",
    "            cluster_coords = coords[cluster_mask]\n",
    "            cluster_probs = np.clip(probs[cluster_mask], 0.1, 1)\n",
    "            alpha = 0.5 if cluster != -1 else 0.1\n",
    "            axs[i].scatter(cluster_coords[:,0], cluster_coords[:,1], s = cluster_probs, alpha = alpha, label=f\"Cluster {cluster}\")\n",
    "\n",
    "        axs[i].set_xticks([])\n",
    "        axs[i].set_yticks([])\n",
    "        title = f\"{reducer.__name__} - params: {format_params(params)}\"\n",
    "        axs[i].set_title(tw.fill(title, width = 40), fontsize=10)\n",
    "    [axs[i].axis(\"off\") for i in range(n_plots, n_rows * n_cols)]\n",
    "    plt.suptitle(fig_title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_clusters(human_angles_embeddings, fig_title = \"HDSCAN clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "for i,result in enumerate(human_angles_embeddings):\n",
    "    mean_prob = np.mean(result[\"clusters_probs\"])\n",
    "    std_prob = np.std(result[\"clusters_probs\"])\n",
    "    plt.errorbar(i, mean_prob, yerr = std_prob, fmt = \"o\", color = \"black\")\n",
    "plt.xticks(range(len(human_angles_embeddings)), [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in human_angles_embeddings], rotation=0)\n",
    "plt.ylabel(\"Mean cluster probability\")\n",
    "plt.title(\"Mean cluster probability of the embeddings\")\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clusters_distances(data_high_dim, cluster_labels):\n",
    "\n",
    "    intra_cluster_d = []\n",
    "    for cluster_id in np.unique(cluster_labels):\n",
    "        cluster_points = data_high_dim[cluster_labels == cluster_id]\n",
    "        if len(cluster_points) > 1:  # Ensure there's more than one point in the cluster\n",
    "            cluster_pair_d = pairwise_distances(cluster_points, metric = \"cosine\")\n",
    "            cluster_pair_d = np.triu(cluster_pair_d, k=1)\n",
    "            mean_d = np.mean(cluster_pair_d)\n",
    "            std_d = np.std(cluster_pair_d)\n",
    "            intra_cluster_d.append((mean_d, std_d))\n",
    "\n",
    "    between_cluster_d = []\n",
    "    for i, cluster_id1 in enumerate(np.unique(cluster_labels)):\n",
    "        for cluster_id2 in np.unique(cluster_labels):\n",
    "            if cluster_id1 != cluster_id2:\n",
    "                cluster1_points = data_high_dim[cluster_labels == cluster_id1]\n",
    "                cluster2_points = data_high_dim[cluster_labels == cluster_id2]\n",
    "                ds = pairwise_distances(cluster1_points, cluster2_points, metric = \"cosine\")\n",
    "                mean_d = np.mean(ds)\n",
    "                std_d = np.std(ds)\n",
    "                between_cluster_d.append((mean_d, std_d))\n",
    "\n",
    "    return intra_cluster_d, between_cluster_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in human_angles_embeddings:\n",
    "    intra_cluster_d, between_cluster_d = compute_clusters_distances(human_angles, result[\"clusters_labels\"])\n",
    "    result[\"intra_cluster_d\"] = intra_cluster_d\n",
    "    result[\"between_cluster_d\"] = between_cluster_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.boxplot([[d[0] for d in result[\"intra_cluster_d\"]] for result in human_angles_embeddings], positions = range(len(human_angles_embeddings)), showfliers=False)\n",
    "plt.xticks(range(len(human_angles_embeddings)), [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in human_angles_embeddings], rotation=0)\n",
    "plt.ylabel(\"Mean intra-cluster distance\")\n",
    "plt.title(\"Intra-cluster distances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.boxplot([[d[0] for d in result[\"between_cluster_d\"]] for result in human_angles_embeddings], positions = range(len(human_angles_embeddings)), showfliers=False)\n",
    "plt.xticks(range(len(human_angles_embeddings)), [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in human_angles_embeddings], rotation=0)\n",
    "plt.ylabel(\"Mean between-cluster distance\")\n",
    "plt.title(\"Between-cluster distances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "metric = \"euclidean\"\n",
    "for result in human_angles_embeddings:\n",
    "    labels = result[\"clusters_labels\"]\n",
    "    if len(np.unique(labels)) == 1:\n",
    "        result[\"silhouette_score\"] = 0\n",
    "        result[\"davies_bouldin_score\"] = 0\n",
    "        result[\"calinski_harabasz_score\"] = 0\n",
    "    else:\n",
    "        result[\"silhouette_score\"] = silhouette_score(result[\"embeddings\"], labels, metric = metric)\n",
    "        result[\"davies_bouldin_score\"] = davies_bouldin_score(result[\"embeddings\"], labels)\n",
    "        result[\"calinski_harabasz_score\"] = calinski_harabasz_score(result[\"embeddings\"], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(20, 15))\n",
    "for i, score in enumerate([\"silhouette_score\", \"davies_bouldin_score\", \"calinski_harabasz_score\"]):\n",
    "    scores = [result[score] for result in human_angles_embeddings]\n",
    "    axs[i].bar(range(len(human_angles_embeddings)), scores)\n",
    "    axs[i].set_xticks(range(len(human_angles_embeddings)))\n",
    "    axs[i].set_xticklabels([tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in human_angles_embeddings], rotation=0)\n",
    "    axs[i].set_title(score)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emv-requDRed-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
