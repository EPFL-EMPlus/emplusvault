{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../..\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import textwrap as tw\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from ast import literal_eval\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import numba\n",
    "from emv.db.dao import DataAccessObject\n",
    "from sqlalchemy.sql import text\n",
    "\n",
    "from emv.features.pose import load_poses \n",
    "from emv.features.pose_utils import draw_pose, CONNECTIONS, KEYPOINTS_NAMES, ANGLES_ASSOCIATIONS\n",
    "\n",
    "# Clustering\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "# DR\n",
    "from umap import UMAP\n",
    "from umap.umap_ import nearest_neighbors\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from trimap import TRIMAP\n",
    "import pymde\n",
    "\n",
    "# Metrics\n",
    "from emv.embeddings.dr_eval import compute_embeddings, compute_umap_embeddings, plot_embeddings, format_params\n",
    "from emv.embeddings.dr_eval import \\\n",
    "    compute_coranking_metrics, \\\n",
    "    random_triplet_accuracy, \\\n",
    "    compute_pcc, \\\n",
    "    global_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the transformed features for the poses, feature_type = 'pose_filtered' is a smaller dataset than just 'pose'\n",
    "# In comparison to the full data, it has been filtered to only keep \"interesting\" poses for each sport\n",
    "query = text(\"SELECT * FROM feature WHERE feature_type = 'pose_filtered'\")\n",
    "pose_df = pd.DataFrame(DataAccessObject().fetch_all(query))\n",
    "pose_df['embedding_33'] = pose_df['embedding_33'].apply(lambda x: literal_eval(x))\n",
    "pose_df[\"sport\"] = pose_df.data.map(lambda x: x[\"sport\"])\n",
    "\n",
    "print(f\"{pose_df.shape[0]} poses retrieved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_df.sport.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_sample = 500\n",
    "sport_poses = []\n",
    "for sport in pose_df.sport.unique():\n",
    "    n_poses_in_sport = len(pose_df[pose_df.sport == sport])\n",
    "    if n_poses_in_sport < N_sample:\n",
    "        sport_poses.append(pose_df[pose_df.sport == sport])\n",
    "    else:\n",
    "        sport_poses.append(pose_df[pose_df.sport == sport].sample(N_sample, random_state=42))\n",
    "sport_poses = pd.concat(sport_poses)\n",
    "sport_poses = sport_poses.reset_index(drop=True)\n",
    "print(f\"Testing with {len(sport_poses)} poses.\")\n",
    "\n",
    "features = np.array(sport_poses[\"embedding_33\"].tolist())\n",
    "\n",
    "colors = sport_poses.sport.map(lambda x: sns.color_palette(\"Set2\", n_colors=len(sport_poses.sport.unique()))[list(sport_poses.sport.unique()).index(x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA embeddings\n",
    "features_embeddings = [compute_embeddings(features = features, reducer = PCA, params = {\"n_components\": 2})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP embeddings\n",
    "n_neighbors = [50, 100, 500]\n",
    "features_embeddings.extend(compute_umap_embeddings(features = features, n_neighbors = n_neighbors, min_dist = 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSNE embeddings\n",
    "perps = [5, 10, 50, 100]\n",
    "for perp in perps:\n",
    "    features_embeddings.append(compute_embeddings(features = features, reducer = TSNE, params = {\"n_components\": 2, \"metric\": \"cosine\", \"perplexity\": perp}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRIMAP embeddings\n",
    "n_inliers_values = [10, 20, 50] # Ratio of 2:1:1 for n_inliers:n_outliers:n_random (as recommended in the paper)\n",
    "for n in n_inliers_values:\n",
    "    m = int(0.5 * n)\n",
    "    features_embeddings.append(compute_embeddings(features = features, reducer = TRIMAP, params = {\"n_inliers\": n, \"n_outliers\": m, \"n_random\": m, \"distance\": \"cosine\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings(features_embeddings, fig_title = \"Human angles embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threeD_umap = UMAP(min_dist = 0.5, n_neighbors = 100, n_components=3).fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_SPORTS = [\"Weightlifting\", \"Cycling\"]\n",
    "sport_ids = []\n",
    "for sport in SELECTED_SPORTS:\n",
    "    sport_ids.extend(sport_poses[sport_poses.sport == sport].index.tolist())\n",
    "\n",
    "x = threeD_umap.embedding_[:, 0]\n",
    "y = threeD_umap.embedding_[:, 1]\n",
    "z = threeD_umap.embedding_[:, 2]\n",
    "# Flatten z to 0 if id not in sport_ids\n",
    "z_selected = np.array([z[i] if i in sport_ids else 0 for i in range(len(z))])\n",
    "ms = [2 if i in sport_ids else 0.5 for i in range(len(z))]\n",
    "\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "ax1 = fig.add_subplot(131, projection = \"3d\")\n",
    "ax1.scatter(x, y, z, c=colors, s=0.5)\n",
    "ax1.set_title(\"UMAP 3D\", fontweight = \"bold\")\n",
    "ax1.view_init(10, 45)\n",
    "\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "ax2.scatter(x, y, z_selected, c=colors, s=ms)\n",
    "ax2.set_title(\"Selected sport: \" + \", \".join(SELECTED_SPORTS), fontweight = \"bold\")\n",
    "ax2.view_init(10, 45)\n",
    "\n",
    "ax3 = fig.add_subplot(133)\n",
    "ax3.scatter(x, y, c=colors, s=0.5)\n",
    "ax3.set_title(\"Top-down view\", fontweight = \"bold\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sphere surface embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphere_mapper = UMAP(output_metric='haversine', min_dist=0.1, n_neighbors=100, random_state=42).fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.sin(sphere_mapper.embedding_[:, 0]) * np.cos(sphere_mapper.embedding_[:, 1])\n",
    "y = np.sin(sphere_mapper.embedding_[:, 0]) * np.sin(sphere_mapper.embedding_[:, 1])\n",
    "z = np.cos(sphere_mapper.embedding_[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x, y, z, c=colors, s=0.5)\n",
    "ax.view_init(10, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = np.arctan2(x, y)\n",
    "long = -np.arccos(z)\n",
    "\n",
    "plt.scatter(lat, long, c=colors, s=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torus surface embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(fastmath=True)\n",
    "def torus_euclidean_grad(x, y, torus_dimensions=(2*np.pi,2*np.pi)):\n",
    "    \"\"\"Standard euclidean distance.\n",
    "\n",
    "    ..math::\n",
    "        D(x, y) = \\sqrt{\\sum_i (x_i - y_i)^2}\n",
    "    \"\"\"\n",
    "    distance_sqr = 0.0\n",
    "    g = np.zeros_like(x)\n",
    "    for i in range(x.shape[0]):\n",
    "        a = abs(x[i] - y[i])\n",
    "        if 2*a < torus_dimensions[i]:\n",
    "            distance_sqr += a ** 2\n",
    "            g[i] = (x[i] - y[i])\n",
    "        else:\n",
    "            distance_sqr += (torus_dimensions[i]-a) ** 2\n",
    "            g[i] = (x[i] - y[i]) * (a - torus_dimensions[i]) / a\n",
    "    distance = np.sqrt(distance_sqr)\n",
    "    return distance, g/(1e-6 + distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torus_mapper = UMAP(output_metric=torus_euclidean_grad, min_dist=0.1, n_neighbors=100,  random_state=42).fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 1.5 # Size of the doughnut circle\n",
    "r = 1 # Size of the doughnut cross-section\n",
    "\n",
    "x = (R + r * np.cos(torus_mapper.embedding_[:, 0])) * np.cos(torus_mapper.embedding_[:, 1])\n",
    "y = (R + r * np.cos(torus_mapper.embedding_[:, 0])) * np.sin(torus_mapper.embedding_[:, 1])\n",
    "z = r * np.sin(torus_mapper.embedding_[:, 0])\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x, y, z, c=colors, s = 0.1)\n",
    "ax.set_zlim3d(-3, 3)\n",
    "ax.view_init(35, 70)\n",
    "ax.set_title(\"Torus embedding\", fontweight = \"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torus volume embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(fastmath=True)\n",
    "def torus_volume_euclidean_grad(x, y, torus_dimensions=(2*np.pi, 2*np.pi)):\n",
    "    \"\"\"Euclidean distance and gradient in the full volume of a torus.\"\"\"\n",
    "    best_distance_sqr = np.inf\n",
    "    best_g = np.zeros_like(x)\n",
    "    \n",
    "    for dx in [-1, 0, 1]:\n",
    "        for dy in [-1, 0, 1]:\n",
    "            shift = np.array([dx, dy]) * np.array(torus_dimensions)\n",
    "            distance_sqr = 0.0\n",
    "            g = np.zeros_like(x)\n",
    "            \n",
    "            for i in range(x.shape[0]):\n",
    "                a = abs(x[i] - (y[i] + shift[i]))\n",
    "                if a < 0.5 * torus_dimensions[i]:\n",
    "                    distance_sqr += a ** 2\n",
    "                    g[i] = (x[i] - (y[i] + shift[i]))\n",
    "                else:\n",
    "                    distance_sqr += (torus_dimensions[i] - a) ** 2\n",
    "                    g[i] = (x[i] - (y[i] + shift[i])) * (a - torus_dimensions[i]) / a\n",
    "\n",
    "            if distance_sqr < best_distance_sqr:\n",
    "                best_distance_sqr = distance_sqr\n",
    "                best_g = g\n",
    "\n",
    "    distance = np.sqrt(best_distance_sqr)\n",
    "    return distance, best_g / (1e-6 + distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torus_volume_mapper = UMAP(output_metric=torus_volume_euclidean_grad, min_dist=0.1, n_neighbors=100,  random_state=42).fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torus_volume_mapper.embedding_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 1.5 # Size of the doughnut circle\n",
    "r = 1 # Size of the doughnut cross-section\n",
    "\n",
    "x = (R + r * np.cos(torus_mapper.embedding_[:, 0])) * np.cos(torus_mapper.embedding_[:, 1])\n",
    "y = (R + r * np.cos(torus_mapper.embedding_[:, 0])) * np.sin(torus_mapper.embedding_[:, 1])\n",
    "z = r * np.sin(torus_mapper.embedding_[:, 0])\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x, y, z, c=colors, s = 0.1)\n",
    "ax.set_zlim3d(-3, 3)\n",
    "ax.view_init(30, 45)\n",
    "ax.set_title(\"Torus embedding\", fontweight = \"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cylinder surface embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(fastmath=True)\n",
    "def cylinder_euclidean_grad(x, y, cylinder_dimension=2*np.pi, linear_dimension=1.0):\n",
    "    \"\"\"Euclidean distance and gradient for cylindrical projection.\n",
    "\n",
    "    x, y: Points between which the distance and gradient are computed.\n",
    "    cylinder_dimension: The dimension of the cylindrical wraparound (default 2*pi).\n",
    "    linear_dimension: The linear dimension (default 1.0).\n",
    "    \"\"\"\n",
    "    distance_sqr = 0.0\n",
    "    g = np.zeros_like(x)\n",
    "    \n",
    "    # Cylindrical dimension (e.g., angular wraparound)\n",
    "    a = abs(x[0] - y[0])\n",
    "    if 2 * a < cylinder_dimension:\n",
    "        distance_sqr += a ** 2\n",
    "        g[0] = (x[0] - y[0])\n",
    "    else:\n",
    "        distance_sqr += (cylinder_dimension - a) ** 2\n",
    "        g[0] = (x[0] - y[0]) * (a - cylinder_dimension) / a\n",
    "    \n",
    "    # Linear dimension (e.g., height)\n",
    "    b = abs(x[1] - y[1])\n",
    "    distance_sqr += b ** 2\n",
    "    g[1] = (x[1] - y[1])\n",
    "    \n",
    "    distance = np.sqrt(distance_sqr)\n",
    "    return distance, g / (1e-6 + distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cylinder_mapper = UMAP(output_metric=cylinder_euclidean_grad, min_dist=0.1, n_neighbors=100, random_state=42).fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panorama dimensions\n",
    "R_pano = 4.5\n",
    "H_pano = 3.55\n",
    "\n",
    "# Cylindrical dimension (theta) and height (h)\n",
    "cylinder_dimension = 2 * np.pi\n",
    "radius = R_pano  # Radius of the cylinder\n",
    "\n",
    "# Extract the cylindrical (theta) and linear (h) coordinates\n",
    "theta_coords = cylinder_mapper.embedding_[:, 0] % cylinder_dimension\n",
    "h_coords = cylinder_mapper.embedding_[:, 1]\n",
    "h_coords = H_pano * (h_coords - np.min(h_coords)) / (np.max(h_coords) - np.min(h_coords)) # Remap height to [0, H_pano] size of the Panorama\n",
    "\n",
    "# Convert cylindrical coordinates to Cartesian coordinates\n",
    "x = radius * np.cos(theta_coords)\n",
    "y = radius * np.sin(theta_coords)\n",
    "z = h_coords\n",
    "\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax1.scatter(x, y, z, c=colors, s = 0.1)\n",
    "ax1.set_title(\"Cylindrical projection\", fontweight = \"bold\")\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.scatter(theta_coords, h_coords, c=colors, s = 0.5)\n",
    "ax2.set_title(\"Unwrapped cylinder\", fontweight = \"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing PyMDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mde = pymde.preserve_neighbors(features, n_neighbors=100, embedding_dim=2, verbose = True)\n",
    "embeddings = mde.embed(verbose = True)\n",
    "pymde.plot(embeddings, color_by=sport_poses.sport, figsize_inches=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mde = pymde.preserve_neighbors(features, n_neighbors=100, embedding_dim=2, constraint=pymde.Standardized(), verbose = True)\n",
    "embeddings = mde.embed(verbose = True)\n",
    "pymde.plot(embeddings, color_by=sport_poses.sport, figsize_inches=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mde = pymde.preserve_neighbors(features, n_neighbors=100, embedding_dim=3, verbose = True)\n",
    "embeddings = mde.embed(verbose = True)\n",
    "pymde.plot(embeddings, color_by=sport_poses.sport, figsize_inches=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mde = pymde.preserve_neighbors(features, n_neighbors=100, embedding_dim=5, constraint=pymde.Standardized())\n",
    "embeddings = mde.embed()\n",
    "\n",
    "reducer = UMAP(n_neighbors=100, min_dist=0.1, n_components=2)\n",
    "umap_embeddings = reducer.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(umap_embeddings[:, 0], umap_embeddings[:, 1], c=colors, s=0.1)\n",
    "plt.title(\"UMAP embedding of the 5D MDE embedding\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding metadata to the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sport one-hot encoding\n",
    "sport_poses['sport_enc'] = pd.get_dummies(sport_poses['sport']).astype(int).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections = {}\n",
    "\n",
    "scales = [0.01, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "for scale in scales:\n",
    "    mapper = UMAP(n_components=2, min_dist=0.1, n_neighbors=100, random_state=42)\n",
    "    data = np.array(sport_poses.apply(lambda df: np.concatenate([df[\"embedding_33\"], scale * np.array(df[\"sport_enc\"])]), axis=1)).tolist()\n",
    "    embedding = mapper.fit_transform(data)\n",
    "    \n",
    "    projections[scale] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 6)) \n",
    "\n",
    "anchor_embedding = projections[scales[-1]]\n",
    "\n",
    "for i, scale in enumerate(scales):\n",
    "    ax = fig.add_subplot(1, 6, i + 1)\n",
    "    aligned_embedding = pymde.align(source=projections[scale], target=anchor_embedding)\n",
    "    ax.scatter(aligned_embedding[:, 0], aligned_embedding[:, 1], c=colors, s = 0.1)\n",
    "    ax.set_title(f\"Metadata scale {scale}\", fontweight = \"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cylinder_projections = {}\n",
    "\n",
    "scales = [0.01, 0.1, 0.5, 1]\n",
    "for scale in scales:\n",
    "    mapper = UMAP(output_metric=cylinder_euclidean_grad, min_dist=0.1, n_neighbors=100, random_state=42)\n",
    "    data = np.array(sport_poses.apply(lambda df: np.concatenate([df[\"embedding_33\"], scale * np.array(df[\"sport_enc\"])]), axis=1)).tolist()\n",
    "    embedding = mapper.fit_transform(data)\n",
    "    \n",
    "    cylinder_projections[scale] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panorama dimensions\n",
    "R_pano = 1\n",
    "H_pano = 1\n",
    "\n",
    "# Cylindrical dimension (theta) and height (h)\n",
    "cylinder_dimension = 2 * np.pi\n",
    "radius = R_pano  # Radius of the cylinder\n",
    "\n",
    "anchor_embedding = cylinder_projections[scales[-1]]\n",
    "\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "for i, scale in enumerate(scales):\n",
    "    if i != 3:\n",
    "        aligned_embedding = pymde.align(source=cylinder_projections[scale], target=anchor_embedding)\n",
    "    else:\n",
    "        aligned_embedding = cylinder_projections[scale]\n",
    "\n",
    "    # Extract the cylindrical (theta) and linear (h) coordinates\n",
    "    theta_coords = aligned_embedding[:, 0] % cylinder_dimension\n",
    "    h_coords = aligned_embedding[:, 1]\n",
    "    #h_coords = H_pano * (h_coords - np.min(h_coords)) / (np.max(h_coords) - np.min(h_coords)) # Remap height to [0, H_pano] size of the Panorama\n",
    "\n",
    "    # Convert cylindrical coordinates to Cartesian coordinates\n",
    "    x = radius * np.cos(theta_coords)\n",
    "    y = radius * np.sin(theta_coords)\n",
    "    z = h_coords\n",
    "\n",
    "    ax = fig.add_subplot(1, 4, i + 1, projection='3d')\n",
    "    ax.scatter(x, y, z, c=colors, s = 0.1)\n",
    "    ax.set_title(f\"Metadata scale {scale}\", fontweight = \"bold\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections = {}\n",
    "\n",
    "scales = [0.01, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "for scale in scales:\n",
    "    mapper = UMAP(n_components=3, min_dist=0.1, n_neighbors=100, random_state=42)\n",
    "    data = np.array(sport_poses.apply(lambda df: np.concatenate([df[\"embedding_33\"], scale * np.array(df[\"sport_enc\"])]), axis=1)).tolist()\n",
    "    embedding = mapper.fit_transform(data)\n",
    "    \n",
    "    projections[scale] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 12)) \n",
    "\n",
    "embeddings_aligned = {}\n",
    "for i, scale in enumerate(scales):\n",
    "    ax = fig.add_subplot(2, 3, i + 1, projection='3d')\n",
    "    if i > 0:\n",
    "        anchor_embedding = projections[scales[i - 1]]\n",
    "        aligned_embedding = np.array(pymde.align(source=projections[scale], target=anchor_embedding))\n",
    "    else:\n",
    "        aligned_embedding = projections[scale]\n",
    "    embeddings_aligned[scale] = aligned_embedding\n",
    "    ax.scatter(aligned_embedding[:, 0], aligned_embedding[:, 1], aligned_embedding[:, 2], c=colors, s = 0.1)\n",
    "    ax.set_title(f\"Metadata scale {scale}\", fontweight = \"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emv.api.models import Projection, MapProjectionFeatureCreate\n",
    "from emv.db.queries import create_projection, create_map_projection_feature\n",
    "\n",
    "total_tiles = len(sport_poses) # either all features or a subset of features\n",
    "atlas_width = 4096\n",
    "max_tile_size = 512\n",
    "max_tiles_per_atlas = (atlas_width // max_tile_size) ** 2\n",
    "atlas_count = int(total_tiles / max_tiles_per_atlas) + 1\n",
    "\n",
    "print(f\"Total tiles: {total_tiles}, max tiles per atlas: {max_tiles_per_atlas} => atlas count: {atlas_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scale, embedding in embeddings_aligned.items():\n",
    "    if scale == 0.01:\n",
    "        continue\n",
    "    \n",
    "    # Create the projection, replace the names with the desired ones, library_id = 2 is for the IOC\n",
    "    projection = Projection(\n",
    "        projection_name=f\"IOC Poses + Sport (scale {scale})\",\n",
    "        version=\"0.0.1\",\n",
    "        library_id=2,\n",
    "        model_name=\"openpifpaf_fast\",\n",
    "        model_params={},\n",
    "        data={},\n",
    "        dimension=3,\n",
    "        atlas_folder_path=\"\",\n",
    "        atlas_width=atlas_width,\n",
    "        tile_size=max_tile_size,\n",
    "        atlas_count=atlas_count,\n",
    "        total_tiles=total_tiles,\n",
    "        tiles_per_atlas=max_tiles_per_atlas,\n",
    "    )\n",
    "\n",
    "    projection_id = create_projection(projection)['projection_id']\n",
    "\n",
    "    # Create an entry in the map_projection_feature table for each feature, links features, media and coordinates\n",
    "    for i, row in sport_poses.iterrows():\n",
    "        create_map_projection_feature(MapProjectionFeatureCreate(\n",
    "            projection_id=projection_id,\n",
    "            media_id=row.media_id,\n",
    "            atlas_order=-1,\n",
    "            index_in_atlas=-1,\n",
    "            coordinates=[embedding[i, 0], embedding[i, 1], embedding[i, 2]],\n",
    "            feature_id=row.feature_id\n",
    "        ))\n",
    "        \n",
    "    print(f\"Projection {projection_id} created with {total_tiles} tiles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_poses.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emblaze Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emblaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "every_nth = 1\n",
    "\n",
    "emb = emblaze.Embedding({emblaze.Field.POSITION: features[::every_nth], emblaze.Field.COLOR: colors[::every_nth]}, metric=\"cosine\")\n",
    "emb.compute_neighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = emblaze.EmbeddingSet([\n",
    "    emb.project(method=\"umap\", n_neighbors=n, min_dist=0.1) for n in [50, 100, 500]\n",
    "])\n",
    "\n",
    "variants.compute_neighbors(metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_annotation_pose(pose, threshold = 0.1, linewidth = 5, color = \"black\", alpha = 1):\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    \n",
    "    keypoints = pose[\"data\"][\"keypoints\"]\n",
    "    plt.scatter([k[0] for k in keypoints if k[2] > threshold], \n",
    "                [k[1] for k in keypoints if k[2] > threshold], \n",
    "                s=10, color=color, alpha = alpha)\n",
    "    for c in CONNECTIONS:\n",
    "        k1 = keypoints[KEYPOINTS_NAMES.index(c[0])]\n",
    "        k2 = keypoints[KEYPOINTS_NAMES.index(c[1])]\n",
    "        if k1[2] > threshold and k2[2] > threshold:\n",
    "            plt.plot([k1[0], k2[0]], \n",
    "                    [k1[1], k2[1]], \n",
    "                    linewidth=linewidth, color=color, alpha = alpha)\n",
    "    \n",
    "    # Invert y axis\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    plt.axis(\"off\")\n",
    "    plt.gca().patch.set_alpha(0)\n",
    "    \n",
    "    buffer = BytesIO()\n",
    "    fig.savefig(buffer)\n",
    "    buffer.seek(0)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    img = Image.open(buffer).resize((128,128), Image.Resampling.BICUBIC)\n",
    "    \n",
    "    img = img.convert(\"RGBA\")  \n",
    "    datas = img.getdata()\n",
    "    newData = []\n",
    "    for item in datas:\n",
    "        if item[0] == 255 and item[1] == 255 and item[2] == 255:\n",
    "            newData.append((255, 255, 255, 0))\n",
    "        else:\n",
    "            newData.append(item)\n",
    "    img.putdata(newData)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnails = []\n",
    "for i,pose in tqdm(sport_poses[::every_nth].iterrows(), total = len(sport_poses[::every_nth])):\n",
    "    img = draw_annotation_pose(pose)\n",
    "    thumbnails.append(img)\n",
    "    \n",
    "thumbnails = emblaze.ImageThumbnails([np.array(thumbnail) for thumbnail in thumbnails])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = emblaze.Viewer(embeddings = variants, thumbnails = thumbnails)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot with thumbnails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import base64\n",
    "\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from emv.features.pose_utils import CONNECTIONS, KEYPOINTS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_annotation_pose(pose, threshold = 0.1, linewidth = 5, color = \"black\", alpha = 1):\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    \n",
    "    keypoints = pose[\"data\"][\"keypoints\"]\n",
    "    plt.scatter([k[0] for k in keypoints if k[2] > threshold], \n",
    "                [k[1] for k in keypoints if k[2] > threshold], \n",
    "                s=10, color=color, alpha = alpha)\n",
    "    for c in CONNECTIONS:\n",
    "        k1 = keypoints[KEYPOINTS_NAMES.index(c[0])]\n",
    "        k2 = keypoints[KEYPOINTS_NAMES.index(c[1])]\n",
    "        if k1[2] > threshold and k2[2] > threshold:\n",
    "            plt.plot([k1[0], k2[0]], \n",
    "                    [k1[1], k2[1]], \n",
    "                    linewidth=linewidth, color=color, alpha = alpha)\n",
    "    \n",
    "    # Invert y axis\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    plt.axis(\"off\")\n",
    "    plt.gca().patch.set_alpha(0)\n",
    "    \n",
    "    buffer = BytesIO()\n",
    "    fig.savefig(buffer)\n",
    "    buffer.seek(0)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    img = Image.open(buffer).resize((128,128), Image.Resampling.BICUBIC)\n",
    "    \n",
    "    img = img.convert(\"RGBA\")  \n",
    "    datas = img.getdata()\n",
    "    newData = []\n",
    "    for item in datas:\n",
    "        if item[0] == 255 and item[1] == 255 and item[2] == 255:\n",
    "            newData.append((255, 255, 255, 0))\n",
    "        else:\n",
    "            newData.append(item)\n",
    "    img.putdata(newData)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports = sport_poses.sport.unique()\n",
    "colors = sns.color_palette(\"hsv\", len(sports))\n",
    "colors_map = {s: c for s,c in zip(sports, colors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings = compute_umap_embeddings(features = features, n_neighbors = [500], min_dist = 0.5)[0][\"embeddings\"]\n",
    "embeddings = features_embeddings[-1][\"embeddings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the embedding colored by sport\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(embeddings[:,0], embeddings[:,1], c = [colors_map[s] for s in sport_poses.sport], s = 0.1)\n",
    "plt.legend(handles=[plt.Line2D([0], [0], marker='o', color='w', label=s, markerfacecolor=colors_map[s], markersize=10) for s in sports], loc = [1.01, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sport_poses[\"embedding\"] = embeddings.tolist()\n",
    "\n",
    "n_rows = 4\n",
    "n_cols = int(len(sports) / n_rows) + 1\n",
    "d = 3\n",
    "\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * d, n_rows * d))\n",
    "axs = axs.flatten()\n",
    "for i,sport in enumerate(sports):\n",
    "    axs[i].scatter(embeddings[sport_poses.sport == sport,0], embeddings[sport_poses.sport == sport,1], c = colors_map[sport], s = 0.1)\n",
    "    axs[i].set_title(sport)\n",
    "    axs[i].set_xlim(-0.1,1.1)\n",
    "    axs[i].set_ylim(-0.1,1.1)\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "[ax.set_visible(False) for ax in axs[len(sports):]]\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a maximum of N thumbnails on the plot\n",
    "N = 1000\n",
    "EVERY_N = int(len(sport_poses) / N) \n",
    "if EVERY_N < 1:\n",
    "    EVERY_N = 1\n",
    "    \n",
    "sample_poses = sport_poses.iloc[::EVERY_N]\n",
    "\n",
    "thumbnails = []\n",
    "for i,pose in tqdm(sample_poses.iterrows()):\n",
    "    #color = colors_map[pose[\"sport\"]]\n",
    "    img = draw_annotation_pose(pose, color = \"black\")\n",
    "    thumbnails.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emv.embeddings.dr_eval import plot_embeddings_with_images\n",
    "\n",
    "#embeddings = features_embeddings[3][\"embeddings\"][::EVERY_N]\n",
    "sample_embeddings = embeddings[::EVERY_N]\n",
    "plot_embeddings_with_images(sample_embeddings, thumbnails, zoom = 0.2, figsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "radius = 0.05\n",
    "\n",
    "knn = NearestNeighbors(radius = radius)\n",
    "knn.fit(sample_embeddings)\n",
    "dists, ids = knn.radius_neighbors(sample_embeddings)\n",
    "\n",
    "sample_poses[\"coords\"] = list(sample_embeddings)\n",
    "sample_poses[\"nearest_ids\"] = list(ids)\n",
    "sample_poses[\"nearest_sports\"] = sample_poses.nearest_ids.map(lambda x: Counter(sample_poses.iloc[x].sport.tolist()).most_common())\n",
    "\n",
    "\n",
    "for _ in range(10):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    random_pose = sample_poses.sample(1)\n",
    "    \n",
    "    draw_pose(random_pose.squeeze(axis = 0), ax = axs[0], show_frame = True)\n",
    "    \n",
    "    axs[1].scatter(sample_embeddings[:,0], sample_embeddings[:,1], s = 1)\n",
    "    axs[1].scatter(random_pose[\"coords\"].values[0][0], random_pose[\"coords\"].values[0][1], s = 30, color = \"red\", marker = \"x\")\n",
    "    axs[1].add_patch(plt.Circle((random_pose[\"coords\"].values[0][0], random_pose[\"coords\"].values[0][1]), radius, color='red', fill = False))\n",
    "\n",
    "    axs[1].set_title(f\"Embedded poses - Matched pose from {random_pose.sport.values[0]}\")\n",
    "    axs[1].set_xticks([])\n",
    "    axs[1].set_yticks([])\n",
    "\n",
    "    matches = random_pose[\"nearest_sports\"].values[0][:k][::-1]\n",
    "    total_matches = np.sum([m[1] for m in matches])\n",
    "    axs[2].barh([m[0] for m in matches], [m[1] / total_matches for m in matches])\n",
    "    axs[2].set_title(\"Top sports for the top100 nearest poses\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-ranking Metrics: Trustworthiness and Continuity\n",
    "\n",
    "References:\n",
    "* https://towardsdatascience.com/on-the-validating-umap-embeddings-2c8907588175\n",
    "* https://github.com/MoritzM00/drcomp/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [10, 50, 100, 500, 1000]\n",
    "for result in features_embeddings:\n",
    "    t_values, c_values = compute_coranking_metrics(features, result[\"embeddings\"], ks = ks)\n",
    "    result[\"trustworthiness\"] = t_values\n",
    "    result[\"continuity\"] = c_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestyles = {\"PCA\": \"-.\", \"TSNE\": \"--\", \"UMAP\": \":\", \"TRIMAP\": \"-\"}\n",
    "plt.figure(figsize=(10, 5)) \n",
    "\n",
    "for i, result in enumerate(features_embeddings):\n",
    "    plt.plot(ks, result[\"trustworthiness\"], \n",
    "             label = f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", \n",
    "             marker = \"x\", \n",
    "             linestyle = linestyles[result[\"reducer\"].__name__])\n",
    "\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Trustworthiness\")\n",
    "plt.title(\"Trustworthiness of the different embeddings (features: human angles)\")\n",
    "plt.legend(loc = [1.01, 0.2], fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5)) \n",
    "\n",
    "for i, result in enumerate(features_embeddings):\n",
    "    plt.plot(ks, result[\"continuity\"], \n",
    "             label = f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", \n",
    "             marker = \"x\", \n",
    "             linestyle = linestyles[result[\"reducer\"].__name__])\n",
    "\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Continuity\")\n",
    "plt.title(\"Continuity of the different embeddings (features: human angles)\")\n",
    "plt.legend(loc = [1.01, 0.2], fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Triplet Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_d = squareform(pdist(features, metric=\"euclidean\"))\n",
    "dists,knn = NearestNeighbors(n_neighbors=len(features) - 1).fit(features).kneighbors()\n",
    "\n",
    "for result in features_embeddings:\n",
    "    embeddings_d = squareform(pdist(result[\"embeddings\"], metric=\"euclidean\"))\n",
    "    result[\"triplet_accuracy_local\"] = random_triplet_accuracy(knn, original_d, embeddings_d, sampling = \"local\", n_repetitions=100)\n",
    "    result[\"triplet_accuracy_mixed\"] = random_triplet_accuracy(knn, original_d, embeddings_d, sampling = \"mixed\", n_repetitions=100)\n",
    "    result[\"triplet_accuracy_global\"] = random_triplet_accuracy(knn, original_d, embeddings_d, sampling = \"global\", n_repetitions=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in features_embeddings]\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(20, 15))\n",
    "for i, sampling in enumerate([\"local\", \"mixed\", \"global\"]):\n",
    "    for j, result in enumerate(features_embeddings):\n",
    "        acc, std = result[f\"triplet_accuracy_{sampling}\"]\n",
    "        axs[i].errorbar(j, acc, yerr = std, fmt = \"o\", color = \"black\")\n",
    "    axs[i].set_ylabel(\"Accuracy\")\n",
    "    axs[i].set_title(f\"Random triplet accuracy ({sampling} sampling)\")\n",
    "    axs[i].set_xticks(range(len(features_embeddings)), labels, rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Correlation Coefficient (PCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in features_embeddings:\n",
    "    result[\"pcc\"] = compute_pcc(features, result[\"embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "for i,result in enumerate(features_embeddings):\n",
    "    plt.errorbar(i, result[\"pcc\"][0], yerr=result[\"pcc\"][1], fmt=\"x\", color = \"black\")\n",
    "plt.xticks(range(len(features_embeddings)), [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in features_embeddings], rotation=0)\n",
    "plt.ylabel(\"PCC\")\n",
    "plt.title(\"Pearson Correlation Coefficient (PCC) between the clusters in the high and low dimensional spaces\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Score (GS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in features_embeddings:\n",
    "    result[\"global_score\"] = global_score(features, result[\"embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "for i,result in enumerate(features_embeddings):\n",
    "    plt.bar(i, result[\"global_score\"], color = \"black\")\n",
    "plt.xticks(range(len(features_embeddings)), [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in features_embeddings], rotation=0)\n",
    "plt.ylabel(\"GS\")\n",
    "plt.title(\"Global Score (GS) of the embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in features_embeddings:\n",
    "    hdscan = HDBSCAN(min_cluster_size=10, min_samples=10, metric=\"euclidean\").fit(result[\"embeddings\"])\n",
    "    result[\"clusters_labels\"] = hdscan.labels_\n",
    "    result[\"clusters_probs\"] = hdscan.probabilities_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters(embeddings_results, fig_title, d = 4):\n",
    "    n_plots = len(embeddings_results)\n",
    "    n_cols = 4\n",
    "    n_rows = int(np.ceil(n_plots / n_cols))\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(n_cols * d, n_rows * d))\n",
    "    axs = axs.flatten()\n",
    "    for i, result in enumerate(embeddings_results):\n",
    "        coords = result[\"embeddings\"]\n",
    "        reducer = result[\"reducer\"]\n",
    "        params = result[\"reducer_params\"]\n",
    "        labels = result[\"clusters_labels\"]\n",
    "        probs = result[\"clusters_probs\"]\n",
    "        \n",
    "        for cluster in np.unique(labels):\n",
    "            cluster_mask = labels == cluster\n",
    "            cluster_coords = coords[cluster_mask]\n",
    "            cluster_probs = np.clip(probs[cluster_mask], 0.1, 1)\n",
    "            alpha = 0.5 if cluster != -1 else 0.1\n",
    "            axs[i].scatter(cluster_coords[:,0], cluster_coords[:,1], s = cluster_probs, alpha = alpha, label=f\"Cluster {cluster}\")\n",
    "\n",
    "        axs[i].set_xticks([])\n",
    "        axs[i].set_yticks([])\n",
    "        title = f\"{reducer.__name__} - params: {format_params(params)}\"\n",
    "        axs[i].set_title(tw.fill(title, width = 40), fontsize=10)\n",
    "    [axs[i].axis(\"off\") for i in range(n_plots, n_rows * n_cols)]\n",
    "    plt.suptitle(fig_title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_clusters(features_embeddings, fig_title = \"HDSCAN clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "for i,result in enumerate(features_embeddings):\n",
    "    mean_prob = np.mean(result[\"clusters_probs\"])\n",
    "    std_prob = np.std(result[\"clusters_probs\"])\n",
    "    plt.errorbar(i, mean_prob, yerr = std_prob, fmt = \"o\", color = \"black\")\n",
    "plt.xticks(range(len(features_embeddings)), [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in features_embeddings], rotation=0)\n",
    "plt.ylabel(\"Mean cluster probability\")\n",
    "plt.title(\"Mean cluster probability of the embeddings\")\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clusters_distances(data_high_dim, cluster_labels):\n",
    "\n",
    "    intra_cluster_d = []\n",
    "    for cluster_id in np.unique(cluster_labels):\n",
    "        cluster_points = data_high_dim[cluster_labels == cluster_id]\n",
    "        if len(cluster_points) > 1:  # Ensure there's more than one point in the cluster\n",
    "            cluster_pair_d = pairwise_distances(cluster_points, metric = \"cosine\")\n",
    "            cluster_pair_d = np.triu(cluster_pair_d, k=1)\n",
    "            mean_d = np.mean(cluster_pair_d)\n",
    "            std_d = np.std(cluster_pair_d)\n",
    "            intra_cluster_d.append((mean_d, std_d))\n",
    "\n",
    "    between_cluster_d = []\n",
    "    for i, cluster_id1 in enumerate(np.unique(cluster_labels)):\n",
    "        for cluster_id2 in np.unique(cluster_labels):\n",
    "            if cluster_id1 != cluster_id2:\n",
    "                cluster1_points = data_high_dim[cluster_labels == cluster_id1]\n",
    "                cluster2_points = data_high_dim[cluster_labels == cluster_id2]\n",
    "                ds = pairwise_distances(cluster1_points, cluster2_points, metric = \"cosine\")\n",
    "                mean_d = np.mean(ds)\n",
    "                std_d = np.std(ds)\n",
    "                between_cluster_d.append((mean_d, std_d))\n",
    "\n",
    "    return intra_cluster_d, between_cluster_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in features_embeddings:\n",
    "    intra_cluster_d, between_cluster_d = compute_clusters_distances(features, result[\"clusters_labels\"])\n",
    "    result[\"intra_cluster_d\"] = intra_cluster_d\n",
    "    result[\"between_cluster_d\"] = between_cluster_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.boxplot([[d[0] for d in result[\"intra_cluster_d\"]] for result in features_embeddings], positions = range(len(features_embeddings)), showfliers=False)\n",
    "plt.xticks(range(len(features_embeddings)), [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in features_embeddings], rotation=0)\n",
    "plt.ylabel(\"Mean intra-cluster distance\")\n",
    "plt.title(\"Intra-cluster distances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.boxplot([[d[0] for d in result[\"between_cluster_d\"]] for result in features_embeddings], positions = range(len(features_embeddings)), showfliers=False)\n",
    "plt.xticks(range(len(features_embeddings)), [tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in features_embeddings], rotation=0)\n",
    "plt.ylabel(\"Mean between-cluster distance\")\n",
    "plt.title(\"Between-cluster distances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "metric = \"euclidean\"\n",
    "for result in features_embeddings:\n",
    "    labels = result[\"clusters_labels\"]\n",
    "    if len(np.unique(labels)) == 1:\n",
    "        result[\"silhouette_score\"] = 0\n",
    "        result[\"davies_bouldin_score\"] = 0\n",
    "        result[\"calinski_harabasz_score\"] = 0\n",
    "    else:\n",
    "        result[\"silhouette_score\"] = silhouette_score(result[\"embeddings\"], labels, metric = metric)\n",
    "        result[\"davies_bouldin_score\"] = davies_bouldin_score(result[\"embeddings\"], labels)\n",
    "        result[\"calinski_harabasz_score\"] = calinski_harabasz_score(result[\"embeddings\"], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(20, 15))\n",
    "for i, score in enumerate([\"silhouette_score\", \"davies_bouldin_score\", \"calinski_harabasz_score\"]):\n",
    "    scores = [result[score] for result in features_embeddings]\n",
    "    axs[i].bar(range(len(features_embeddings)), scores)\n",
    "    axs[i].set_xticks(range(len(features_embeddings)))\n",
    "    axs[i].set_xticklabels([tw.fill(f\"{result['reducer'].__name__} - {format_params(result['reducer_params'])}\", width = 20) for result in features_embeddings], rotation=0)\n",
    "    axs[i].set_title(score)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emv-requDRed-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
