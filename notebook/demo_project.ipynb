{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arattinger/Projects/rts/rts/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from rts.db.dao import DataAccessObject\n",
    "from rts.db_settings import DATABASE_URL\n",
    "from rts.db.queries import get_library_id_from_name\n",
    "from rts.io.media import upload_media_files\n",
    "from rts.api.models import Media\n",
    "import os\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "DataAccessObject().connect(DATABASE_URL)\n",
    "\n",
    "ARCHIVE_BASE_PATH = os.getenv(\"BASE_PATH\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- Decouple the upload functions from discovering the files. We need to give them a list of file paths and metadata (minimum one). One of the dangers at the moment is that we might ingest something by accident.\n",
    "- Make sure that all the data for the atlases are returned with the requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup before we can create media objects\n",
    "archive_name =  \"rts\"\n",
    "bucket_name =  archive_name\n",
    "library_id =  get_library_id_from_name(archive_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "# Upload clips\n",
    "\n",
    "clips = []\n",
    "data_dir = os.path.join(ARCHIVE_BASE_PATH, \"data\")\n",
    "for dirname in os.listdir(data_dir):\n",
    "    try:\n",
    "        clip_dir = os.path.join(data_dir, dirname, 'clips', 'videos')\n",
    "\n",
    "        for clip in os.listdir(clip_dir):\n",
    "            clip_path = os.path.join(clip_dir, clip)\n",
    "\n",
    "            clips.append(Media(**{\n",
    "                    'original_path': clip_path,\n",
    "                    'original_id': dirname,\n",
    "                    'media_path': f\"{bucket_name}/videos/{dirname}/{clip}\", \n",
    "                    'media_type': \"video\",\n",
    "                    'media_id': clip.split('.')[0],\n",
    "                    'sub_type': \"clip\", \n",
    "                    'size': os.path.getsize(clip_path), \n",
    "                    'metadata': {},\n",
    "                    'library_id': library_id, \n",
    "                    'hash': hashlib.md5(f\"{bucket_name}/videos/{dirname}/{clip}\".encode()).hexdigest(), \n",
    "                    'parent_id': -1,\n",
    "                    'start_ts': 0, 'end_ts': 10, \n",
    "                    'start_frame': 0, 'end_frame': 10, 'frame_rate': 30, \n",
    "            }))\n",
    "\n",
    "    except NotADirectoryError:\n",
    "        pass\n",
    "print(len(clips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate\n"
     ]
    }
   ],
   "source": [
    "uploaded_clips = upload_media_files(clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Media(media_id=None, media_path='rts/videos/ZB006020/ZB006020-L002.mp4', original_path='/Users/arattinger/Projects/rts/rts/testdata/data/ZB006020/clips/videos/ZB006020-L002.mp4', original_id='ZB006020', created_at=None, media_type='video', sub_type='clip', size=437415, metadata={}, library_id=1, hash='6349d3b98c85348cb92f6dedef5ed60a', parent_id=-1, start_ts=0.0, end_ts=10.0, start_frame=0, end_frame=10, frame_rate=30.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clips[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZB006020-L001-02\n",
      "ZB006020-L001-00\n",
      "ZB006020-L001-01\n",
      "ZB006020-L002-02\n",
      "ZB006020-L002-01\n",
      "ZB006020-L002-00\n",
      "ZB006020-L000-01\n",
      "ZB006020-L000-00\n",
      "ZB006020-L000-02\n",
      "ZB002020-L001-01\n",
      "ZB002020-L001-00\n",
      "ZB002020-L001-02\n",
      "ZB002020-L002-00\n",
      "ZB002020-L002-01\n",
      "ZB002020-L002-02\n",
      "ZB002020-L000-02\n",
      "ZB002020-L000-00\n",
      "ZB002020-L000-01\n",
      "ZB012020-L001-01\n",
      "ZB012020-L001-00\n",
      "ZB012020-L001-02\n",
      "ZB012020-L003-02\n",
      "ZB012020-L003-01\n",
      "ZB012020-L003-00\n",
      "ZB012020-L004-02\n",
      "ZB012020-L004-01\n",
      "ZB012020-L004-00\n",
      "ZB012020-L000-02\n",
      "ZB012020-L000-00\n",
      "ZB012020-L000-01\n",
      "ZB012020-L002-00\n",
      "ZB012020-L002-01\n",
      "ZB012020-L002-02\n",
      "ZB003020-L001-02\n",
      "ZB003020-L001-00\n",
      "ZB003020-L001-01\n",
      "ZB003020-L000-01\n",
      "ZB003020-L000-00\n",
      "ZB003020-L000-02\n",
      "ZB008020-L001-02\n",
      "ZB008020-L001-00\n",
      "ZB008020-L001-01\n",
      "ZB008020-L003-00\n",
      "ZB008020-L003-01\n",
      "ZB008020-L003-02\n",
      "ZB008020-L000-01\n",
      "ZB008020-L000-00\n",
      "ZB008020-L000-02\n",
      "ZB008020-L002-02\n",
      "ZB008020-L002-01\n",
      "ZB008020-L002-00\n",
      "ZB004020-L001-00\n",
      "ZB004020-L001-01\n",
      "ZB004020-L001-02\n",
      "ZB004020-L003-02\n",
      "ZB004020-L003-00\n",
      "ZB004020-L003-01\n",
      "ZB004020-L000-02\n",
      "ZB004020-L000-01\n",
      "ZB004020-L000-00\n",
      "ZB004020-L002-01\n",
      "ZB004020-L002-00\n",
      "ZB004020-L002-02\n",
      "ZB005020-L001-02\n",
      "ZB005020-L001-01\n",
      "ZB005020-L001-00\n",
      "ZB005020-L002-02\n",
      "ZB005020-L002-00\n",
      "ZB005020-L002-01\n",
      "ZB005020-L000-00\n",
      "ZB005020-L000-01\n",
      "ZB005020-L000-02\n",
      "ZB001020-L005-01\n",
      "ZB001020-L005-00\n",
      "ZB001020-L005-02\n",
      "ZB001020-L007-02\n",
      "ZB001020-L007-01\n",
      "ZB001020-L007-00\n",
      "ZB001020-L003-02\n",
      "ZB001020-L003-00\n",
      "ZB001020-L003-01\n",
      "ZB001020-L001-00\n",
      "ZB001020-L001-01\n",
      "ZB001020-L001-02\n",
      "ZB001020-L004-02\n",
      "ZB001020-L008-02\n",
      "ZB001020-L008-00\n",
      "ZB001020-L004-00\n",
      "ZB001020-L004-01\n",
      "ZB001020-L008-01\n",
      "ZB001020-L006-00\n",
      "ZB001020-L006-01\n",
      "ZB001020-L006-02\n",
      "ZB001020-L002-01\n",
      "ZB001020-L002-00\n",
      "ZB001020-L002-02\n",
      "ZB001020-L000-02\n",
      "ZB001020-L000-01\n",
      "ZB001020-L000-00\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "# Upload thumbnails\n",
    "thumbnails = []\n",
    "square_res = 256\n",
    "\n",
    "data_dir = os.path.join(ARCHIVE_BASE_PATH, \"data\")\n",
    "for dirname in os.listdir(data_dir):\n",
    "    try:\n",
    "        clip_dir = os.path.join(data_dir, dirname, 'clips', 'images', '256px')\n",
    "\n",
    "        for clip in os.listdir(clip_dir):\n",
    "            clip_path = os.path.join(clip_dir, clip)\n",
    "\n",
    "            # Find the parent. There can be multiple ways this can be achieved but\n",
    "            # most of the time this will not be solely based with the database\n",
    "            print(clip.split('.')[0])\n",
    "\n",
    "\n",
    "            thumbnails.append(Media(**{\n",
    "                    'original_path': clip_path,\n",
    "                    'original_id': dirname,\n",
    "                    'media_path': f\"{bucket_name}/images/{dirname}/{square_res}px/{clip}\", \n",
    "                    'media_type': \"image\", \n",
    "                    'sub_type': \"thumbnail\", \n",
    "                    'size': os.path.getsize(clip_path),\n",
    "                    'metadata': {},\n",
    "                    'library_id': library_id, \n",
    "                    'hash': hashlib.md5(f\"{bucket_name}/videos/{dirname}/{clip}\".encode()).hexdigest(), \n",
    "                    'parent_id': -1,  # Fill in the info here from the media objects\n",
    "                    'start_ts': 0, 'end_ts': 10, \n",
    "                    'start_frame': 0, 'end_frame': 10, 'frame_rate': 30, \n",
    "            }))\n",
    "\n",
    "    except NotADirectoryError:\n",
    "        pass\n",
    "print(len(clips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_clips = upload_media_files(clips)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
