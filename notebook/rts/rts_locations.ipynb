{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../..\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emv.db.dao import DataAccessObject\n",
    "from emv.db.queries import get_features_by_type_paginated, count_features_by_type\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "from emv.api.models import Feature\n",
    "from emv.api.models import Projection, MapProjectionFeatureCreate\n",
    "from emv.db.queries import create_projection, create_map_projection_feature, create_feature\n",
    "from emv.io.media import create_square_atlases\n",
    "from umap import UMAP\n",
    "import numba\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from emv.db.queries import get_all_media_by_library_id, get_library_id_from_name, get_library_from_name, check_media_exists\n",
    "from emv.storage.storage import get_storage_client\n",
    "from emv.features.image import embed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 100000 #count_features_by_type(\"transcript+ner\", short_clips_only=True) + 1\n",
    "data = get_features_by_type_paginated(\"transcript+ner\", page_size=10000, short_clips_only=True)\n",
    "\n",
    "while len(data) < MAX_FEATURES:\n",
    "    last_seen_id = data[-1].get(\"feature_id\", None)\n",
    "    if last_seen_id is None:\n",
    "        break\n",
    "    data.extend(get_features_by_type_paginated(\"transcript+ner\", page_size=10000, last_seen_feature_id=last_seen_id, short_clips_only=True))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Retrieved {len(df)} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"locations\"] = df[\"data\"].map(lambda x: [w[0] for w in x[\"entities\"] if w[1] == \"LOC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual matching\n",
    "with open(\"emv/features/cities.json\", \"r\") as f:\n",
    "    cities = json.load(f)\n",
    "    \n",
    "locations = pd.DataFrame([{\"locations\":k, \"lon\":float(v[0]), \"lat\":float(v[1])} for k,v in cities.items() if len(v) == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_locations = locations.locations.values\n",
    "df = df[df.locations.map(lambda x: any([l in found_locations for l in x]))]\n",
    "print(f\"Filtered to {len(df)} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"data\", \"feature_id\", \"media_id\", \"locations\"]]\n",
    "df[\"locations\"] = df[\"locations\"].map(lambda x: list(set([l for l in x if l in found_locations])))\n",
    "df[\"geo_coords\"] = df[\"locations\"].map(lambda x: [cities[l] for l in x])\n",
    "df = df.explode([\"locations\", \"geo_coords\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get thumbnails and create atlases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_id = get_library_id_from_name(\"rts\")\n",
    "\n",
    "max_medias = 500000\n",
    "thumbnails = get_all_media_by_library_id(lib_id, media_type=\"image\", sub_type=\"screenshot\", page_size=1000)\n",
    "\n",
    "while len(thumbnails) < max_medias:\n",
    "    new_medias = get_all_media_by_library_id(lib_id, \n",
    "                                             media_type=\"image\", \n",
    "                                             sub_type=\"screenshot\", \n",
    "                                             page_size=1000, \n",
    "                                             last_seen_media_id=thumbnails[-1][\"media_id\"], \n",
    "                                             last_seen_date=thumbnails[-1][\"created_at\"])\n",
    "    if len(new_medias) == 0:\n",
    "        break\n",
    "    thumbnails.extend(new_medias)\n",
    "\n",
    "thumbnails = pd.DataFrame(thumbnails)\n",
    "print(f\"Found {len(thumbnails)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnails = thumbnails[[\"parent_id\", \"media_path\"]].groupby(\"parent_id\").agg(list).reset_index()\n",
    "thumbnails[\"media_path\"] = thumbnails[\"media_path\"].map(lambda x: x[0])\n",
    "thumbnails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(thumbnails, left_on=\"media_id\", right_on=\"parent_id\", how=\"left\")\n",
    "df = df.drop(columns=[\"parent_id\"])\n",
    "df.dropna(subset=[\"media_path\"], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = get_storage_client()\n",
    "\n",
    "def get_thumbnail(media_path):\n",
    "    frame_bytes = storage_client.get_bytes(\"rts\", media_path)\n",
    "    if type(frame_bytes) == bytes:\n",
    "        frame = cv2.imdecode(np.frombuffer(frame_bytes, np.uint8), -1)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        frame = None\n",
    "        \n",
    "    return frame\n",
    "\n",
    "df[\"thumbnail\"] = df.media_path.map(lambda x: get_thumbnail(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"thumbnail\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check map\n",
    "plt.scatter(df[\"geo_coords\"].map(lambda x: float(x[1])), df[\"geo_coords\"].map(lambda x: float(x[0])), s=1, marker=\"o\")\n",
    "plt.scatter(6.15, 46.2, s=100, marker=\"x\", color=\"red\", label=\"Geneva\")\n",
    "plt.scatter(8.5, 47.4, s=100, marker=\"x\", color=\"green\", label=\"Zurich\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Features, Atlases and Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"feature_id\"] = df.apply(lambda x: create_feature(Feature(\n",
    "                                                        feature_type='locations',\n",
    "                                                        version=\"1\",\n",
    "                                                        model_name='transcript+ner+geolocation',\n",
    "                                                        model_params={},\n",
    "                                                        data={\n",
    "                                                            \"location\": x[\"locations\"],\n",
    "                                                            \"geo_coords\": x[\"geo_coords\"],\n",
    "                                                            \"media_path\": x[\"media_path\"]\n",
    "                                                            },\n",
    "                                                        media_id=x['media_id']\n",
    "                                                    )), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"feature_id\"] = df.feature_id.map(lambda x: x[\"feature_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atlases\n",
    "\n",
    "**Note**: the same clip can mention multiple locations. Since the mapping is based on the locations, the same clip can appear multiple times.\n",
    "In the Atlases, we don't need to duplicate the thumbnails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = df[[\"media_id\", \"media_path\", \"thumbnail\"]].groupby(\"media_id\").agg(list).reset_index()\n",
    "clips[\"media_path\"] = clips[\"media_path\"].map(lambda x: x[0])\n",
    "clips[\"thumbnail\"] = clips[\"thumbnail\"].map(lambda x: x[0])\n",
    "clips.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tiles = len(clips) # either all features or a subset of features\n",
    "atlas_width = 4096\n",
    "max_tile_size = 512\n",
    "max_tiles_per_atlas = (atlas_width // max_tile_size) ** 2\n",
    "atlas_count = int(total_tiles / max_tiles_per_atlas) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the projection, replace the names with the desired ones\n",
    "projection = Projection(\n",
    "    projection_name=\"RTS locations\",\n",
    "    version=\"1\",\n",
    "    library_id=get_library_id_from_name(\"rts\"),\n",
    "    model_name=\"whisper+spacy\",\n",
    "    model_params={},\n",
    "    data={},\n",
    "    dimension=3,\n",
    "    atlas_folder_path=\"\",\n",
    "    atlas_width=atlas_width,\n",
    "    tile_size=max_tile_size,\n",
    "    atlas_count=atlas_count,\n",
    "    total_tiles=total_tiles,\n",
    "    tiles_per_atlas=max_tiles_per_atlas,\n",
    ")\n",
    "\n",
    "projection_id = create_projection(projection)['projection_id']\n",
    "print(f\"Projection ID: {projection_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = clips.thumbnail.values.tolist()\n",
    "images = [Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) for img in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_atlases = create_square_atlases(atlas_name=\"atlas_rts_locations\",\n",
    "                                       projection_id=projection_id, \n",
    "                                       images=images, \n",
    "                                       width=atlas_width, \n",
    "                                       max_tile_size=max_tile_size, \n",
    "                                       no_border=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips[\"atlas_order\"] = clips.index // max_tiles_per_atlas\n",
    "clips[\"index_in_atlas\"] = clips.index % max_tiles_per_atlas\n",
    "\n",
    "# Merge with locations df\n",
    "df = df.merge(clips[[\"media_id\", \"atlas_order\", \"index_in_atlas\"]], on=\"media_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    create_map_projection_feature(MapProjectionFeatureCreate(\n",
    "        projection_id=projection_id,\n",
    "        media_id=row.media_id,\n",
    "        atlas_order=row.atlas_order,\n",
    "        index_in_atlas=row.index_in_atlas,\n",
    "        coordinates=[row.geo_coords[0], row.geo_coords[1], 0],\n",
    "        feature_id=row.feature_id\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emv-requDRed-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
