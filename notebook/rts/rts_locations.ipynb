{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../..\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emv.db.dao import DataAccessObject\n",
    "from emv.db.queries import get_features_by_type_paginated, count_features_by_type\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from emv.api.models import Feature\n",
    "from emv.api.models import Projection, MapProjectionFeatureCreate\n",
    "from emv.db.queries import create_projection, create_map_projection_feature, create_feature\n",
    "from emv.io.media import create_square_atlases\n",
    "from umap import UMAP\n",
    "import numba\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sqlalchemy.sql import text\n",
    "from datetime import datetime\n",
    "\n",
    "from emv.db.queries import get_all_media_by_library_id, get_library_id_from_name, get_library_from_name, check_media_exists, get_media_by_id, delete_feature_by_type\n",
    "from emv.storage.storage import get_storage_client\n",
    "from emv.features.image import embed_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create \"locations\" features from \"transcript+ner\" features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_features = count_features_by_type(\"transcript+ner\", short_clips_only=True)\n",
    "print(f\"Total features: {total_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = total_features + 1\n",
    "data = get_features_by_type_paginated(\"transcript+ner\", page_size=10000, short_clips_only=True)\n",
    "\n",
    "for _ in tqdm(range(MAX_FEATURES // 10000)):\n",
    "    last_seen_id = data[-1].get(\"feature_id\", None)\n",
    "    if last_seen_id is None:\n",
    "        break\n",
    "    data.extend(get_features_by_type_paginated(\"transcript+ner\", page_size=10000, last_seen_feature_id=last_seen_id, short_clips_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop fields not needed\n",
    "df = []\n",
    "for d in tqdm(data):\n",
    "    df.append(\n",
    "        {\n",
    "            \"feature_id\": d[\"feature_id\"],\n",
    "            \"media_id\": d[\"media_id\"],\n",
    "            \"data\": d[\"data\"]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "df = pd.DataFrame(df)\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "print(f\"Retrieved {len(df)} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"locations\"] = df[\"data\"].map(lambda x: [w[0] for w in x[\"entities\"] if w[1] == \"LOC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual matching\n",
    "with open(\"emv/features/cities.json\", \"r\") as f:\n",
    "    cities = json.load(f)\n",
    "    \n",
    "locations = pd.DataFrame([{\"locations\":k, \"lon\":float(v[0]), \"lat\":float(v[1])} for k,v in cities.items() if len(v) == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_locations = locations.locations.values\n",
    "df = df[df.locations.map(lambda x: any([l in found_locations for l in x]))]\n",
    "print(f\"Filtered to {len(df)} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"data\", \"media_id\", \"locations\"]]\n",
    "df[\"locations\"] = df[\"locations\"].map(lambda x: list(set([l for l in x if l in found_locations])))\n",
    "df[\"geo_coords\"] = df[\"locations\"].map(lambda x: [cities[l] for l in x])\n",
    "df = df.explode([\"locations\", \"geo_coords\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if clip has thumbnail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dao = DataAccessObject()\n",
    "\n",
    "def query_thumbnail(media_id):\n",
    "    query = text(\"SELECT * FROM media WHERE parent_id = :parent_id AND media_type = 'image' AND sub_type = 'screenshot'\")\n",
    "    result = dao.fetch_all(query, {\"parent_id\": media_id})\n",
    "    if len(result) == 0:\n",
    "        return None\n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dao = DataAccessObject()\n",
    "df[\"thumbnail_media\"] = df[\"media_id\"].map(query_thumbnail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = get_storage_client()\n",
    "df[\"has_thumbnail\"] = df[\"thumbnail_media\"].map(lambda x: storage_client.object_exists(\"rts\", x.get(\"media_path\", \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check map\n",
    "plt.scatter(df[\"geo_coords\"].map(lambda x: float(x[1])), df[\"geo_coords\"].map(lambda x: float(x[0])), \n",
    "            s=1, marker=\"o\",\n",
    "            c=df[\"has_thumbnail\"].map(lambda x: \"red\" if x else \"blue\"))\n",
    "plt.title(f\"Missing {df['has_thumbnail'].value_counts()[False]} thumbnails out of {len(df)} instances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"has_thumbnail\"]]\n",
    "df = df.drop(columns=[\"has_thumbnail\"])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"feature_id\"] = df.apply(lambda x: create_feature(Feature(\n",
    "                                                        feature_type='locations',\n",
    "                                                        version=\"1\",\n",
    "                                                        model_name='transcript+ner+geolocation',\n",
    "                                                        model_params={},\n",
    "                                                        data={\n",
    "                                                            \"location\": x[\"locations\"],\n",
    "                                                            \"geo_coords\": x[\"geo_coords\"],\n",
    "                                                            \"media_path\": x[\"thumbnail_media\"].get(\"media_path\", \"\")\n",
    "                                                            },\n",
    "                                                        media_id=x['media_id']\n",
    "                                                    ))[\"feature_id\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Atlases and Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atlases\n",
    "\n",
    "**Note**: the same clip can mention multiple locations. Since the mapping is based on the locations, the same clip can appear multiple times.\n",
    "In the Atlases, we don't need to duplicate the thumbnails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 100000\n",
    "PAGE_SIZE = 10000\n",
    "features = get_features_by_type_paginated(\"locations\", page_size=PAGE_SIZE)\n",
    "\n",
    "for _ in tqdm(range(MAX_FEATURES // PAGE_SIZE)):\n",
    "    last_seen_id = features[-1].get(\"feature_id\", None)\n",
    "    if last_seen_id is None:\n",
    "        break\n",
    "    features.extend(get_features_by_type_paginated(\"locations\", page_size=PAGE_SIZE, last_seen_feature_id=last_seen_id))\n",
    "    \n",
    "features = pd.DataFrame(features)\n",
    "print(f\"Retrieved {len(features)} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnails_paths = list(set(features[\"data\"].map(lambda x: x[\"media_path\"]).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = get_storage_client()\n",
    "\n",
    "def get_thumbnail(media_path):\n",
    "    frame_bytes = storage_client.get_bytes(\"rts\", media_path)\n",
    "    if type(frame_bytes) == bytes:\n",
    "        frame = cv2.imdecode(np.frombuffer(frame_bytes, np.uint8), -1)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = Image.fromarray(frame)\n",
    "    else:\n",
    "        frame = None\n",
    "        \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnails = [get_thumbnail(p) for p in tqdm(thumbnails_paths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tiles = len(thumbnails) # either all features or a subset of features\n",
    "atlas_width = 4096\n",
    "max_tile_size = 512\n",
    "max_tiles_per_atlas = (atlas_width // max_tile_size) ** 2\n",
    "atlas_count = int(total_tiles / max_tiles_per_atlas) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the projection, replace the names with the desired ones\n",
    "projection = Projection(\n",
    "    projection_name=\"RTS locations 26k\",\n",
    "    version=\"1\",\n",
    "    library_id=get_library_id_from_name(\"rts\"),\n",
    "    model_name=\"whisper+spacy\",\n",
    "    model_params={},\n",
    "    data={},\n",
    "    dimension=3,\n",
    "    atlas_folder_path=\"\",\n",
    "    atlas_width=atlas_width,\n",
    "    tile_size=max_tile_size,\n",
    "    atlas_count=atlas_count,\n",
    "    total_tiles=total_tiles,\n",
    "    tiles_per_atlas=max_tiles_per_atlas,\n",
    ")\n",
    "\n",
    "projection_id = create_projection(projection)['projection_id']\n",
    "print(f\"Projection ID: {projection_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_id = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_atlases = create_square_atlases(atlas_name=\"atlas_rts_locations\",\n",
    "                                       projection_id=projection_id, \n",
    "                                       images=thumbnails, \n",
    "                                       width=atlas_width, \n",
    "                                       max_tile_size=max_tile_size, \n",
    "                                       no_border=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnails_df = pd.DataFrame(thumbnails_paths, columns=[\"thumbnail_path\"])\n",
    "thumbnails_df[\"atlas_order\"] = thumbnails_df.index // max_tiles_per_atlas\n",
    "thumbnails_df[\"index_in_atlas\"] = thumbnails_df.index % max_tiles_per_atlas\n",
    "\n",
    "# Merge with locations features\n",
    "features[\"thumbnail_path\"] = features[\"data\"].map(lambda x: x[\"media_path\"])\n",
    "features = features.merge(thumbnails_df, on=\"thumbnail_path\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"geo_coords\"] = features[\"data\"].map(lambda x: x[\"geo_coords\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in features.iterrows():\n",
    "    create_map_projection_feature(MapProjectionFeatureCreate(\n",
    "        projection_id=projection_id,\n",
    "        media_id=row.media_id,\n",
    "        atlas_order=row.atlas_order,\n",
    "        index_in_atlas=row.index_in_atlas,\n",
    "        coordinates=[row.geo_coords[0], row.geo_coords[1], 0],\n",
    "        feature_id=row.feature_id\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locations metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 100000\n",
    "PAGE_SIZE = 10000\n",
    "features = get_features_by_type_paginated(\"locations\", page_size=PAGE_SIZE)\n",
    "\n",
    "for _ in tqdm(range(MAX_FEATURES // PAGE_SIZE)):\n",
    "    last_seen_id = features[-1].get(\"feature_id\", None)\n",
    "    if last_seen_id is None:\n",
    "        break\n",
    "    features.extend(get_features_by_type_paginated(\"locations\", page_size=PAGE_SIZE, last_seen_feature_id=last_seen_id))\n",
    "    \n",
    "features = pd.DataFrame(features)\n",
    "print(f\"Retrieved {len(features)} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_hdf(\"data/rts_metadata.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[['mediaId', 'publishedDate', 'categoryName', 'assetType',\n",
    "                                    'contentType', 'backgoundType', 'collection', 'publishedBy',\n",
    "                                    'title', 'resume', 'geoTheme', 'resumeSequence',\n",
    "                                    'sequences']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"parent_id\"] = features.media_id.map(lambda x: x.split(\"-\")[1])\n",
    "features = features.merge(metadata[['mediaId', 'publishedDate', 'categoryName', 'assetType',\n",
    "                                    'contentType', 'backgoundType', 'collection', 'publishedBy',\n",
    "                                    'title', 'resume', 'geoTheme', 'resumeSequence',\n",
    "                                    'sequences']], \n",
    "                          left_on=\"parent_id\", right_on=\"mediaId\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.assetType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.contentType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.backgoundType.explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.collection.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.publishedBy.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.publishedDate.map(lambda x: datetime.strptime(x, \"%Y-%m-%dT%H:%M:%SZ\").year).value_counts().sort_index().plot(kind=\"bar\", figsize=(12, 6), title=\"Published date per year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorie_to_theme = {\n",
    "    \"Téléjournal, flashes\": \"Information & Actualité\",\n",
    "    \"Actualités régionales\": \"Information & Actualité\",\n",
    "    \"ACTUALITE\": \"Information & Actualité\",\n",
    "    \"INFORMATION\": \"Information & Actualité\",\n",
    "    \"Autres émissions d'actualités\": \"Information & Actualité\",\n",
    "    \"Autres (information)\": \"Information & Actualité\",\n",
    "    \"Plateaux, débats, highlights\": \"Information & Actualité\",\n",
    "    \"Sujets internationaux et nationaux mélangés (débats)\": \"Information & Actualité\",\n",
    "    \"Politique, économie, société\": \"Information & Actualité\",\n",
    "    \"Informations de service\": \"Information & Actualité\",\n",
    "    \"Rencontres, entretiens, portraits\": \"Information & Actualité\",\n",
    "\n",
    "    \"Talk shows\": \"Débats & Talk Shows\",\n",
    "    \"Débats\": \"Débats & Talk Shows\",\n",
    "\n",
    "    \"Société, religion\": \"Société & Monde\",\n",
    "    \"Pays et peuples\": \"Société & Monde\",\n",
    "    \"Emissions de conseil\": \"Société & Monde\",\n",
    "    \"Emissions de compagnie\": \"Société & Monde\",\n",
    "    \"Médecine, santé\": \"Société & Monde\",\n",
    "    \"Histoire\": \"Société & Monde\",\n",
    "\n",
    "    \"CULTURE ET CONNAISSANCE\": \"Culture & Connaissance\",\n",
    "    \"Science\": \"Culture & Connaissance\",\n",
    "    \"Emissions didactiques\": \"Culture & Connaissance\",\n",
    "    \"Magazines culturels\": \"Culture & Connaissance\",\n",
    "    \"Arts et médias\": \"Culture & Connaissance\",\n",
    "\n",
    "    \"Arts\": \"Arts & Spectacles\",\n",
    "    \"Ballets\": \"Arts & Spectacles\",\n",
    "    \"Opéras\": \"Arts & Spectacles\",\n",
    "    \"Concerts\": \"Arts & Spectacles\",\n",
    "    \"Shows et variétés musicales\": \"Arts & Spectacles\",\n",
    "    \"Cabaret, humour\": \"Arts & Spectacles\",\n",
    "\n",
    "    \"MUSIQUE\": \"Musique\",\n",
    "    \"Pop et rock, clips\": \"Musique\",\n",
    "    \"Folklore et musique populaire\": \"Musique\",\n",
    "\n",
    "    \"SPORT\": \"Sport\",\n",
    "    \"Résultats et magazines sportifs\": \"Sport\",\n",
    "    \"Autres émissions sportives\": \"Sport\",\n",
    "    \"Retransmissions en direct\": \"Sport\",\n",
    "\n",
    "    \"FICTION\": \"Fiction & Divertissement\",\n",
    "    \"Série et feuilletons\": \"Fiction & Divertissement\",\n",
    "    \"DIVERTISSEMENT\": \"Fiction & Divertissement\",\n",
    "    \"Autres émissions de divertissement\": \"Fiction & Divertissement\",\n",
    "\n",
    "    \"EMISSIONS POUR ENFANTS ET ADOLESCENTS\": \"Jeunesse\",\n",
    "    \"Jeux, concours\": \"Jeunesse\",\n",
    "\n",
    "    \"RELIGION\": \"Religion & Spiritualité\",\n",
    "    \"Cultes, messes et prédications\": \"Religion & Spiritualité\",\n",
    "    \"Autres émissions religieuses\": \"Religion & Spiritualité\",\n",
    "\n",
    "    \"AUTRES EMISSIONS\": \"Autres / Inclassables\",\n",
    "    None: \"Autres / Inclassables\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"theme\"] = features.contentType.map(lambda x: categorie_to_theme.get(x, \"Autres / Inclassables\"))\n",
    "features.theme.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emv-requDRed-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
