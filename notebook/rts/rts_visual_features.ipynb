{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../..\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import textwrap as tw\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from ast import literal_eval\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import numba\n",
    "from emv.db.dao import DataAccessObject\n",
    "from sqlalchemy.sql import text\n",
    "\n",
    "from umap import UMAP\n",
    "from emv.embeddings.dr_eval import plot_embeddings_with_images, normalize_embedding\n",
    "\n",
    "from emv.db.queries import get_all_media_by_library_id, get_library_id_from_name, get_library_from_name\n",
    "from emv.storage.storage import get_storage_client\n",
    "from emv.features.image import embed_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load clips from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_id = get_library_id_from_name(\"rts\")\n",
    "\n",
    "max_medias = 10000\n",
    "medias = get_all_media_by_library_id(lib_id, media_type=\"image\", page_size=100)\n",
    "\n",
    "while len(medias) < max_medias:\n",
    "    new_medias = get_all_media_by_library_id(lib_id, media_type=\"image\", page_size=100, last_seen_media_id=medias[-1][\"media_id\"], last_seen_date=medias[-1][\"created_at\"])\n",
    "    if len(new_medias) == 0:\n",
    "        break\n",
    "    medias.extend(new_medias)\n",
    "\n",
    "medias = pd.DataFrame(medias)\n",
    "print(f\"Found {len(medias)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = get_storage_client()\n",
    "\n",
    "def get_thumbnail(media_path):\n",
    "    frame_bytes = storage_client.get_bytes(\"rts\", media_path)\n",
    "    if type(frame_bytes) == bytes:\n",
    "        frame = cv2.imdecode(np.frombuffer(frame_bytes, np.uint8), -1)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "    return frame\n",
    "\n",
    "medias[\"thumbnail\"] = medias.media_path.map(lambda x: get_thumbnail(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "        \n",
    "features = []\n",
    "for b in batch(medias.thumbnail.values.tolist(), 500):\n",
    "    features.append(embed_images(b))\n",
    "\n",
    "features = np.concatenate(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = UMAP(n_components=2, n_neighbors=100, min_dist=0.1, metric=\"euclidean\", random_state=42)\n",
    "embedding = reducer.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = normalize_embedding(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnails = medias.thumbnail.values\n",
    "thumbnails = [cv2.resize(t, (64, 64)) for t in thumbnails]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings_with_images(embedding, thumbnails, zoom = 0.07, figsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new Projection based on the visual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emv.api.models import Feature\n",
    "from emv.api.models import Projection, MapProjectionFeatureCreate\n",
    "from emv.db.queries import create_projection, create_map_projection_feature, create_feature\n",
    "from emv.io.media import create_square_atlases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save features to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medias[\"embedding\"] = features.tolist()\n",
    "\n",
    "medias[\"feature_id\"] = medias.apply(lambda row: create_feature(Feature(feature_type='rts_visual',\n",
    "                                                                       version=\"1\",\n",
    "                                                                       model_name='resnet50',\n",
    "                                                                       model_params={},\n",
    "                                                                       data={},\n",
    "                                                                       media_id=row['media_id'], \n",
    "                                                                       embedding_size=2048,\n",
    "                                                                       embedding_2048=row['embedding']\n",
    "                                                                    )\n",
    "                                                               ), axis = 1)\n",
    "medias[\"feature_id\"] = medias[\"feature_id\"].map(lambda x: x.feature_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tiles = len(medias) # either all features or a subset of features\n",
    "atlas_width = 4096\n",
    "max_tile_size = 512\n",
    "max_tiles_per_atlas = (atlas_width // max_tile_size) ** 2\n",
    "atlas_count = int(total_tiles / max_tiles_per_atlas) + 1\n",
    "\n",
    "# Create the projection, replace the names with the desired ones\n",
    "projection = Projection(\n",
    "    projection_name=\"RTS Visual 3D\",\n",
    "    version=\"0.0.1\",\n",
    "    library_id=get_library_id_from_name(\"rts\"),\n",
    "    model_name=\"resnet50\",\n",
    "    model_params={},\n",
    "    data={},\n",
    "    dimension=3,\n",
    "    atlas_folder_path=\"\",\n",
    "    atlas_width=atlas_width,\n",
    "    tile_size=max_tile_size,\n",
    "    atlas_count=atlas_count,\n",
    "    total_tiles=total_tiles,\n",
    "    tiles_per_atlas=max_tiles_per_atlas,\n",
    ")\n",
    "\n",
    "projection_id = create_projection(projection)['projection_id']\n",
    "print(f\"Projection ID: {projection_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Atlases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = medias.thumbnail.values.tolist()\n",
    "images = [Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) for img in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_atlases = create_square_atlases(atlas_name=\"atlas_rts_visual\",\n",
    "                                       projection_id=projection_id, \n",
    "                                       images=images, \n",
    "                                       width=atlas_width, \n",
    "                                       max_tile_size=max_tile_size, \n",
    "                                       no_border=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute embeddings in 3D and save to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = UMAP(n_components=3, n_neighbors=100, min_dist=0.1, metric=\"euclidean\", random_state=42)\n",
    "embedding_3d = reducer.fit_transform(medias_with_features.embedding_2048.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(embedding_3d[:, 0], embedding_3d[:, 1], embedding_3d[:, 2], s=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an entry in the map_projection_feature table for each feature, links features, media and coordinates\n",
    "for i, row in medias.iterrows():\n",
    "    create_map_projection_feature(MapProjectionFeatureCreate(\n",
    "        projection_id=projection_id,\n",
    "        media_id=row.media_id,\n",
    "        atlas_order=i // max_tiles_per_atlas,\n",
    "        index_in_atlas=i % max_tiles_per_atlas,\n",
    "        coordinates=[embedding_3d[i, 0], embedding_3d[i, 1], embedding_3d[i, 2]],\n",
    "        feature_id=row.feature_id\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emv-requDRed-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
